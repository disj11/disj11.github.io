[{"content":"Ktlint는 Kotlin 코드 스타일을 검사하고 포맷팅하는 도구로, 협업 시 코드의 일관성을 유지하는 데 유용합니다. Ktlint 1.0 버전부터 기본 설정이 ktlint_official 코드 스타일로 변경되었습니다. 만약 다른 스타일을 사용하고 싶다면, .editorconfig 파일의 ktlint_code_style 속성을 통해 이를 변경할 수 있습니다. 코드 스타일 변경하기 # .editorconfig 파일에서 아래와 같이 설정하여 원하는 코드 스타일을 지정할 수 있습니다: [*.{kt,kts}] ktlint_code_style = intellij_idea # 또는 android_studio, ktlint_official (기본값) 특정 규칙 비활성화하기 # 특정 규칙을 비활성화하려면 ktlint_ 접두사와 규칙 세트의 ID를 조합하여 설정하면 됩니다. 예를 들어, ktlint_official 코드 스타일을 사용하면서 standard 규칙 세트의 final-newline 규칙을 비활성화하려면 다음과 같이 설정합니다: [*.{kt,kts}] ktlint_code_style = ktlint_official ktlint_standard_final-newline = disabled IntelliJ에서 Ktlint 플러그인 활용하기 # IntelliJ IDEA를 사용하는 경우, Ktlint 플러그인을 설치하면 규칙 세트 ID와 규칙 이름을 쉽게 확인할 수 있습니다. 플러그인을 설치한 후, Settings \u0026gt; Tools \u0026gt; Ktlint에서 모드를 Manual로 변경하면 코드 스타일이 맞지 않는 경우 관련 정보를 확인할 수 있습니다. 규칙 비활성화 예시 # 아래 이미지는 IntelliJ에서 표시되는 특정 규칙의 예시입니다. 해당 규칙을 비활성화하려면 .editorconfig 파일에 다음과 같이 추가합니다: [*.{kt,kts}] ktlint_standard_no-multi-spaces = disabled 추가 참고 사항 # 전체 규칙 세트 비활성화: 특정 규칙 세트 전체를 비활성화하려면 아래와 같이 설정할 수 있습니다: [*.{kt,kts}] ktlint_standard = disabled # \u0026#39;standard\u0026#39; 규칙 세트 전체 비활성화 실험적 규칙 활성화: 실험적 규칙은 기본적으로 비활성화되어 있으며, 명시적으로 활성화해야 사용할 수 있습니다: [*.{kt,kts}] ktlint_experimental = enabled Pre-commit Hook 및 자동화 # Ktlint는 Git pre-commit hook과 통합하여 커밋 전에 자동으로 코드 스타일 검사를 실행할 수 있습니다. Gradle을 사용하는 경우 아래 명령어로 Git Hook을 추가할 수 있습니다: ./gradlew addKtlintCheckGitPreCommitHook 참고 자료 # 더 자세한 설정 옵션은 KtLint 공식 문서를 참조하세요.","date":"2024-02-22T20:46:04+09:00","href":"https://disj11.github.io/editorconfig/","objectID":"b7c956215f241b4a2f16a0223df89833_0","order":0,"tags":["kotlin"],"title":"Ktlint: 기본 설정 변경 및 커스터마이징 가이드"},{"content":"S3 Sink Connector에는 파일 로테이션을 설정할 수 있는 두 가지 주요 속성이 있습니다. 이번 포스트에서는 이 두 속성의 차이를 비교하고, 각각의 동작 방식을 자세히 살펴보겠습니다. rotate.interval.ms rotate.schedule.interval.ms 먼저 두 속성의 주요 차이를 표로 정리하였습니다. rotate.schedule.interval.ms rotate.interval.ms 기준 시간 시스템 시간 기준 timestamp.extractor를 통해 설정 (Kafka Record Time, Record Field, Wall Clock 등) 지속적인 데이터 스트림 필요 여부 필요하지 않음 필요함 Exactly-once 보장 여부 보장되지 않음 경우에 따라 보장됨 지속적인 데이터 유입 # rotate.schedule.interval.ms # 이 속성은 시스템 시간을 기준으로 일정 간격마다 파일을 플러시하고 S3에 업로드합니다. 지속적인 데이터 유입이 필요하지 않으며, 설정된 시간이 지나면 자동으로 파일이 커밋됩니다. 사용하기 위해서는 반드시 timezone 속성을 설정해야 합니다. 예를 들어, rotate.schedule.interval.ms 값을 3000ms로 설정한 경우를 살펴보겠습니다. 시간 (time) 오프셋 (Offset) 설명 (Description) 1706713200000 100 토픽 데이터 수신 1706713201000 101 토픽 데이터 수신 1706713202000 102 토픽 데이터 수신 1706713203000 n/a 파일 플러시 시작 위 예시에서, 데이터가 더 이상 들어오지 않더라도 지정된 시간(3000ms)이 지나면 파일이 플러시되고 업로드됩니다. rotate.interval.ms # 이 속성은 첫 번째 레코드의 타임스탬프를 기준으로 파일의 타임스탬프 범위를 계산합니다. 이후 레코드의 타임스탬프가 범위를 초과하면 파일을 플러시하고 S3에 업로드합니다. 지속적인 데이터 유입이 필요하며, 데이터가 중단되면 파일이 업로드되지 않고 열려 있는 상태로 남을 수 있습니다. 예를 들어, rotate.interval.ms 값을 3000ms로 설정한 경우를 살펴보겠습니다. 시간 (time) 오프셋 (Offset) 설명 (Description) 1706713200000 100 토픽 데이터 수신 1706713201000 101 토픽 데이터 수신 1706713202000 102 토픽 데이터 수신 1706713204000 103 타임스탬프 범위 초과로 파일 플러시 및 업로드 시작 1706713205000 104 토픽 데이터 수신 위 예시에서, 후속 레코드(Offset: 104)가 없으면 파일이 업로드되지 않을 가능성이 있으므로 주의가 필요합니다. Exactly-once Delivery # Exactly-once delivery를 보장하려면 기본적으로 rotate.interval.ms를 사용하는 것이 권장됩니다. 추가로 다양한 조건을 충족해야만 정확히 한 번만 데이터를 전달할 수 있습니다. Confluent 문서에서는 아래와 같은 이미지를 제공하여 Exactly-once delivery 조건을 설명합니다: 결론 # 두 속성은 서로 다른 목적과 환경에서 사용됩니다: rotate.schedule.interval.ms: 데이터 유입이 불규칙하거나 적은 경우 적합. rotate.interval.ms: 지속적인 데이터 유입이 보장되고 Exactly-once delivery가 필요한 경우 적합. 참고자료: Amazon S3 Sink Connector for Confluent Platform Amazon S3 Sink Connector for Confluent Cloud Partitioning Records into S3 Objects Confluent S3 Sink Connector EOS","date":"2024-01-10T16:42:15+09:00","href":"https://disj11.github.io/s3-sink-connector-scheduled-rotation/","objectID":"694dcce2f77b641a8389c0aa505c5f38_0","order":0,"tags":["kafka"],"title":"S3 Sink Connector Scheduled Rotation"},{"content":"Redis는 인기 있는 인메모리 데이터 구조 저장소로, 키 삭제를 위한 여러 방법을 제공합니다. 이 글에서는 DEL과 UNLINK 명령어의 차이점, 그리고 lazyfree-lazy-user-del 설정 옵션에 대해 살펴보며, Redis 키 삭제 전략을 최적화하는 데 도움을 드리고자 합니다. DEL 명령어 # Redis의 DEL 명령어는 데이터베이스에서 키를 제거하는 기본적인 작업입니다. 한 번의 작업으로 여러 키를 삭제할 수 있으며, 시간 복잡도는 O(N)입니다. 여기서 N은 제거할 키의 수입니다.1 시간 복잡도 분석 # 단순 키 타입(예: Strings): 키당 O(1) 복잡한 데이터 구조(예: Lists, Sets, Hashes): 키당 O(M), M은 데이터 구조 내 요소의 수 따라서, N개의 키를 삭제하는 총 시간 복잡도는 최악의 경우 O(N*M)로 표현될 수 있습니다. 성능 영향 # Redis는 주로 단일 스레드로 작동하기 때문에, 큰 키나 여러 복잡한 데이터 구조를 삭제하는 것은 서버를 차단하여 전체 성능에 영향을 줄 수 있습니다. 이러한 차단 동작은 특히 고처리량 환경에서 문제가 될 수 있습니다. UNLINK 명령어 # Redis 4.0에서 도입된 UNLINK 명령어는 키 삭제를 위한 비차단 대안을 제공합니다.23 주요 특징 # 일정한 시간 복잡도: 키 크기나 데이터 구조 복잡성에 관계없이 키당 O(1) 비동기 삭제: 키를 키스페이스에서 즉시 제거하고 실제 메모리 회수는 나중에 예약 비차단: 메모리가 해제되는 동안 Redis가 다른 명령을 계속 처리할 수 있음 내부 메커니즘 # UNLINK 명령어는 두 단계로 작동합니다: 키스페이스에서 키를 즉시 연결 해제합니다(O(1) 작업). 실제 메모리 회수를 백그라운드 스레드에서 비동기적으로 수행하도록 예약합니다. 작은 키에 대한 최적화 # 모든 UNLINK 작업이 비동기적으로 처리되는 것은 아닙니다. 매우 작은 키의 경우, 비동기 삭제를 예약하는 오버헤드가 즉시 삭제 비용을 초과할 수 있습니다. Redis는 내부적으로 삭제 비용을 계산하고, 비용이 특정 임계값을 초과하는 경우에만 비동기적으로 처리합니다. lazyfree.c 기반 간소화된 의사 코드4 if (deletion_cost \u0026gt; LAZYFREE_THRESHOLD) { schedule_async_deletion(key); } else { delete_immediately(key); } lazyfree-lazy-user-del 설정 # 기존 코드에서 DEL을 UNLINK로 변경하는 것이 실용적이지 않은 상황을 위해, Redis 6.0에서는 lazyfree-lazy-user-del 설정 옵션을 도입했습니다. 사용법 # Redis 설정에서 yes로 설정하면:5 lazyfree-lazy-user-del yes 이 옵션은 모든 DEL 명령어를 내부적으로 UNLINK로 처리하게 하여, 코드 변경 없이 비차단 삭제의 이점을 제공합니다. 결론 # DEL과 UNLINK의 차이를 이해하는 것은 특히 큰 키나 고처리량 시나리오를 다룰 때 Redis 성능을 최적화하는 데 중요합니다. DEL은 작은 키와 단순한 데이터 구조에 적합한 반면, UNLINK는 더 큰 데이터 세트와 복잡한 구조에 상당한 이점을 제공합니다. lazyfree-lazy-user-del 옵션은 광범위한 코드 수정 없이 이러한 이점을 활용할 수 있는 편리한 방법을 제공합니다. 사용 사례를 신중히 고려하고 적절한 삭제 전략을 구현함으로써 Redis 기반 애플리케이션의 성능과 응답성을 크게 향상시킬 수 있습니다. https://redis.io/docs/latest/commands/del/\u0026#160;\u0026#x21a9;\u0026#xfe0e; https://redis.io/docs/latest/commands/unlink/\u0026#160;\u0026#x21a9;\u0026#xfe0e; http://redisgate.kr/redis/command/unlink.php\u0026#160;\u0026#x21a9;\u0026#xfe0e; https://github.com/redis/redis/blob/unstable/src/lazyfree.c\u0026#160;\u0026#x21a9;\u0026#xfe0e; https://redis.io/docs/latest/operate/oss_and_stack/management/config-file/\u0026#160;\u0026#x21a9;\u0026#xfe0e;","date":"2023-10-20T20:57:17+09:00","href":"https://disj11.github.io/redis-del-command/","objectID":"574427588ebf40cd68081a2df6e03c44_0","order":0,"tags":["redis"],"title":"Redis Del Command"},{"content":"Configuration # connectionTimeout # 클라이언트가 커넥션을 요청한 이후에 커넥션을 얻기까지 기다릴 수 있는 최대 시간을 제어한다. 이 시간을 초과하면 SQLException 이 발생한다. 허용되는 최소값은 250ms 이며 기본값은 30,000ms (30초) 이다. idleTimeout # 커넥션이 유휴 상태(사용되지 않는 상태)로 유지될 수 있는 최대 시간을 제어한다. 이 설정은 minimumIdle 값이 maximumPoolSize 보다 작은 경우에만 적용된다. 설정된 시간 동안 커넥션이 사용되지 않으면 해당 커넥션은 커넥션풀에서 제거된다. 이 때 커넥션풀에 있는 유휴 상태의 커넥션이 miniumIdle 과 같다면 제거되지 않는다. 커넥션이 유휴 상태로 변경되는데에는 최대 +30초 에서 평균 +15초의 변동이 있을 수 있다. 이 값이 0이라면 유휴 커넥션을 제거하지 않는다. 이 값을 설정할 수 있는 최소값은 10,000ms (10초) 이며 기본값은 600,000ms (10분) 이다. NOTE: 커넥션 사용 이후 커넥션풀에 커넥션을 다시 반환하면 해당 커넥션의 idle time 은 다시 0으로 초기화된다. maxLifetime # 커넥션풀에 커넥션이 존재할 수 있는 최대 수명을 제어한다. 이 시간을 초과하면 커넥션풀에 있는 커넥션을 제거한다. 이때 현재 사용중인 커넥션이라면 커넥션을 제거하지 않는다. 커넥션풀에 있는 커넥션의 대량 제거를 방지하기 위해서 커넥션별로 시간 차이를 두며 작동한다. 이 값은 데이터베이스의 연결 시간 제한(MySQL인 경우 wait_timeout) 보다 짧아야 하며 네트워크 지연을 고려하여 wait_timeout 설정보다 2~3초 정도 짧게 줄 것을 권고한다. 이 값이 0이라면 최대 수명이 없음 (무한 수명) 을 의미한다. 허용되는 최소 값은 30,000ms (30초) 이며 기본값은 1,800,000ms (30분) 이다. NOTE: 커넥션 사용 여부와 관련 없이, 말 그대로 커넥션이 존재할 수 있는 최대 수명이다. minimumIdle # 최소 유휴 연결 수를 유지하기 위한 설정이다. 유휴 연결이 이 값보다 적어지고 총 커넥션이 maximumPoolSize 보다 작은 경우 HikariCP 는 빠르고 효율적으로 커넥션을 추가하기 위한 작업을 수행한다. 기본값은 maximumPoolSize 와 동일하다. maximumPoolSize # 유휴 커넥션과 사용 중인 커넥션을 모두 포함한 커넥션의 최대 수를 제어한다. 커넥션 요청시 유휴 커넥션이 없다면 connectionTimeout 만큼 차단되며, 이 시간동안 커넥션을 얻지 못할 시 SQLException 이 발생한다. 기본값은 10 이다. 참고 # HikariCP README.md 참고","date":"2023-09-02T15:16:53+09:00","href":"https://disj11.github.io/hikari-cp-configuration/","objectID":"b89d3496ac3560f046075f9c228fb2b6_0","order":0,"tags":["database"],"title":"HikariCP 자주 사용 하는 설정값 정리"},{"content":"JIT Compiler 란? # 자바 코드의 실행을 위해서는 바이트 코드로 컴파일이 필요하다. 바이트 코드는 다시 JVM 의 인터프리터를 통해 기계어로 해석되는 과정을 거쳐 실행된다. 이런 이유로 인터프리터를 통해 해석되는 과정없이 실행되는 언어에 비해 많이 느리다. 이러한 성능 차이를 해결하기 위해 JVM 에서는 JIT (Just In Time) Compiler 를 도입하였다. JIT Compiler 에 대한 자세한 내용 # Oracle 에서는 JDK 1.3 부터 HotSpot 이라는 가상 머신을 포함한다. 여기에는 C1 이라고 하는 클라이언트 컴파일러와 C2 라고 하는 서버 컴파일러 두 개의 JIT 컴파일러가 포함되어 있다. C1은 더 빠르게 실행되고 조금 덜 최적화 된 코드를 생성하도록 설계되었고, C2 는 실행하는데 시간이 좀 더 소요되지만 더 최적화 된 코드를 생성하도록 설계되었다. Tiered Compilation # JVM은 호출되는 메서드를 추적하고 자주 호출되는 메서드를 C1을 사용하여 컴파일한다. C1으로 컴파일된 메서드의 호출수가 증가하면 C2를 사용하여 한번 더 컴파일한다. 이해를 위해 간단하게 적었지만 세부적인 Compilation Levels 은 다음과 같다: Level 0 – Interpreted Code Level 1 – Simple C1 Compiled Code Level 2 – Limited C1 Compiled Code Level 3 – Full C1 Compiled Code Level 4 – C2 Compiled Code 각 레벨에 대해 더 자세한 내용을 확인하고 싶다면 Compilation Levels을 참고한다. 언제 C1, C2 를 사용하여 컴파일이 일어나는지 궁금하다면 다음 명령어를 통해 임계값을 확인할 수 있다: java -XX:+PrintFlagsFinal -version | grep Threshold | grep Tier openjdk version \u0026#34;17.0.7\u0026#34; 2023-04-18 OpenJDK Runtime Environment Temurin-17.0.7+7 (build 17.0.7+7) OpenJDK 64-Bit Server VM Temurin-17.0.7+7 (build 17.0.7+7, mixed mode, sharing) uintx IncreaseFirstTierCompileThresholdAt = 50 {product} {default} intx Tier2BackEdgeThreshold = 0 {product} {default} intx Tier2CompileThreshold = 0 {product} {default} intx Tier3BackEdgeThreshold = 60000 {product} {default} intx Tier3CompileThreshold = 2000 {product} {default} intx Tier3InvocationThreshold = 200 {product} {default} intx Tier3MinInvocationThreshold = 100 {product} {default} intx Tier4BackEdgeThreshold = 40000 {product} {default} intx Tier4CompileThreshold = 15000 {product} {default} intx Tier4InvocationThreshold = 5000 {product} {default} intx Tier4MinInvocationThreshold = 600 {product} {default} Tier3InvocationThreshold 와 Tier3BackEdgeThreshold, Tier3CompileThreshold 를 살펴보자. 맨 앞의 Tier3는 Level 3 로 컴파일 되기 위한 임계값임을 나타내며 각각의 의미는 다음과 같다: Tier3InvocationThreshold: 메서드 호출 횟수의 임계값을 나타낸다. Tier3BackEdgeThreshold: 백 엣지의 임계값을 나타낸다. Tier3CompileThreshold: 메서드 호출 횟수 임계값과 백 엣지 임계값의 합 백 엣지란, 반복문 등에서 이전 실행한 블록으로 돌아가는 분기 구문을 말한다. 예를들어 for 반복문의 경우 조건을 검사하고 조건문이 참이라면 다시 for 반복문의 블록으로 돌아가게 되는데, 이를 백 엣지라고 한다. 이 페이지에 메서드를 컴파일해야하는지 여부를 판단하기 위한 로직이 설명되어 있으며, 이를 코드로 표현하면 다음과 같다: function shouldCompileMethod(invocationCount, backEdgeCount) { if (invocationCount \u0026gt; Tier3InvocationThreshold) { return true; } if (invocationCount \u0026gt; Tier3MinInvocationThreshold \u0026amp;\u0026amp; invocationCount + backEdgeCount \u0026gt; Tier3CompileThreshold ) { return true; } return false; } 이 로직과 위의 임계값 정보를 바탕으로 메서드를 몇번 호출해야 컴파일이 일어날지 예측해보자. 먼저 위에서 찾은 Tier3 임계값이 다음과 같았다: intx Tier3CompileThreshold = 2000 intx Tier3InvocationThreshold = 200 intx Tier3MinInvocationThreshold = 100 만약 어떤 메서드가 있고, 메서드를 한번 호출할 때마다 20개의 loop back-edge count 를 생성한다고 해보자. 이 메서드는 100번 호출될 때 컴파일 될 것을 예측할 수 있다. (정확한 횟수는 아니므로 테스트는 해봐야 함.) 100 + (20 * 100) \u0026gt; 2000 --- ---------- ---- 1 2 3 1: 메서드 호출 횟수 2: back-edge 3: Tier3CompileThreshold 실제로 최적화가 일어나는지 확인해보고 싶다면 아래의 VM Options 를 추가하여 확인할 수 있다: -XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation 옵션을 추가하고 프로그램을 실행하면 hotspot_pid\u0026lt;pid\u0026gt;.log 형식의 파일이 생성된다. 샘플 코드를 통해 실제로 최적화가 일어나는지 확인해보자: fun main() { val arr = intArrayOf(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) (1..3000).forEach { i -\u0026gt; findMax(arr) if (i % 100 == 0) { // 너무 빨리 종료되면 c2 컴파일이 안될 수도 있어서 Thread.sleep(100) } } } fun findMax(arr: IntArray): Int { var max = arr[0] for (i in 1 until arr.size) { if (max \u0026lt; arr[i]) { max = arr[i] } } return max } 위 프로그램을 실행하면 hotspot_pid\u0026lt;pid\u0026gt;.log 파일이 생긴다. 파일을 열어보면 다음과 같이 level 3 컴파일을 위해 c1 queue 에 메서드가 적재된 것을 확인할 수 있다. \u0026lt;task_queued compile_id=\u0026#39;205\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;228\u0026#39; backedge_count=\u0026#39;2048\u0026#39; iicount=\u0026#39;228\u0026#39; level=\u0026#39;3\u0026#39; stamp=\u0026#39;0.438\u0026#39; comment=\u0026#39;tiered\u0026#39; hot_count=\u0026#39;228\u0026#39;/\u0026gt; count 와 backedge_count 를 통해 메서드가 몇 번 호출되었는지와 백엣지 수를 확인할 수 있다. 조금 더 아래 로그를 살펴보면 다음과 같이 level 3 로 코드 최적화가 된 것을 확인할 수 있다. \u0026lt;nmethod compile_id=\u0026#39;205\u0026#39; compiler=\u0026#39;c1\u0026#39; level=\u0026#39;3\u0026#39; entry=\u0026#39;0x00000208cb1883a0\u0026#39; size=\u0026#39;2560\u0026#39; address=\u0026#39;0x00000208cb188190\u0026#39; relocation_offset=\u0026#39;344\u0026#39; insts_offset=\u0026#39;528\u0026#39; stub_offset=\u0026#39;1872\u0026#39; scopes_data_offset=\u0026#39;2040\u0026#39; scopes_pcs_offset=\u0026#39;2216\u0026#39; dependencies_offset=\u0026#39;2520\u0026#39; nul_chk_table_offset=\u0026#39;2528\u0026#39; oops_offset=\u0026#39;1992\u0026#39; metadata_offset=\u0026#39;2008\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;228\u0026#39; backedge_count=\u0026#39;2048\u0026#39; iicount=\u0026#39;228\u0026#39; stamp=\u0026#39;0.438\u0026#39;/\u0026gt; 마찬가지로 level 4 로 코드가 최적화 된 것도 로그를 통해 확인할 수 있다. \u0026lt;task_queued compile_id=\u0026#39;207\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;2048\u0026#39; backedge_count=\u0026#39;18432\u0026#39; iicount=\u0026#39;2048\u0026#39; stamp=\u0026#39;2.914\u0026#39; comment=\u0026#39;tiered\u0026#39; hot_count=\u0026#39;2048\u0026#39;/\u0026gt; \u0026lt;nmethod compile_id=\u0026#39;207\u0026#39; compiler=\u0026#39;c2\u0026#39; level=\u0026#39;4\u0026#39; entry=\u0026#39;0x00000208d2c30820\u0026#39; size=\u0026#39;1232\u0026#39; address=\u0026#39;0x00000208d2c30690\u0026#39; relocation_offset=\u0026#39;344\u0026#39; insts_offset=\u0026#39;400\u0026#39; stub_offset=\u0026#39;880\u0026#39; scopes_data_offset=\u0026#39;936\u0026#39; scopes_pcs_offset=\u0026#39;1056\u0026#39; dependencies_offset=\u0026#39;1184\u0026#39; handler_table_offset=\u0026#39;1192\u0026#39; nul_chk_table_offset=\u0026#39;1216\u0026#39; oops_offset=\u0026#39;920\u0026#39; metadata_offset=\u0026#39;928\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;2100\u0026#39; backedge_count=\u0026#39;18900\u0026#39; iicount=\u0026#39;2100\u0026#39; stamp=\u0026#39;2.917\u0026#39;/\u0026gt; JIT Compiler 가 정말 성능을 향상시켜주는지 알고 싶다면 -Xint 옵션으로 Jit Compiler 사용을 중지하고 테스트 해 볼 수 있다. 앞에서 살펴본 코드를 조금 변경하여 총 3번 실행해보았다. fun main() { val arr = intArrayOf(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) val startTimeMills = System.currentTimeMillis() (1..1_0000_0000).forEach { i -\u0026gt; findMax(arr) } println(\u0026#34;실행시간: ${System.currentTimeMillis() - startTimeMills}ms\u0026#34;) } fun findMax(arr: IntArray): Int { var max = arr[0]","date":"2023-05-10T23:56:05+09:00","href":"https://disj11.github.io/java-jit-compiler/","objectID":"4658aac5581ac910f876ff199ba0868c_0","order":0,"tags":["development"],"title":"Java JIT Compiler"},{"content":"for (i in 1 until arr.size) { if (max \u0026lt; arr[i]) { max = arr[i] } } return max } JIT Compiler 를 활성화한 경우: 실행시간: 1595ms 실행시간: 875ms 실행시간: 1252ms JIT Compiler 를 비활성화 한 경우: 실행시간: 28558ms 실행시간: 32401ms 실행시간: 24760ms NOTE: spring boot 애플리케이션을 IntelliJ 에서 실행하면 -XX:TieredStopAtLevel=1 이 자동으로 추가된다. 이로 인해 level 1 으로만 컴파일 되는 문제가 있다. (Jetbrains Issue) 정확한 확인을 위해서는 Run/Degub Configurations -\u0026gt; Modify options -\u0026gt; Disabled launch Optimization 옵션을 체크하여 실행해야한다. 참고 자료 # https://www.baeldung.com/jvm-tiered-compilation https://www.baeldung.com/graal-java-jit-compiler https://www.lmax.com/blog/staff-blogs/2016/03/05/observing-jvm-warm-effects/ https://www.oreilly.com/library/view/java-performance-the/9781449363512/ch04.html https://hg.openjdk.org/jdk8/jdk8/hotspot/file/104743074675/src/share/vm/runtime/advancedThresholdPolicy.hpp https://www.youtube.com/watch?v=CQi3SS2YspY\u0026amp;list=PLyGtIjZ_uWKNT5-ob1TL26hH0KVfoJQzw","date":"2023-05-10T23:56:05+09:00","href":"https://disj11.github.io/java-jit-compiler/","objectID":"4658aac5581ac910f876ff199ba0868c_1","order":1,"tags":["development"],"title":"Java JIT Compiler"},{"content":"Glue workflow 사용중 3시간 정도 걸리는 Glue Job 이 발견되었다. Worker 의 수를 10 -\u0026gt; 30 으로 올리니 17분 정도로 드라마틱하게 단축되어 왜 이런 현상이 발생하였는지 찾아보았다. Spark 에는 Shuffle Partition 이란 게 존재한다. join, groupBy 등의 연산을 수행할 때 이 Shuffle Partition 이 사용된다. 이 Shuffle Partition 은 Spark의 성능에 가장 큰 영향을 미치는 Partition 이다. 연산에 쓰이는 메모리가 부족할 때 Shuffle Spill (데이터를 직렬화 하고 스토리지에 저장, 데이터 처리 이후에 역직렬화 후 연산 재개) 이 발생한다. Shuffle Spill 이 일어나면, Task 가 지연되고 에러가 발생할 수 있다. 이 문제를 해결하기 위해서는 Core 당 메모리를 늘려야한다. 참고 사이트: https://aws.amazon.com/ko/blogs/big-data/introducing-amazon-s3-shuffle-in-aws-glue/ https://tech.kakao.com/2021/10/08/spark-shuffle-partition/","date":"2023-05-10T18:58:24+09:00","href":"https://disj11.github.io/shuffle-operation-in-glue/","objectID":"d76ce26aee8040146e22a71588af6dcc_0","order":0,"tags":["TIL","AWS","Glue"],"title":"Shuffle Operation in Glue"},{"content":"SQS 의 Queue type 에는 Standard 와 FIFO 가 있다. Standard queues 는 At-least-once delivery, Best-Effort Ordering 으로 작동한다. At-least-once delivery 는 적어도 한번 메시지가 전달된다는 의미로 같은 메시지가 경우에 따라 두 번 이상 전달될 수 있다. Best-Effort Ordering 은 경우에 따라 메시지의 순서가 보장되지 않는 것을 의미한다. 이러한 특성으로 Standard queues 를 사용하는 어플리케이션은 멱등성(idempotent) 을 보장해야 한다. 높은 처리량이 필요한 어플리케이션에 주로 사용한다. FIFO 는 Exactly-Once Processing, First-In-First-Out Delivery 로 작동한다. 메시지는 정확히 한 번 처리되며 메시지를 보내고 받는 순서가 보장된다. 이벤트 순서가 중요한 어플리케이션에 주로 사용한다. 참고 사이트: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-types.html","date":"2023-05-06T12:55:31+09:00","href":"https://disj11.github.io/sqs-queue-types/","objectID":"109cba42c1c691bccb86eaa42fac11ff_0","order":0,"tags":["TIL","AWS","SQS"],"title":"SQS Queue Types"},{"content":"메인 시퀀스로부터의 거리(Distance from the Main Sequence)는 아키텍처 구조를 평가하는 여러 메트릭 중 하나입니다. 이는 불안정도(instability) 와 추상도(abstractness) 를 이용해 계산되므로, 두 개념을 먼저 이해하는 것이 중요합니다. 추상도 (Abstractness) # 추상도는 모듈 내의 추상 아티팩트(abstract artifact) 와 구상 아티팩트(concrete artifact) 의 비율을 나타내며, 구현 대비 추상화 정도를 측정합니다. 추상 아티팩트에는 추상 클래스나 인터페이스가 포함되며, 구상 아티팩트는 일반 클래스(구현체)를 의미합니다. 추상도를 계산하는 공식은 다음과 같습니다: $$ A = \\frac{M^a}{M^a + M^c} $$여기서: \\(M^a\\): 모듈 내 추상 요소(인터페이스 또는 추상 클래스)의 수 \\(M^c\\): 모듈 내 구상 요소(일반 클래스)의 수 추상도의 값은 0에서 1 사이에 위치하며, 1에 가까울수록 해당 모듈이 완전히 추상적임을 의미합니다. 예를 들어, 5,000 라인의 코드를 모두 main() 메서드에 구현한 애플리케이션은 구상 요소만 포함하고 있으므로 추상도는 0에 가깝습니다. 불안정도 (Instability) # 불안정도는 코드의 변동 가능성(volatility)을 나타내며, 원심 커플링(efferent coupling)과 구심 커플링(afferent coupling)의 비율로 계산됩니다. 공식은 다음과 같습니다: $$ I = \\frac{C^e}{C^a + C^e} $$여기서: \\(C^e\\): 원심 커플링(다른 코드 아티팩트로 유출되는 의존성의 수) \\(C^a\\): 구심 커플링(다른 코드 아티팩트로부터 유입되는 의존성의 수) 불안정도의 값 역시 0에서 1 사이에 위치하며, 값이 1에 가까울수록 해당 모듈이 외부 의존성이 많아 변동 가능성이 높음을 의미합니다. 예를 들어, 여러 클래스를 호출하는 클래스는 호출된 메서드 중 하나라도 변경될 경우 해당 클래스가 영향을 받을 가능성이 높아 불안정도가 높다고 볼 수 있습니다. 메인 시퀀스로부터의 거리 (Distance from the Main Sequence) # 메인 시퀀스로부터의 거리는 불안정도와 추상도를 결합하여 계산되며, 다음 공식을 사용합니다: $$ D = |A + I - 1| $$여기서: \\(A\\): 추상도 \\(I\\): 불안정도 이 값은 항상 0에서 1 사이에 위치하며, 값이 작을수록 해당 모듈이 이상적인 균형 상태에 가까움을 나타냅니다. 이를 시각적으로 표현하면 다음과 같은 그래프가 됩니다: x축: 불안정도 (\\(I\\)) y축: 추상도 (\\(A\\)) 메인 시퀀스: \\(A + I = 1\\)을 만족하는 선 메인 시퀀스에 가까운 모듈일수록 추상화와 안정성 간의 균형이 잘 이루어진 상태입니다. 쓸모없는 구역과 고통스러운 구역 # 그래프에서 메인 시퀀스로부터 멀어진 영역은 두 가지로 나뉩니다: 쓸모없는 구역 (Zone of Uselessness): 그래프의 오른쪽 위에 위치하며, 지나치게 높은 추상도로 인해 실제 구현에서 사용하기 어려운 코드를 나타냅니다. 고통스러운 구역 (Zone of Pain): 그래프의 왼쪽 아래에 위치하며, 거의 추상화되지 않은 상태로 인해 취약하고 유지보수가 어려운 코드를 나타냅니다. 따라서 메인 시퀀스와의 거리를 줄이는 것이 코드 품질과 유지보수성을 높이는 데 중요한 목표가 됩니다.","date":"2023-03-12T14:09:09+09:00","href":"https://disj11.github.io/distance-from-the-main-sequence/","objectID":"0b2a90ca1841f6eeb373c950ccca4592_0","order":0,"tags":["software engineering"],"title":"메인 시퀀스로부터의 거리: 추상도와 불안정도를 활용한 아키텍처 평가"},{"content":"응집 (Cohesion) # 응집은 소프트웨어 모듈 내 구성 요소들이 얼마나 밀접하게 연관되어 있는지를 나타내는 개념으로, 높은 응집도는 모듈의 독립성과 유지보수성을 높이는 데 기여합니다. 응집은 여러 유형으로 나뉘며, 각 유형은 모듈 내 구성 요소들의 관계와 협력 방식을 기준으로 정의됩니다. 아래에서는 각 응집 유형을 예시와 함께 설명합니다. 1. 기능적 응집 (Functional Cohesion) # 모듈 내 모든 구성 요소가 단일한 목적을 위해 협력하며, 특정 작업을 완벽히 수행하기 위해 필요한 모든 기능이 포함된 경우입니다. 이는 가장 이상적인 응집 형태로 간주됩니다. 예시: 계산기 프로그램에서 사각형의 넓이와 둘레를 계산하는 모듈은 입력값(가로, 세로)을 받아 넓이와 둘레를 계산한 후 결과를 반환합니다. 이 모듈은 단일 작업(사각형 계산)에 집중되어 있어 기능적 응집을 가집니다. 2. 순차적 응집 (Sequential Cohesion) # 모듈 내 구성 요소들이 순차적으로 실행되며, 하나의 구성 요소 출력이 다음 구성 요소의 입력으로 사용되는 경우입니다. 예시: 데이터 처리 파이프라인을 생각해볼 수 있습니다. 예를 들어, 파일에서 데이터를 읽고 → 데이터를 정제하고 → 정제된 데이터를 데이터베이스에 저장하는 작업이 순서대로 이루어지는 모듈은 순차적 응집을 가집니다. 3. 소통적 응집 (Communicational Cohesion) # 모듈 내 구성 요소들이 공통 데이터를 사용하거나 동일한 데이터를 기반으로 작업하는 경우입니다. 예시: 고객의 장바구니 데이터를 처리하는 모듈에서는 장바구니 데이터를 기반으로 할인 계산, 배송비 계산, 세금 계산 등의 작업이 이루어질 수 있습니다. 이처럼 구성 요소들은 서로 다른 작업을 수행하지만, 동일한 데이터를 공유하며 협력합니다. 4. 절차적 응집 (Procedural Cohesion) # 구성 요소들이 특정 절차나 순서를 따라 실행되도록 그룹화된 경우입니다. 이는 순차적 응집과 유사하지만, 반드시 동일한 데이터를 다루지 않을 수도 있습니다. 예시: 사용자 인증 모듈에서 사용자의 자격 증명을 확인하고 → 액세스 토큰을 생성하며 → 사용자 활동 로그를 업데이트하는 과정은 절차적 응집의 예입니다. 5. 일시적 응집 (Temporal Cohesion) # 모듈 내 구성 요소들이 특정 시간이나 이벤트에 따라 함께 실행되는 경우입니다. 예시: 시스템 초기화 시, 로그 파일 생성, 설정 파일 로드, 캐시 초기화 등 서로 연관성이 없어 보이는 작업들이 동시에 실행된다면 이는 일시적 응집에 해당합니다. 6. 논리적 응집 (Logical Cohesion) # 구성 요소들이 기능적으로 연관되기보다는 논리적인 범주에 따라 그룹화된 경우입니다. 예시: 자바의 StringUtils 클래스처럼 문자열 관련 다양한 정적 메서드(문자열 대소문자 변환, 문자열 자르기 등)가 포함된 경우입니다. 이들은 논리적으로는 관련이 있지만, 기능적으로는 독립적입니다. 7. 동시적 응집 (Coincidental Cohesion) # 모듈 내 구성 요소들이 단순히 같은 소스 파일에 포함되어 있을 뿐, 서로 아무런 연관성이 없는 경우입니다. 이는 가장 낮은 수준의 응집도로 간주됩니다. 예시: 한 모듈에 문자열 출력 함수와 리스트 정렬 함수가 함께 포함되어 있다면 이는 동시적 응집의 예로 볼 수 있습니다. 이러한 설계는 유지보수성과 재사용성을 저하시킵니다. LCOM (Lack of Cohesion in Methods) # 코드의 응집도를 정량적으로 평가하기 위해 LCOM(Lack of Cohesion in Methods) 메트릭을 사용할 수 있습니다. 이는 클래스 내 메서드들이 공유 필드를 얼마나 활용하는지 분석하여 응집도를 측정합니다. LCOM 활용 예: 클래스 X, Y, Z 비교 # 이미지에 나타난 클래스 X, Y, Z는 LCOM(Lack of Cohesion in Methods, 메서드 간 응집 결여도)을 계산하고 이해하는 데 유용한 사례를 제공합니다. 각 클래스의 구조를 분석하여 응집도를 평가해보겠습니다. 1. 클래스 X # 구성: 필드 A, B, C (육각형) 메서드 m1(), m2(), m3() (사각형) 각 메서드는 여러 필드를 공유하며 서로 연결되어 있습니다. 분석: 클래스 X는 모든 필드(A, B, C)가 여러 메서드(m1(), m2(), m3())에 의해 공유되고 사용됩니다. 이는 메서드와 필드가 서로 밀접하게 연관되어 있음을 나타냅니다. LCOM 평가: LCOM 점수가 낮습니다(즉, 응집도가 높음). 이는 클래스가 단일한 목적을 가지고 있으며, 메서드들이 협력하여 작업을 수행한다는 것을 보여줍니다. 2. 클래스 Y # 구성: 필드 A, B, C 메서드 m1(), m2(), m3() 각 필드는 오직 하나의 메서드에서만 사용됩니다. 분석: 클래스 Y에서는 각 메서드가 특정 필드만 사용하며 다른 필드나 메서드와 상호작용하지 않습니다. 이는 메서드들이 독립적으로 작동한다는 것을 의미합니다. LCOM 평가: LCOM 점수가 매우 높습니다(즉, 응집도가 낮음). 이 경우 클래스 Y는 단일 클래스로 유지할 필요가 없으며, 각 필드와 관련된 메서드를 별도의 클래스로 분리하는 것이 더 바람직합니다. 3. 클래스 Z # 구성: 필드 A, B, C 메서드 m1(), m2(), m3() 일부 메서드는 여러 필드를 공유하며 상호작용하지만, 특정 필드는 독립적으로 사용됩니다. 분석: 클래스 Z는 일부 메서드와 필드가 서로 연관되어 있지만, 다른 구성 요소들은 독립적으로 작동합니다. 이는 클래스 내에서 응집도가 부분적으로 유지되고 있음을 나타냅니다. LCOM 평가: LCOM 점수는 중간 수준입니다. 독립적인 구성 요소(예: C와 관련된 m3())를 별도의 클래스로 분리하면 응집도를 향상시킬 수 있습니다. 결론 # 클래스 X는 높은 응집도를 가지며 잘 설계된 구조입니다. 클래스 Y는 낮은 응집도를 가지며, 리팩토링을 통해 각 필드와 관련된 메서드를 별도의 클래스로 분리하는 것이 적합합니다. 클래스 Z는 부분적으로 응집되어 있으며, 독립적인 구성 요소를 분리하여 개선할 여지가 있습니다. 이처럼 LCOM 분석은 클래스의 구조적 결함을 식별하고 설계를 개선하는 데 유용한 도구로 활용될 수 있습니다. 결론 # 응집도는 소프트웨어 설계 품질을 평가하는 중요한 척도이며, 높은 응집도를 유지하는 것이 바람직합니다. 각 유형의 응집을 이해하고 이를 설계에 적용함으로써 더 나은 모듈화와 유지보수성을 달성할 수 있습니다.","date":"2023-03-12T11:41:11+09:00","href":"https://disj11.github.io/cohesion-in-software-engineering/","objectID":"a35cbd56dc52fb38d6b50c76480a89b6_0","order":0,"tags":["software engineering"],"title":"소프트웨어 응집도와 LCOM: 이해와 활용"},{"content":"확장성 # 확장성은 시스템이 증가하는 부하에 효과적으로 대처할 수 있는 능력을 설명하는 데 사용되는 용어입니다. 하지만 \u0026ldquo;X는 확장 가능하다\u0026rdquo; 또는 \u0026ldquo;Y는 확장성이 없다\u0026quot;라는 표현은 구체적인 의미를 전달하기 어렵습니다. 확장성을 논의한다는 것은 \u0026ldquo;시스템이 커진다면 이에 대처하기 위한 선택은 무엇인가?\u0026rdquo; 그리고 \u0026ldquo;추가 부하를 처리하기 위해 자원을 어떻게 투입할 것인가?\u0026rdquo; 와 같은 구체적인 질문을 고려한다는 뜻입니다. 확장성을 평가하려면 시스템이 증가하는 부하에 어떻게 반응하는지, 이를 해결하기 위해 어떤 전략을 사용할 수 있는지를 명확히 이해해야 합니다. 특히, 수직적 확장(scale-up)과 수평적 확장(scale-out)의 차이를 이해하는 것이 중요합니다. 수직적 확장(scale-up): 기존 시스템의 성능을 높이기 위해 더 강력한 하드웨어를 추가하거나 업그레이드하는 방식입니다. 예를 들어, 더 빠른 CPU나 더 많은 메모리를 추가하는 것이 이에 해당합니다. 수평적 확장(scale-out): 여러 대의 시스템을 추가하여 부하를 분산시키는 방식입니다. 예를 들어, 웹 서버를 여러 대로 늘리고 로드 밸런서를 통해 트래픽을 분산시키는 방법이 있습니다. 각 방법에는 장단점이 있으며, 상황에 따라 적합한 전략을 선택해야 합니다. 부하 기술하기 # 확장성을 논의하려면 현재 시스템의 부하를 간결하고 명확하게 기술해야 합니다. 이를 통해 \u0026ldquo;부하가 두 배로 증가하면 어떤 일이 발생할까?\u0026rdquo; 와 같은 시나리오를 분석할 수 있습니다. 부하는 부하 매개변수(load parameter) 라는 몇 가지 숫자로 표현됩니다. 시스템마다 적합한 부하 매개변수는 다르지만, 일반적으로 다음과 같은 항목들이 포함됩니다: 웹 서버의 초당 요청 수 데이터베이스의 읽기 대 쓰기 비율 동시 활성 사용자(active user) 수 캐시 적중률(cache hit rate) 이러한 매개변수는 평균적인 상황을 나타낼 수도 있지만, 때로는 극단적인 경우(예: 피크 타임, 병목 현상)가 시스템 성능에 더 큰 영향을 미칠 수 있습니다. 따라서 평균뿐만 아니라 극단적인 상황도 함께 고려해야 합니다. 예를 들어, 대규모 전자상거래 플랫폼에서는 초당 요청 수와 동시 활성 사용자가 중요한 부하 매개변수가 될 수 있습니다. 반면, 스트리밍 서비스에서는 캐시 적중률과 네트워크 대역폭 사용량이 주요 지표가 될 것입니다. 성능 기술하기 # 부하를 정의한 후에는 부하가 증가했을 때 시스템 성능이 어떻게 변화하는지 조사할 필요가 있습니다. 이를 위해 다음과 같은 질문을 던질 수 있습니다: 부하 매개변수를 증가시키고 자원(CPU, 메모리, 네트워크 대역폭)은 그대로 유지하면 성능에 어떤 영향을 미칠까요? 부하 매개변수를 증가시키면서 성능을 유지하려면 자원을 얼마나 추가해야 할까요? 이 질문들에 답하려면 시스템 성능을 측정하고 평가할 수 있는 지표가 필요합니다. 주요 성능 지표 # 일괄 처리 시스템(batch processing system): 주로 처리량(throughput) 에 관심을 둡니다. 예: 초당 처리 가능한 레코드 수 또는 일정 크기의 데이터 집합을 처리하는 데 걸리는 시간. 온라인 시스템(online system): 주로 응답 시간(response time) 에 관심을 둡니다. 응답 시간은 클라이언트가 요청을 보내고 응답을 받기까지 걸리는 시간으로 정의됩니다. 응답 시간은 고정된 값이 아니라 요청마다 변동될 수 있으므로, 단일 숫자가 아닌 분포(distribution) 로 이해해야 합니다. 응답 시간 분석 # 평균 응답 시간은 전체적인 경향을 파악하기에는 유용하지만, 실제 사용자 경험을 정확히 반영하지 못할 수 있습니다. 이는 평균값이 극단적인 값(특이 값, outlier)에 의해 왜곡될 가능성이 있기 때문입니다. 따라서 평균 대신 백분위(percentile) 를 사용하는 것이 더 적합합니다. 중앙값(median): 응답 시간을 빠른 순서대로 정렬했을 때 중간값으로, 50%의 요청이 이 시간 이하로 처리됨을 의미합니다. 상위 백분위: 95분위(p95), 99분위(p99), 99.9분위(p999) 등이 자주 사용됩니다. 예: 95분위 응답 시간이 1.5초라면, 100개의 요청 중 95개는 1.5초 이내에 처리되고 나머지 5개는 더 오래 걸린다는 뜻입니다. 꼬리 지연 시간(Tail Latency) # 꼬리 지연 시간은 상위 백분위에서 나타나는 높은 응답 시간을 의미하며, 이는 사용자 경험에 큰 영향을 미칩니다. 예를 들어, 대부분의 요청이 빠르게 처리되더라도 일부 요청에서 지나치게 긴 응답 시간이 발생하면 사용자는 서비스가 느리다고 느낄 수 있습니다. 따라서 꼬리 지연 시간을 줄이는 것은 고품질 서비스를 제공하는 데 중요한 요소입니다. 효율적 확장을 위한 전략 # 확장성과 관련하여 단순히 자원을 추가하는 방식 외에도 효율적으로 자원을 활용하거나 최적화하는 방법도 중요합니다. 다음과 같은 전략들이 유용할 수 있습니다: 캐싱 전략 강화: 자주 조회되는 데이터를 캐시에 저장하여 데이터베이스 조회 부담을 줄입니다. 데이터베이스 쿼리 최적화: 쿼리 실행 계획을 개선하거나 인덱스를 추가하여 데이터베이스 성능을 향상시킵니다. 로드 밸런싱: 트래픽을 여러 서버로 분산시켜 병목 현상을 방지합니다. 비동기 처리: 시간이 오래 걸리는 작업은 비동기로 처리하여 주요 작업 흐름의 응답 시간을 단축합니다. 또한, 부하와 성능 간 관계를 시각적으로 표현한 그래프나 도표를 활용하면 문제를 분석하고 해결책을 설계하는 데 큰 도움이 됩니다. 위 내용을 바탕으로 확장성과 관련된 논의를 진행하면 보다 체계적이고 실질적인 접근이 가능할 것입니다.","date":"2023-02-05T12:15:15+09:00","href":"https://disj11.github.io/what-you-need-to-know-first-for-scalability/","objectID":"4a0cc8ecd24023d79932941231a36c42_0","order":0,"tags":["development"],"title":"확장성과 성능 최적화: 시스템 부하와 효율적인 대처 전략"},{"content":"Windows 초기 설정 # Windows 최초 설치 후 설정 정리 날개셋 한글 입력기 설치 # 세벌식 유저이므로 날개셋 한글 입력기를 다운받는다. vim 유저이므로 ESC 누를 시 영문으로 전환하는 기능을 설정한다. 설정 방법은 아래 이미지를 참고한다. PowerToys # Microsoft Store 에서 Microsoft PowerToys 를 찾아 설치한다. Scoop # scoop 을 다운 받는다. Set-ExecutionPolicy RemoteSigned -Scope CurrentUser # Optional: Needed to run a remote script the first time irm get.scoop.sh | iex Git # Git 을 다운 받는다. scoop install git VIM # gvim 을 다운받는다. 설치 시 Create .bat files 를 체크한다. 이 옵션을 체크하면 명령 프롬프트에서 vim 명령 사용이 가능해진다. vim-plug 를 설치한다. powershell 을 실행하여 다음 명령어를 입력한다. iwr -useb https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim |` ni $HOME/vimfiles/autoload/plug.vim -Force _vimrc 파일을 작성한다. C:\\Users\\사용자계정 위치에 _vimrc 파일을 생성한 뒤 다음 내용을 입력한다. let mapleader=\u0026#34; \u0026#34; set encoding=UTF-8 set rtp+=/opt/homebrew/opt/fzf set number set showcmd set incsearch set ignorecase set scrolloff=5 set clipboard^=unnamed,unnamedplus set smartindent set expandtab set tabstop=4 set shiftwidth=4 set softtabstop=4 map \u0026lt;Home\u0026gt; ^ map \u0026lt;End\u0026gt; $ nnoremap \u0026lt;leader\u0026gt;ca ggVG \u0026#34; vim-plug call plug#begin() Plug \u0026#39;ryanoasis/vim-devicons\u0026#39; Plug \u0026#39;joshdick/onedark.vim\u0026#39; Plug \u0026#39;vim-airline/vim-airline\u0026#39; Plug \u0026#39;vim-airline/vim-airline-themes\u0026#39; Plug \u0026#39;terryma/vim-multiple-cursors\u0026#39; Plug \u0026#39;preservim/nerdtree\u0026#39; Plug \u0026#39;easymotion/vim-easymotion\u0026#39; Plug \u0026#39;tpope/vim-commentary\u0026#39; Plug \u0026#39;tpope/vim-surround\u0026#39; call plug#end() syntax on colorscheme onedark let g:airline_theme=\u0026#39;onedark\u0026#39; let NERDTreeMapOpenVSplit=\u0026#39;s\u0026#39; let NERDTreeMapPreviewVSplit=\u0026#39;gs\u0026#39; let NERDTreeMapOpenSplit=\u0026#39;S\u0026#39; let NERDTreeMapPreviewSplit=\u0026#39;gS\u0026#39; nnoremap \u0026lt;leader\u0026gt;e :NERDTreeToggle\u0026lt;CR\u0026gt; nnoremap \u0026lt;leader\u0026gt;E :NERDTreeFind\u0026lt;CR\u0026gt; nmap \u0026lt;leader\u0026gt;- :split\u0026lt;CR\u0026gt; nmap \u0026lt;leader\u0026gt;\\| :vsplit\u0026lt;CR\u0026gt; nmap \u0026lt;leader\u0026gt;qq :qall\u0026lt;CR\u0026gt; nmap \u0026lt;leader\u0026gt;/ \u0026lt;Plug\u0026gt;(easymotion-bd-fn) nmap \u0026lt;leader\u0026gt;n \u0026lt;Plug\u0026gt;(easymotion-next) nmap \u0026lt;leader\u0026gt;N \u0026lt;Plug\u0026gt;(easymotion-prev) nmap \u0026lt;leader\u0026gt;j \u0026lt;Plug\u0026gt;(easymotion-j) nmap \u0026lt;leader\u0026gt;k \u0026lt;Plug\u0026gt;(easymotion-k) nmap gsa ysiw nmap gsd ds nmap gsr cs vmap gsa S if has(\u0026#39;gui_running\u0026#39;) set guifont=JetBrainsMono\\ Nerd\\ Font\\ Mono:h13 endif \u0026#34; intellij if has(\u0026#39;ide\u0026#39;) set ideajoin set quickscope nmap \u0026lt;leader\u0026gt;uw \u0026lt;Action\u0026gt;(HideAllWindows) nmap \u0026lt;leader\u0026gt;ft \u0026lt;Action\u0026gt;(ActivateTerminalToolWindow) nmap \u0026lt;leader\u0026gt;* \u0026lt;Action\u0026gt;(FindUsages) nmap \u0026lt;leader\u0026gt;gg \u0026lt;Action\u0026gt;(Git.Branches) nmap gd \u0026lt;Action\u0026gt;(GotoDeclaration) nmap gI \u0026lt;Action\u0026gt;(GotoImplementation) nmap ]m \u0026lt;Action\u0026gt;(MethodDown) nmap [m \u0026lt;Action\u0026gt;(MethodUp) nmap ]e \u0026lt;Action\u0026gt;(GotoNextError) nmap ]E \u0026lt;Action\u0026gt;(GotoPreviousError) nmap \u0026lt;leader\u0026gt;sd \u0026lt;Action\u0026gt;(QuickJavaDoc) nmap \u0026lt;leader\u0026gt;be \u0026lt;Action\u0026gt;(RecentFiles) nmap \u0026lt;leader\u0026gt;ff \u0026lt;Action\u0026gt;(GotoFile) nmap \u0026lt;leader\u0026gt;fn \u0026lt;Action\u0026gt;(NewFile) nmap \u0026lt;leader\u0026gt;sg \u0026lt;Action\u0026gt;(FindInPath) nmap \u0026lt;leader\u0026gt;cf \u0026lt;Action\u0026gt;(ReformatCode) nmap \u0026lt;leader\u0026gt;ca \u0026lt;Action\u0026gt;(Generate) nmap \u0026lt;leader\u0026gt;cr \u0026lt;Action\u0026gt;(RenameElement) nmap \u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextWholeOccurrence xmap \u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextWholeOccurrence nmap g\u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextOccurrence xmap g\u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextOccurrence nmap \u0026lt;C-x\u0026gt; \u0026lt;Plug\u0026gt;SkipOccurrence xmap \u0026lt;C-x\u0026gt; \u0026lt;Plug\u0026gt;SkipOccurrence nmap \u0026lt;C-p\u0026gt; \u0026lt;Plug\u0026gt;RemoveOccurrence xmap \u0026lt;C-p\u0026gt; \u0026lt;Plug\u0026gt;RemoveOccurrence nmap \u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllWholeOccurrences xmap \u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllWholeOccurrences nmap g\u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllOccurrences xmap g\u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllOccurrences endif vim 플러그인을 설치한다. powershell 을 관리자 권한으로 실행한다. vim 명령을 입력 후 vim 으로 진입한다. :PlugInstall 명령어를 통해 플러그인을 설치한다. Nerd Fonts 에서 JetBrainsMono Nerd Font 를 설치한다. 압축 해제하면 여러 개의 파일이 나오는데, JetBrains Mono Regular Nerd Font Complete Mono Windows Compatible 만 설치해도 된다. SDKMAN # 자바 버전 관리를 편하게 하기 위해 sdkman 을 설치한다. scoop bucket add palindrom615 https://github.com/palindrom615/scoop-bucket scoop install sdkman JDK # sdkman 을 사용하여 설치하고 싶은 자바를 선택하여 설치한다. sdk list java 명령어로 자바 버전을 확인할 수 있다. IntelliJ # JetBrains Toolbox App 을 설치한다. 이후 ToolBox App 에서 Intellij IDEA Ultimate 를 설치한다. IntelliJ 설치가 완료되면 아래의 플러그인을 설치한다. IdeaVim IdeaVim-EasyMotion IdeaVim-Quickscope 이외에 필요한 플러그인이 있다면, 추가적으로 설치한다. (Kotest 플러그인 등) 이후 vim 과 동일한 키 설정을 사용하기 하기 위해 .ideavimrc 에 다음 내용을 추가한다. source ~/_vimrc 개발 시 JDK 가 필요하다면 SDK 에 JDK 설치 경로를 추가한다. SDKMAN 으로 설치한 JDK 는 ~/.sdkman 위치에서 찾을 수 있다. Etc. # Hugo # 개인 블로그 개발 환경을 위해 hugo 설치 scoop install hugo-extended","date":"2023-01-30T09:10:13+09:00","href":"https://disj11.github.io/notes/windows-initial-setup/","objectID":"b73afb709007eb214f049c0b08270fc4_0","order":0,"tags":["settings"],"title":"Windows Initial Setup"},{"content":"Kotlin provides extension functions for the Iterable interface, such as the filter function. Here is an example of using the filter function: fun averageNonBlankLength(strings: List\u0026lt;String\u0026gt;): Double = strings .filter { it.isNotBlank() } .map(String::length) .sum() / strings.size.toDouble() It\u0026rsquo;s worth noting that the filter and map functions in Kotlin return new Lists, unlike their counterparts Stream.filter and Stream.map in Java, which return a Stream. In this example, two new intermediate lists are created in memory as the result of calling filter and map on the original list. However, this overhead may not be significant depending on the size of the original list and the complexity of the operations. If the size of the original list or complexity of the operation chain is high and memory usage is a concern, you might consider using sequence type instread of List . you can convert a list to a sequence via asSequence() function which will create a lazy sequence and perform operations on it. Another option is to use the sequenceOf(list) function which will create a sequence from the list. Here\u0026rsquo;s an example of using the sequence type to perform the same operation as the previous example: fun averageNonBlankLength(strings: List\u0026lt;String\u0026gt;): Double = strings.asSequence() .filter { it.isNotBlank() } .map(String::length) .sum() / strings.size.toDouble() In this example, the asSequence() function is used to convert the original List of strings to a Sequence of strings. Then, the filter and map functions are used to perform the same operations as before, but instead of creating intermediate Lists, a Sequence is returned from each function call. It\u0026rsquo;s worth noting that using a sequence allows for lazy evaluation, meaning that the elements of the sequence are only evaluated as they are needed, this can help to reduce the memory usage. Using a sequence can be beneficial when memory efficiency is a concern, particularly in situations where the size of the result set of data is not known ahead of time or when the operations are complex and intermediate results are unnecessary to be stored in memory. This is how the list processing goes: The sequence processing goes like this: If you would like to learn more about the sequence type in Kotlin, you can refer to the official documentation","date":"2023-01-10T23:59:43+09:00","href":"https://disj11.github.io/en/memory-efficient-iterable-data-processing-with-sequences/","objectID":"9196b793888e6c55f42104278dbfd7ea_0","order":0,"tags":["kotlin"],"title":"Kotlin: Memory Efficient Iterable Data Processing with Sequences"},{"content":"Kotlin의 Iterable과 Sequence는 컬렉션을 처리하는 두 가지 주요 방식으로, 각기 다른 평가 전략과 성능 특성을 가집니다. 이 글에서는 두 방식의 차이점을 중심으로, 각각의 장단점과 적합한 사용 사례를 설명합니다. Iterable vs Sequence: 평가 방식의 차이 # 1. 즉시 평가 (Eager Evaluation) - Iterable # Iterable은 각 처리 단계에서 전체 컬렉션에 대해 연산을 수행하며, 중간 결과를 새로운 컬렉션으로 반환합니다. 이 방식은 각 단계가 독립적으로 실행되므로 직관적이고 간단하지만, 중간 결과로 인해 메모리 사용량이 증가할 수 있습니다. 작동 방식 # 각 연산(filter, map 등)이 전체 컬렉션에 대해 실행됩니다. 중간 결과로 새로운 리스트가 생성됩니다. 모든 작업이 완료된 후 최종 결과를 얻습니다. 예를 들어, 다음 코드는 Iterable 방식으로 작동합니다: val words = \u0026#34;The quick brown fox jumps over the lazy dog\u0026#34;.split(\u0026#34; \u0026#34;) val lengthsList = words.filter { println(\u0026#34;filter: $it\u0026#34;); it.length \u0026gt; 3 } .map { println(\u0026#34;length: ${it.length}\u0026#34;); it.length } .take(4) println(\u0026#34;Lengths of first 4 words longer than 3 chars:\u0026#34;) println(lengthsList) 출력 결과: filter: The filter: quick filter: brown filter: fox filter: jumps filter: over filter: the filter: lazy filter: dog length: 5 length: 5 length: 5 length: 4 Lengths of first 4 words longer than 3 chars: [5, 5, 5, 4] 위 예제에서 볼 수 있듯이, filter와 map 연산은 모든 요소에 대해 수행되고, 중간 리스트가 생성됩니다. 2. 지연 평가 (Lazy Evaluation) - Sequence # Sequence는 연산을 필요할 때까지 미루며, 각 요소에 대해 연산 체인을 순차적으로 적용합니다. 이는 중간 결과를 저장하지 않으므로 메모리 효율성이 높아지고, 불필요한 계산을 피할 수 있습니다. 작동 방식 # 각 요소가 처리 체인을 통과하며 필요한 만큼만 계산됩니다. 중간 리스트를 생성하지 않습니다. 최종 결과를 요청하는 시점(터미널 연산)에서 계산이 수행됩니다. 다음 코드는 동일한 작업을 Sequence로 처리하는 방법입니다: val words = \u0026#34;The quick brown fox jumps over the lazy dog\u0026#34;.split(\u0026#34; \u0026#34;) val lengthsSequence = words.asSequence() .filter { println(\u0026#34;filter: $it\u0026#34;); it.length \u0026gt; 3 } .map { println(\u0026#34;length: ${it.length}\u0026#34;); it.length } .take(4) println(\u0026#34;Lengths of first 4 words longer than 3 chars:\u0026#34;) println(lengthsSequence.toList()) 출력 결과: Lengths of first 4 words longer than 3 chars: filter: The filter: quick length: 5 filter: brown length: 5 filter: fox filter: jumps length: 5 filter: over length: 4 [5, 5, 5, 4] 여기서 볼 수 있듯이, Sequence는 필요한 만큼만 데이터를 처리하며 불필요한 연산을 피합니다. 성능 비교 # 1. 작은 데이터셋 # 작은 크기의 컬렉션에서는 Iterable이 더 유리할 수 있습니다. 즉시 평가 방식은 CPU 캐시 활용성이 높아 간단한 작업에서는 더 빠르게 동작합니다. 2. 큰 데이터셋 # 큰 데이터셋이나 복잡한 연산 체인에서는 Sequence가 더 적합합니다. 중간 결과를 저장하지 않고 필요한 만큼만 계산하므로 메모리 사용량과 성능 면에서 효율적입니다. 예제 비교 # Iterable: 모든 요소를 처리하고 중간 리스트를 생성. Sequence: 필요한 요소까지만 계산하고 중간 리스트 생성을 피함. 실제 벤치마크에 따르면, 큰 데이터셋에서 Sequence는 수백 배 더 빠른 성능을 보일 수 있습니다. 사용 시점 # 상황 추천 방식 단순하고 작은 데이터셋 Iterable 복잡한 연산 체인 또는 큰 데이터셋 Sequence 중간 결과 저장 필요 Iterable 불필요한 계산 최소화 필요 Sequence 결론 # Kotlin의 Iterable과 Sequence는 각각 다른 방식으로 컬렉션을 처리하며, 적절한 선택은 작업의 특성과 데이터 크기에 따라 달라집니다. 작은 데이터셋이나 간단한 작업에는 Iterable, 메모리 효율성과 성능 최적화가 중요한 경우에는 Sequence를 사용하는 것이 좋습니다. 이러한 차이를 이해하고 적절히 활용하면 더 효율적인 Kotlin 코드를 작성할 수 있습니다. 참고자료: https://kotlinlang.org/docs/sequences.html https://proandroiddev.com/sequences-x-iterable-in-kotlin-b5df65cad2d2?gi=59a6e33d99d9 https://stackoverflow.com/questions/35629159/kotlins-iterable-and-sequence-look-exactly-same-why-are-two-types-required/35630670 https://kt.academy/article/ek-sequence","date":"2023-01-10T23:59:43+09:00","href":"https://disj11.github.io/memory-efficient-iterable-data-processing-with-sequences/","objectID":"b0b2647497d39a8d7b5016846e7ddd3b_0","order":0,"tags":["kotlin"],"title":"효율적인 Kotlin 컬렉션 처리: Iterable과 Sequence의 차이점과 활용법"},{"content":"확장 함수(extension functions)의 수신 객체는 매개변수이기 때문에 null 값이 허용된다. anObject.method() 와 anObject.extensionFunction() 는 비슷해 보일 수 있지만 사실은 그렇지 않다. anObject가 null인 경우, method() 는 호출될 수 없지만 anObject.extensionFunction()은 호출될 수 있다. 다음 예제를 살펴보자: fun String?.extensionFunction() = this?.length fun main() { val str: String? = null println(str.extensionFunction()) // prints \u0026#39;null\u0026#39; } 이 예제에서 확장 함수 내에서 this 를 사용할 때 타입 안전 연산자(safe call operator)를 사용하고 있다. 이 코드에는 단점이 하나 있는데, 바로 null을 반환할 수 있다는 것이다. 이런 경우 이 함수를 사용할 때 다음과 같은 예외 처리가 필요할 것이다: val str: String = \u0026#34;Some text\u0026#34; val length = str.extensionFunction() ?: error(\u0026#34;Should never happen\u0026#34;) 하지만 코드를 사용하는 곳에서 extensionFunction() 이 확장 함수라는 것을 인지하지 못한다면 예외 처리를 하지 못할 수도 있다. 이런 경우 버그 발생의 여지가 있다. 따라서 null이 가능한 수신 객체를 사용할 경우에는 null을 반환하지 않는 것이 좋다. null을 반환하는 확장 함수가 필요한 경우, 해당 확장 함수를 non-nullable 유형의 확장으로 정의하고, 호출할 때 타입 안전 연산자를 사용하는 것이 좋다. 다음 코드를 참고하자: fun String.extensionFunction(): Int? { return // ... } val length = str?.extensionFunction() 확장 함수에 대해 궁금한 점이 있다면 공식 문서 더 많은 정보를 확인할 수 있다.","date":"2023-01-08T21:22:27+09:00","href":"https://disj11.github.io/nullable-receiver-in-extension-functions-of-kotlin/","objectID":"13b0cf36b526654795d8d3c931abfea3_0","order":0,"tags":["kotlin"],"title":"Kotlin: 확장 함수의 수신 객체"},{"content":"The receiver object in extension functions allows null values because it is actually a parameter. At first glance, anObject.method() and anObject.extensionFunction() may look similar, but this is not the case. If anObject is null, the method() will never be called, but the extensionFunction() can still be called. Here is an example: fun String?.extensionFunction() = this?.length fun main() { val str: String? = null println(str.extensionFunction()) // prints \u0026#39;null\u0026#39; } In this example, when using this inside an extension function, note that the safe call operator should be used. This code has a disadvantage: it may return null. In these cases, we should write code like the following: val str: String = \u0026#34;Some text\u0026#34; val length = str.extensionFunction() ?: error(\u0026#34;Should never happen\u0026#34;) If the surrounding code changes, it could cause a bug to occur. To avoid these problems, if you use a nullable receiver inside an extension function, it is best not to return null. If you need an extension function that returns null, you can define it as an extension of a non-nullable type and use the safe call operator when calling the extension, as shown in the following code: fun String.extensionFunction(): Int? { return // ... } val length = str?.extensionFunction() If you have any questions about the extensions, you can find more information here.","date":"2023-01-08T21:22:27+09:00","href":"https://disj11.github.io/en/nullable-receiver-in-extension-functions-of-kotlin/","objectID":"2dbe44e0911d44532b267a5323b18451_0","order":0,"tags":["kotlin"],"title":"Nullable Receiver in Extension Functions of Kotlin"},{"content":"Kotlin에서 데이터 클래스를 주의해야 할 사항이 있다. 데이터 클래스는 자동으로 copy() 함수를 생성하는데, 이 함수를 통해 속성값을 수정한 새로운 인스턴스를 생성할 수 있게 된다. 클래스의 속성 중에 불변성을 유지해야 하는 속성이 있다면, 데이터 클래스의 사용은 위험할 수 있다. 예를 들어, 다음과 같은 Point 클래스가 있다: data class Point private constructor( val value: Int, ) { companion object { fun of(value: Int) = if (value \u0026lt; 0) { throw IllegalArgumentException(\u0026#34;The value argument should always be set to a positive value, but the current value is $value\u0026#34;) } else { Point(value) } } } 코드에서 보는 바와 같이 Point 클래스의 value 속성은 양수여야 한다. 그러나 copy() 함수를 사용하면 음수값을 설정할 수 있다: val point = Point.of(10) // The copy() function allows us to set an invalid value. val invalidPoint = point.copy(value = -10) 이를 방지하기 위해 데이터 클래스 대신 다음과 같은 Point 클래스를 정의할 수 있다: class Point private constructor( val value: Int, ) { override fun equals(other: Any?): Boolean { if (this === other) return true if (javaClass != other?.javaClass) return false other as Point if (value != other.value) return false return true } override fun hashCode(): Int { return value } override fun toString(): String { return \u0026#34;Point(value=$value)\u0026#34; } } 이 포스트에서 알아본 것 처럼, Kotlin에서 데이터 클래스를 사용할 때 copy() 함수가 자동으로 생성된다는 점을 조심해야한다. 데이터 클래스에 대해 더 많은 정보를 원한다면 공식 문서를 참조하다.","date":"2023-01-08T14:39:00+09:00","href":"https://disj11.github.io/notes-on-using-data-classes-in-kotlin/","objectID":"33d5ed4a10544fb713669873294bc369_0","order":0,"tags":["kotlin"],"title":"Kotlin에서 데이터 클래스를 사용할 때 주의할 점"},{"content":"When using data classes in Kotlin, it is important to keep a few things in mind. Data classes automatically create a copy() function, which can be used to create a new instance of the class with modified property values. However, if a property of the class must maintain an invariant, this function may not behave as expected. For example, consider the following Point class: data class Point private constructor( val value: Int, ) { companion object { fun of(value: Int) = if (value \u0026lt; 0) { throw IllegalArgumentException(\u0026#34;The value argument should always be set to a positive value, but the current value is $value\u0026#34;) } else { Point(value) } } } The value property of the Point class is intended to be positive. However, the copy() function allows us to set an invalid value: val point = Point.of(10) // The copy() function allows us to set an invalid value. val invalidPoint = point.copy(value = -10) To prevent this from happening, we can define the Point class as follows: class Point private constructor( val value: Int, ) { override fun equals(other: Any?): Boolean { if (this === other) return true if (javaClass != other?.javaClass) return false other as Point if (value != other.value) return false return true } override fun hashCode(): Int { return value } override fun toString(): String { return \u0026#34;Point(value=$value)\u0026#34; } } As we have learned in this post, it is important to always consider the copy() function when using data classes in Kotlin. If you have any questions about the data classes, you can find more information here.","date":"2023-01-08T14:39:00+09:00","href":"https://disj11.github.io/en/notes-on-using-data-classes-in-kotlin/","objectID":"2b7b0aa434c491d238b82df1cb31e25e_0","order":0,"tags":["kotlin"],"title":"Notes on Using Data Classes in Kotlin"},{"content":"개요 # 이전까지 자바에서 사용하던 HttpURLConnection 는 지원 수준이 너무 낮아 서드 파티 라이브러리인 Apache HttpClient, Jetty, 스프링의 RestTemplate 을 많이 사용하였다. 하지만 Java 11 에서 HTTP/2와 Web Socket 을 구현하는 HTTP Client API 의 표준화가 정식으로 도입되었다. 이번 포스팅에서는 Java 11 에서 채택된 HTTP Client API 표준화에 대해 알아본다. 변경점 (JEP 321) # Java 9 에서 도입되었던 HTTP API가 이제 공식적으로 Java SE API에 통합 되었다. 새로운 HTTP APIs 는 java.net.HTTP.* 패키지에서 확인할 수 있다. 최신 버전의 HTTP 프로토콜은 stream multiplexing, header compression 와 push promises 등을 통해 전반벅인 성능이 향상되었다. Java 11 부터 API는 비동기로 동작합니다. 비동기는 CompletableFuture 를 사용하여 구현되었다. 새로운 HTTP 클라이언트 API는 외부 종속성 없이 HTTP/2와 같은 최신 웹 기능을 지원한다. 새로운 API는 HTTP 1.1/2 WebSocket에 대한 기본 지원을 제공한다. 핵심 기능을 제공하는 클래스와 인터페이스는 다음과 같다. HttpClient class, java.net.http.HttpClient HttpRequest class, java.net.http.HttpRequest HttpResponse interface, java.net.http.HttpResponse WebSocket interface, java.net.http.WebSocket 이전 버전의 문제점 # 기존에 사용하던 HttpURLConnection API 는 다음과 같은 문제가 존재했다: 더 이상 작동하지 않는 프로토콜을 사용하도록 디자인 되었다. (FTP, gopher, etc.) HTTP/1.1 이전 버전이며 너무 추상적이다. blocking mode 로만 동작한다. (하나의 스레드당 하나의 request/response) HTTP Client API 개요 # HttpURLConnection 과 달리 HTTP Client 는 동기화 비동기 모두를 제공한다. API는 다음의 3가지 핵심 클래스로 이루어 진다. HttpRequest - HttpClient 를 통해 보낼 요청 HttpClient - 여러 요청에 대한 공통 구성 정보를 담는 컨테이너 역할 HttpResponse - HttpRequest 호출의 결과 다음 섹션에서 각각에 대해 더 자세히 알아보자. HttpRequest # 이름에서 알 수 있듯 보내려는 요청을 나타내는 객체이다. HttpRequest.Builder 를 사용하여 새 인스턴스를 만들 수 있다. Builder 클래스는 HttpRequest.newBuilder() 를 통해 얻을 수 있다. URI 설정 # 요청을 생성할 때 가장 먼저 해야 할 일은 URL을 제공하는 것이다. 다음과 같이 두 가지 방법을 통해 URL 을 제공 할 수 있다. HttpRequest.newBuilder(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) HTTP Method 지정 # Builder 에서 다음 메서드 중 하나를 호출하여 사용할 HTTP Method 를 정의 할 수 있다. GET() POST(BodyPublisher body) PUT(BodyPublisher body) DELETE() BodyPublisher 에 대해서는 이후에 다루기로 하고, 먼저 간단한 GET 요청 예제를 살펴보자. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .GET() .build(); 이 요청에는 요청에 필요한 모든 정보가 있다. 하지만 때때로 요청에 추가적인 파라미터가 필요할 수도 있다. 몇 가지 중요한 파라미터에는 다음과 같은 것들이 있다. HTTP protocol 의 버전 headers timeout HTTP protocol 버전 # API 는 기본적으로 HTTP/2 프로토콜을 사용하지만 사용하려는 프로토콜의 버전을 명시할 수 있다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .version(HttpClient.Version.HTTP_2) .GET() .build(); 중요한 점은 HTTP/2 가 지원되지 않는 경우 클라이언트는 HTTP/1.1 로 대체한다는 점이다. Header 설정 # header 에 추가적인 정보가 필요한 경우 builder 메서드를 사용할 수 있다. 여기에는 두 가지 방법이 있다. headers() 메서드를 통해 모든 헤더를 키와 값의 쌍으로 제공 header() 메서드를 통해 하나의 키와 값을 제공 HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .headers(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;) .GET() .build(); HttpRequest request2 = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .header(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;) .header(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;) .GET() .build(); Timeout 설정 # Builder 인스턴스의 timeout() 메서드를 사용하여 응답 시간을 설정할 수 있다. 만약 응답 시간을 초과한다면 HttpTimeoutException 이 발생한다. 기본 값은 infinity 이다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .timeout(Duration.of(10, SECONDS)) .GET() .build(); Request Body 설정 # Request Method 가 POST, PUT, DELETE 인 경우 요청 본문을 설정할 수 있다. 새로운 API 는 요청 본문을 작성할 수 있도록 여러가지의 BodyPublisher 구현체를 제공한다. StringProcessor ( HttpRequest.BodyPublishers.ofString 를 사용하여 생성함) InputStreamProcessor (HttpRequest.BodyPublishers.ofInputStream 를 사용하여 생성함) ByteArrayProcessor (HttpRequest.BodyPublishers.ofByteArray 를 사용하여 생성함) FileProcessor (HttpRequest.BodyPublishers.ofFile 를 사용하여 생성함) request body 가 필요 없는 경우는 HttpRequest.BodyPublishers.noBody() 를 사용한다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .POST(HttpRequest.BodyPublishers.noBody()) .build(); StringBodyPublisher # HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.ofString(\u0026#34;Sample request body\u0026#34;)) .build(); InputStreamBodyPublisher # byte[] sampleData = \u0026#34;Sample request body\u0026#34;.getBytes(); HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.ofInputStream(() -\u0026gt; new ByteArrayInputStream(sampleData))) .build(); ByteArrayProcessor # byte[] sampleData = \u0026#34;Sample request body\u0026#34;.getBytes(); HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.ofByteArray(sampleData)) .build(); FileProcessor # HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.fromFile( Paths.get(\u0026#34;src/test/resources/sample.txt\u0026#34;))) .build(); HttpClient # 모든 요청은 HttpClient 를 통해 전송한다. HttpClient 는 HttpClient.newBuilder() 메서드 또는 HttpClient.newHttpClient() 를 통해 얻을 수 있다. Response Body 핸들링 # Publisher 와 비슷하게 Response Body handler 생성을 위한 메서드가 있다. BodyHandlers.ofByteArray BodyHandlers.ofString BodyHandlers.ofFile BodyHandlers.discarding BodyHandlers.replacing BodyHandlers.ofLines BodyHandlers.fromLineSubscriber BodyHandlers 팩토리 클래스의 사용에 주의한다. java 11 이전 버전에서는 다음과 같이 사용했다. HttpResponse\u0026lt;String\u0026gt; response = client.send(request, HttpResponse.BodyHandler.asString()); 이제는 다음과 같이 사용할 수 있다. HttpResponse\u0026lt;String\u0026gt; response = client.send(request, BodyHandlers.ofString()); Proxy 설정 # Builder 인스턴스에서 proxy() 메서드를 사용하여 간단하게 프록시를 추가할 수 있다. 다음은 시스템 기본 프록시를 사용하게 하는 예제이다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient .newBuilder() .proxy(ProxySelector.getDefault()) .build() .send(request, BodyHandlers.ofString()); Redirect Polcy 설정 # 접근하려는 페이지가 다른 주소로 이동하는 경우가 있다. 이 경우 일반적으로 변경된 URI 와 함께 HTTP 상태코드 3xx 를 받게 된다. 적절한 리다이렉션 정책을 설정하면 HttpClient 가 자동으로 요청을 새 URI 로 리다이렉션 한다. 리다이렉션 정책 설정은 Builder 인스턴스의 followRedirects() 메서드를 사용한다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newBuilder() .followRedirects(HttpClient.Redirect.ALWAYS) .build() .send(request, BodyHandlers.ofString()); 리다이렉션 정책은 HttpClient.Redirect 에 정의 되어 있다. Authenticator 설정 # Authenticator 는 연결을 위한 자격증명을 나타낸다. 예를 들어 연결 하려는 서버가 username, password","date":"2021-11-02T18:11:57+09:00","href":"https://disj11.github.io/http-client-in-java/","objectID":"c92630f9f1d66213ba2997c1abb859dc_0","order":0,"tags":["java"],"title":"Http Client in Java"},{"content":"를 요구한다면 PasswordAuthentication 클래스를 사용할 수 있다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newBuilder() .authenticator(new Authenticator() { @Override protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication( \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;.toCharArray()); } }).build() .send(request, BodyHandlers.ofString()); Send Requests - Sync vs. Async # HttpClient 는 동기와 비동기 요청 모두 제공한다. send() - 동기 sendAsync() - 비동기 send 메서드는 응답이 올 때까지 기다리고, HttpResponse 객체를 리턴한다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newBuilder() .build() .send(request, BodyHandlers.ofString()); 응답이 올 때까지 기다리기 때문에 많은 양의 데이터를 처리해야 할 때 단점이 있다. 반면에 sendAsync 메서드는 비동기로 작동하며 CompletableFeature\u0026lt;HttpResponse\u0026gt; 를 리턴한다. CompletableFuture\u0026lt;HttpResponse\u0026lt;String\u0026gt;\u0026gt; response = HttpClient.newBuilder() .build() .sendAsync(request, HttpResponse.BodyHandlers.ofString()); 다음과 같은 사용도 가능하다. List\u0026lt;URI\u0026gt; targets = Arrays.asList( new URI(\u0026#34;https://postman-echo.com/get?foo1=bar1\u0026#34;), new URI(\u0026#34;https://postman-echo.com/get?foo2=bar2\u0026#34;)); HttpClient client = HttpClient.newHttpClient(); List\u0026lt;CompletableFuture\u0026lt;String\u0026gt;\u0026gt; futures = targets.stream() .map(target -\u0026gt; client .sendAsync( HttpRequest.newBuilder(target).GET().build(), HttpResponse.BodyHandlers.ofString()) .thenApply(response -\u0026gt; response.body())) .collect(Collectors.toList()); 비동기를 위한 Executor 설정 # 비동기 호출 시 사용할 스레드를 제공하는 Executor 을 정의할 수도 있다. 이를 사용하여 요청 처리에 사용되는 스레드 수를 제한할 수 있다. ExecutorService executorService = Executors.newFixedThreadPool(2); CompletableFuture\u0026lt;HttpResponse\u0026lt;String\u0026gt;\u0026gt; response1 = HttpClient.newBuilder() .executor(executorService) .build() .sendAsync(request, HttpResponse.BodyHandlers.ofString()); CompletableFuture\u0026lt;HttpResponse\u0026lt;String\u0026gt;\u0026gt; response2 = HttpClient.newBuilder() .executor(executorService) .build() .sendAsync(request, HttpResponse.BodyHandlers.ofString()); HttpClient 는 기본적으로 java.util.concurrent.Executors.newCachedThreadPool() 를 사용한다. CookieHandler 설정 # Builder 의 cookieHandler 메서드를 사용하여 클라이언트별 CookieHandler 를 손쉽게 설정할 수 있다. 예를 들어 모든 쿠키를 허용하지 않으려면 다음과 같이 사용할 수 있다. HttpClient.newBuilder() .cookieHandler(new CookieManager(null, CookiePolicy.ACCEPT_NONE)) .build(); 만약 CookieManager 가 쿠키 저장을 허용했다면 HttpClient 에서 CookieHandler 를 통해 쿠키에 액세스 할 수 있다. ((CookieManager) httpClient.cookieHanlder().get()).getCookieStore() HttpResponse # HttpResponse 클래스는 서버의 응답을 나타낸다. 여러가지 유용한 메서드가 있지만 가장 중요한 것은 두 가지 이다. statusCode() - HTTP 상태 코드를 반환한다. body() - 응답에 대한 본문을 반환하며 반환 유형은 send() 메서드에 전달된 BodyHandler 에 따라 다르다. 이 외에도 uri(), headers(), trailers(), version() 등과 같은 유용한 메서드가 있다. Response 객체의 URI # Response 객체의 uri() 메서드는 응답 된 URI 를 반환한다. 리다이렉션이 일어났을 수도 있기 때문에 request 객체의 URI 와 다른 경우도 있다. assertThat(request.uri().toString(), equalTo(\u0026#34;http://stackoverflow.com\u0026#34;)); assertThat(response.uri().toString(), equalTo(\u0026#34;https://stackoverflow.com/\u0026#34;)); Response Headers # Response 객체의 headers() 메서드를 통해 응답 헤더를 확인할 수 있다. 응답 헤더는 HttpHeaders 이며 read-only 이다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newHttpClient() .send(request, HttpResponse.BodyHandlers.ofString()); HttpHeaders responseHeaders = response.headers(); Response Version # version() 메서드를 통해 서버와 통신하는 데 사용된 HTTP 프로토콜의 버전을 알 수 있다. 요청 시 HTTP/2 버전을 사용했더라도 HTTP/1.1 을 통해 응답이 올 수도 있음에 주의한다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .version(HttpClient.Version.HTTP_2) .GET() .build(); HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newHttpClient() .send(request, HttpResponse.BodyHandlers.ofString()); assertThat(response.version(), equalTo(HttpClient.Version.HTTP_1_1)); 참조 # Exploring the New HTTP Client in Java","date":"2021-11-02T18:11:57+09:00","href":"https://disj11.github.io/http-client-in-java/","objectID":"c92630f9f1d66213ba2997c1abb859dc_1","order":1,"tags":["java"],"title":"Http Client in Java"},{"content":"개요 # DecimalFormat은 미리 정의된 포맷을 사용하여 10진수 문자열 표현을 형식화 할 수 있는 NumberFormat 의 하위 클래스이다. 역으로 문자열을 숫자로 구문 분석하는 데 사용할 수도 있다. 이번 포스팅에서는 DecimalFormat 의 사용법을 알아본다. 패턴 문자 # 숫자를 어떤 형식으로 나타낼 지 지정하기 위해서는 먼저 패턴 문자를 알아야한다. 총 11가지 문자가 있지만, 네 가지만 알고 있으면 대부분의 상황에서 문제 없이 사용할 수 있다. 0 : 값이 제공되면 숫자를, 그렇지 않다면 0을 출력 # : 값이 제공되면 숫자를, 그렇지 않다면 아무것도 출력하지 않음 . : 소수점 구분 기호를 넣을 위치를 지정 , : 그룹화 구분 기호를 넣을 위치를 지정 DecimalFormat 사용 시 패턴이 지정될 경우 지정된 규칙이 실행되고, 그렇지 않은 경우는 JVM Locale 의 DecimalFormatSymbol 에 따라 규칙이 실행된다. 기본 포맷팅 # 실제 코드를 통해 포맷을 적용해보자. Simple Decimal # 정수 부분은 패턴 문자가 입력되는 문자보다 개수가 더 적더라도 잘리지 않는다. 다음의 테스트 코드를 통해 확인할 수 있다. double d = 123.45; Assertions.assertEquals(new DecimalFormat(\u0026#34;#.##\u0026#34;).format(d), \u0026#34;123.45\u0026#34;); Assertions.assertEquals(new DecimalFormat(\u0026#34;0.00\u0026#34;).format(d), \u0026#34;123.45\u0026#34;); 정수와 소수 부분의 패턴 문자가 입력되는 문자보다 길 경우는 # 인 경우 삭제되고, 0 인 경우는 0 이 채워지는 것을 볼 수 있다. double d = 123.45; assertEquals(new DecimalFormat(\u0026#34;####.###\u0026#34;).format(d), \u0026#34;123.45\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;0000.000\u0026#34;).format(d), \u0026#34;0123.450\u0026#34;); Rounding (반올림) # 앞에서 정수 부분은 패턴 문자가 입력되는 문자보다 개수가 더 적더라도 잘리지 않는다고 하였다. 하지만 소수 부분은 패턴 문자가 더 적은 경우, 패턴 문자의 길이에 맞게 반올림 된다. double d = 123.45; assertEquals(new DecimalFormat(\u0026#34;#.#\u0026#34;).format(d), \u0026#34;123.5\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;#\u0026#34;).format(d), \u0026#34;123\u0026#34;); Grouping (그룹핑) # , 패턴 문자는 다음과 같이 사용한다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;#,###.#\u0026#34;).format(d), \u0026#34;1,234,567.9\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;#,###\u0026#34;).format(d), \u0026#34;1,234,568\u0026#34;); Mixing String Literals (문자열 리터럴 혼용) # 문자열 리터럴과 패턴을 혼용하여 사용할 수 있다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;The # number\u0026#34;).format(d), \u0026#34;The 1234568 number\u0026#34;); 다음과 같은 방법을 통해 문자열 리터럴에 특수 문자를 사용 수도 있다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;The \u0026#39;#\u0026#39; # number\u0026#34;).format(d), \u0026#34;The # 1234568 number\u0026#34;); Localized Formatting # 이탈리아 같은 몇몇의 나라에서는 그룹핑 문자로 . 를 사용하고 소수 구분 기호로 , 를 사용한다. 이런 나라에서는 #,###.## 패턴을 이용할 시 1.234.567,89 로 포맷팅 된다. 경우에 따라 이는 유용한 i18n 기능이 될 수도 있지만, 그렇지 않은 경우도 있을 것이다. 이럴 때에는 DecimalFormatSymbols 을 사용한다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;#,###.##\u0026#34;, new DecimalFormatSymbols(Locale.ENGLISH)).format(d), \u0026#34;1,234,567.89\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;#,###.##\u0026#34;, new DecimalFormatSymbols(Locale.ITALIAN)).format(d), \u0026#34;1.234.567,89\u0026#34;); Parsing # 다음과 같이 문자열을 숫자로 파싱이 가능하다. assertEquals(new DecimalFormat(\u0026#34;\u0026#34;, new DecimalFormatSymbols(Locale.ENGLISH)).parse(\u0026#34;1234567.89\u0026#34;), 1234567.89); Thread-Safety # DecimalFormat 은 스레드에 안전하지 않기 때문에 스레드 간 동일 인스턴스를 공유할 때 주의하여야 한다. 참조 # A Practical Guide to DecimalFormat","date":"2021-11-01T20:00:12+09:00","href":"https://disj11.github.io/number-formatter-in-java/","objectID":"2c1f8384688be7e39ddc4bee18838b0b_0","order":0,"tags":["java"],"title":"Number Formatter in Java"},{"content":"소개 # OAuth는 오픈 API의 인증(authentication)과 권한 부여(authorization)를 제공하기 위해 만들어진 프로토콜이다. OAuth 1.0과 OAuth 2.0이 있는데, 현재는 RFC 5849에서 설명하는 OAuth 1.0을 폐기하고, RFC 6749에 설명된 OAuth 2.0 방식을 사용한다. 이번 포스팅에서는 OAuth 2.0에 관하여 알아본다. 역할 (Rules) # OAuth 2.0을 이해하기 위해서는 먼저 OAuth 2.0에서 정의하는 4가지 역할에 관하여 알아야한다. Resource Owner (리소스 소유자) Resource Service (리소스 서버) Client (클라이언트) Authorization Server (인증 서버) 리소스 소유자는 보호된 리소스의 소유자를 말한다. 예를 들어 은행관련 서비스에서 계좌 잔액이라는 리소스가 있다면, 이 계좌의 소유주(예금주)가 리소스의 소유자가 된다. 리소스 서버는 보호된 리소스를 제공하는 서버를 말한다. 예를 들어 오픈뱅킹 서비스는 각 은행들의 API를 연동하여 다양한 리소스(거래내역, 계좌실명 등)를 제공한다. 이런 경우 오픈뱅킹의 서버가 리소스 서버라고 할 수 있다. 클라이언트는 오픈 API를 호출하는 응용 프로그램을 말한다. 예를 들어 오픈뱅킹 API를 이용하여 모든 은행들의 잔액을 볼 수 있는 어플리케이션을 만들었다면, 이 어플리케이션이 클라이언트가 된다. 인증 서버는 리소스 소유자로부터 리소스에 접근 권한을 획득한 이후에 리소스에 접근하기 위한 엑세스 토큰(Access Token)을 발급해주는 서버를 말한다. OAuth 2.0의 흐름 # 다음 그림은 OAuth 2.0의 대략적인 흐름을 나타낸다. +--------+ +---------------+ | |--(1)- Authorization Request -\u0026gt;| Resource | | | | Owner | | |\u0026lt;-(2)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(3)-- Authorization Grant --\u0026gt;| Authorization | | Client | | Server | | |\u0026lt;-(4)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(5)----- Access Token ------\u0026gt;| Resource | | | | Server | | |\u0026lt;-(6)--- Protected Resource ---| | +--------+ +---------------+ 그림을 보고 하나씩 짚어보자. 리소스 서버에게 리소스를 요청하기 전에 먼저 인증을 요청한다. 인증 요청은 리소스 소유자에게 직접 할 수도 있지만, 중간에 인증 서버를 통해 간접적으로 하는 것이 좋다. 클라이언트는 리소스 소유자의 인가를 나타내는 자격정보인 인가 승인을 받는다. 클라이언트는 2번에서 받은 인가 승인을 사용하여 엑세스 토큰을 요청한다. 인증 서버는 클라이언트를 인증하고, 제시된 인가 승인이 유효한지 확인한다. 유효한 경우 엑세스 토큰을 발급한다. 클라이언트는 엑세스 토큰을 제시하여 리소스 서버에 보호된 리소스를 요청한다. 리소스 서버는 엑세스 토큰이 유효한지 확인하고, 유효한 경우 요청을 받아들인다. 인가 승인 (Authorization Grant) # \u0026ldquo;인가 승인\u0026quot;은 리소스 소유자가 보호된 리소스에 대한 접근을 허용한다는 것을 나타내는 자격 정보(Credentials)이다. 이는 클라이언트가 엑세스 토큰을 얻기 위해 사용된다. 인가 승인에는 네 가지 유형이 있다. 이번 포스팅에서는 네 가지 유형 중 인가 코드(authorization code) 방식에 대해서만 설명하며, 추가적인 유형은 RFC 6749 - Authorization Grant를 참고한다. 인가 코드 (Authorization Code) # 클라이언트는 사용자 에이전트(User-Agent)를 통해 리소스 소유자를 인증 서버로 안내한다. 인증 서버는 리소스 소유자를 인증하고, 인증이 완료되면 클라이언트는 인증 코드를 획득한다. 네이버 로그인이나 카카오 로그인 API가 사용하는 인가 승인 유형이 바로 이 유형이다. 엑세스 토큰 (Access Token) # 엑세스 토큰은 보호된 리소스에 접근할 수 있도록 하는 권한 증명이다. 엑세스 토큰으로 접근할 수 있는 리소스의 범위와 사용할 수 있는 기간이 정해져 있다. 리프레시 토큰 (Refresh Token) # 리프레시 토큰은 엑세스 토큰을 얻는 데 사용할 수 있는 권한 증명이다. 엑세스 토큰이 유효하지 않거나, 만료된 경우 새로운 엑세스 토큰을 발급 받기 위해 사용된다. 더 좁은 범위로 추가적인 엑세스 토큰을 받기 위해 사용되기도 한다. 아래의 그림은 리프레시 토큰을 사용하여 엑세스 토큰을 갱신하는 흐름을 보여준다. +--------+ +---------------+ | |--(1)------- Authorization Grant ---------\u0026gt;| | | | | | | |\u0026lt;-(2)----------- Access Token -------------| | | | \u0026amp; Refresh Token | | | | | | | | +----------+ | | | |--(3)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(4)- Protected Resource --| Resource | | Authorization | | Client | | Server | | Server | | |--(5)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(6)- Invalid Token Error -| | | | | | +----------+ | | | | | | | |--(7)----------- Refresh Token -----------\u0026gt;| | | | | | | |\u0026lt;-(8)----------- Access Token -------------| | 인가 획득 (Obtaining Authorization) # 클라이언트가 리소스 소유자로부터 인가를 획득하는 과정에 대해 알아보자. 인가 승인에서 알아본 것처럼 인가 획득을 위한 유형에는 네 가지가 있지만, 이 포스팅에서는 인가 코드를 사용하여 인가를 획득하는 과정에 대해서만 설명한다. 인가 코드 승인 유형은 리다이렉션이 기반이 된다. 때문에 클라이언트는 리소스 소유자의 유저 에이전트(일반적으로 웝 브라우저)와 상호작용 할 수 있어야하며, 리다이렉션을 통해 인증 서버로 오는 요청을 받을수 있어야 한다. 인가 코드 승인 유형 흐름 # 다음 그림은 인가 코드 방식의 흐름을 보여준다. +----------+ | Resource | | Owner | | | +----------+ ^ | (2) +----|-----+ Client Identifier +---------------+ | -+----(1)-- \u0026amp; Redirection URI ----\u0026gt;| | | User- | | Authorization | | Agent -+----(2)-- User authenticates ---\u0026gt;| Server | | | | | | -+----(3)-- Authorization Code ---\u0026lt;| | +-|----|---+ +---------------+ | | ^ v (1) (3) | | | | | | ^ v | | +---------+ | | | |\u0026gt;---(4)-- Authorization Code ---------\u0026#39; | | Client | \u0026amp; Redirection URI | | | | | |\u0026lt;---(5)----- Access Token -------------------\u0026#39; +---------+ (w/ Optional Refresh Token) 1,2,3번의 과정이 두 부분으로 나누어 지는데, 이는 유저 에이전트를 통해 전달되기 때문이다. 1번은 클라이언트가 리소스 소유자의 유저 에이전트를 인증 서버로 안내하며 흐름을 시작하는 과정이다. 클라이언트는 클라이언트의 식별자(client identifier),","date":"2021-10-22T10:08:30+09:00","href":"https://disj11.github.io/an-introduction-to-oauth2/","objectID":"a177d88fa4b2236fde560a5c14b1fe69_0","order":0,"tags":["development"],"title":"Oauth2 에 대해서 알아보자"},{"content":"요청 범위(requested scope), 로컬 상태(local state), 리다이렉션 URI를 포함해야한다. 네이버 아이디로 로그인 API를 연동한 어플리케이션에서 [네이버 아이디로 로그인] 버튼을 누르면 흐름이 시작되는데, 이 과정이라고 생각하면 된다. 2번은 인증 서버가 유저 에이전트를 통해 리소스 소유자를 인증하고, 리소스 소유자가 클라이언트의 접근 요청에 승인 혹은 거부할 지를 선택하는 단계이다. 3번 과정은 인증 서버가 유저 에이전트를 제공된 리다이렉션 URI로 이동시키는 과정이다. 이때 리다이렉션 URI에는 인증 코드와 로컬 상태가 포함된다. 4번은 클라이언트가 이전 과정에서 받은 인증 코드를 포함하여 인증 서버에 엑세스 토큰을 요청하는 단계이다. 요청을 보낼 때에는 3번 과정에서 사용했던 리다이렉션 URI도 포함하여 전달한다. 5번 과정에서 인증서버는 인증 코드가 유효한지 확인하고, 3번 과정과 4번 과정의 리다이렉션 URI가 동일한지 확인한다. 유효하다는 게 획인되면 엑세스 토큰과 (선택적으로) 리프레시 토큰을 응답한다. 인가 요청 (Authorization Request) # 클라이언트는 인증 코드 요청을 할 때 application/x-www-form-urlencoded 를 사용하여 다음 파라미터를 포함해야한다. response_type 필수. \u0026ldquo;code\u0026quot;로 고정 client_id 필수. 클라이언트의 식별자 redirect_uri 선택사항. 자세한 내용은 RFC 6749 - Redirection Endpoint 참고 scope 선택사항. 자세한 내용은 RFC 6749 - Access Token Scope 참고 state 권장사항. 인증 서버는 유저 에이전트를 클라이언트로 리다이렉트할 때 이 값을 포함한다. RFC 6749 - Cross-Site Request Forgery에 기술된대로 사이트 간 요청 위조를 방지하는 데 사용하는 것이 좋다. 인가 요청의 예: GET /authorize?response_type=code\u0026amp;client_id=s6BhdRkqt3\u0026amp;state=xyz\u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1 Host: server.example.com 인가 응답 (Authorization Response) # 리소스 소유자가 접근 요청을 승인하면, 인증 서버는 다음의 파라미터를 application/x-www-form-urlencoded 를 사용하여 클라이언트에게 전달한다. 성공 응답 (Successful Response) # code 필수. 인증 서버에서 생성된 인증 코드이다. 유출 위험을 줄이기 위해 만료 시간이 짧아야 하며 최대 10분이 권장된다. 클라이언트는 인증 코드를 두 번 이상 사용하면 안된다. 만약 두번 이상 사용될 경우 인증 서버는 요청을 거부해야 하며, 해당 인증 코드 이전에 발급된 모든 토큰을 취소하는 것이 좋다. state 클라이언트가 인증 요청 시 state 파라미터를 포함했다면 필수. 클라이언트로부터 전달 받은 값과 동일해야한다. 성공 응답의 예: HTTP/1.1 302 Found Location: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA\u0026amp;state=xyz 오류 응답 (Error Response) # 만약 요청이 누락되거나, 유효하지 않는 경우, 리다이렉션 URI가 일치하지 않는 경우, 클라이언트 식별자가 누락되거나 유효하지 않는 경우는 유저 에이전트를 유효하지 않은 URI로 리다이렉트 되게 해서는 안된다. 이 경우에 인증 서버는 다음 파라미터를 사용하여 리소스 소유자에게 오류를 알려주는 것이 좋다. error 필수. 다음의 에러 코드 사용 invalid_request 요청 시 필수 파라미터의 누락, 유효하지 않은 파라미터 포함, 파라미터를 두 번 이상 포함 등 unauthorized_client 클라이언트가 이 인가 승인 유형을 사용할 권한이 없음 access_denied 리소스 소유자 또는 인증 서버가 요청을 거부 unsupported_response_type 인증 서버가 Authorization Code Grant 유형을 지원하지 않음 invalid_scope 요청한 scope가 유효하지 않거나, 알 수 없거나, 손상된 경우 server_error 인증 서버에 예기치 못한 오류가 발생 temporarily_unavailable 인증 서버의 과부하 또는 유지보수로 인해 요청을 처리할 수 없음 error_description 선택사항. 클라이언트 개발자가 발생한 오류를 이해하는 데 도움을 주는 정보를 제공한다. error_uri 선택사항. 클라이언트 개발자를 위해 발생한 오류와 관련된 추가 정보를 제공한다. state 클라이언트가 인증 요청 시 state 파라미터를 포함했다면 필수. 클라이언트로부터 전달 받은 값과 동일해야한다. 오류 응답의 예: HTTP/1.1 302 Found Location: https://client.example.com/cb?error=access_denied\u0026amp;state=xyz 엑세스 토큰 요청 (Access Token Request) # 클라이언트는 토큰 요청시 UTF-8 인코딩을 사용하여 application/x-www-form-urlencoded 형식으로 된 다음과 같은 파라미터를 body에 담아야한다. grant_type 필수. 값은 \u0026ldquo;authorization_code\u0026quot;로 고정 code 필수. 인증 서버로부터 받은 인증 코드 redirect_uri 인증 요청 시 redirect_uri가 존재했다면 필수이며, 인증 요청 시 사용했던 값과 동일해야 한다. client_id 클라이언트가 인증 서버와 인증하지 않는 경우 필수. 클라이언트 인증에 관한 자세한 내용은 RFC 6749 - Client Authentication를 참고한다. 토큰 요청의 예: POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencodedgrant_type=authorization_code\u0026amp;code=SplxlOBeZQQYbYS6WxSbIA\u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb 엑세스 토큰 응답 (Access Token Response) # Access Token 요청이 유효하고 인증되었다면, 인증 서버는 Access Token과 선택적으로 갱신 토큰을 발급한다. 성공 응답 (Successful Response) # 인증 서버는 Access Token과 선택적으로 갱신 토큰을 발급하고, 다음 파라미터를 200 (OK) 상태 코드로 응답한다. 파라미터는 application/json 유형을 사용하여 HTTP Response Body에 포함한다. access_token 필수. 인증 서버가 발급한 엑세스 토큰 token_type 필수. 토큰의 타입으로 보통 baerer 타입을 많이 사용한다. 자세한 내용은 RFC 6749 - Access Token Types를 참고한다. expires_in 권장사항. 초 단위의 Access Token 수명. 예를 들어 값이 3600이라면 토큰이 생성된 시간으로부터 3600초(1 시간) 뒤에 만료된다는 의미이다. refresh_token 선택사항. 인증 서버가 발급한 리프레시 토큰 scope 클라이언트가 요청한 범위와 동일하다면 선택사항. 그렇지 않은 경우 필수. 자세한 내용은 RFC 6749 - Access Token Scope를 참고한다. 성공 응답의 예: HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;refresh_token\u0026#34;:\u0026#34;tGzv3JOkF0XG5Qx2TlKWIA\u0026#34;, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; } 오류 응답 (Error Response) # 인증 서버는 다음 파라미터를 400 (Bad Request) 상태 코드로 응답한다. 파라미터는 application/json 유형을 사용하여 HTTP Response Body에 포함한다. error 필수. 다음의 에러 코드 사용 invalid_request 요청 시 필수 파라미터의 누락, 유효하지 않은 파라미터 포함, 파라미터를 두 번 이상 포함 등 invalid_client 클라이언트가 인증에 실패한 경우 (e.g. 알 수 없는 클라이언트, 클라이언트 인증이 포함되지 않음, 지원되지 않는 인증 방법). invalid_grant 인가 승인 유형 또는 Refresh Token이 유효하지 않거나, 만료, 취소된 경우 또는 인증 요청에 사용된 리다이렉션 URI가 일치하지 않거나 다른 클라이언트에게 발급된 경우 unauthorized_client 클라이언트가 이 인가 승인 유형을 사용할 권한이 없음 access_denied 리소스 소유자 또는 인증 서버가 요청을 거부 unsupported_grant_type 서버가 지원하지 않는 인가 승인 유형인 경우 temporarily_unavailable 인증 서버의 과부하 또는 유지보수로 인해 요청을 처리할 수 없음 (503 Service Unavailable 상태 코드는 HTTP redirect를 통해 클라이언트에게","date":"2021-10-22T10:08:30+09:00","href":"https://disj11.github.io/an-introduction-to-oauth2/","objectID":"a177d88fa4b2236fde560a5c14b1fe69_1","order":1,"tags":["development"],"title":"Oauth2 에 대해서 알아보자"},{"content":"전달 될 수 없기 때문에 이 오류 코드가 필요) invalid_scope 요청한 scope가 유효하지 않거나, 알 수 없거나, 손상된 경우 error_description 선택사항. 클라이언트 개발자가 발생한 오류를 이해하는 데 도움을 주는 정보를 제공한다. error_uri 선택사항. 클라이언트 개발자를 위해 발생한 오류와 관련된 추가 정보를 제공한다. 오류 응답의 예: HTTP/1.1 400 Bad Request Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;error\u0026#34;:\u0026#34;invalid_request\u0026#34; } 사용 예 # 카카오와 네이버에서도 OAuth 2.0 방식의 로그인 API를 제공한다. 카카오 # 카카오 로그인 문서를 확인해보면, 카카오 로그인을 위해서 인가 코드 받기, 토큰 받기 두 과정을 거친다. 이 과정이 인가 획득과 동일하다. 이렇게 발급받은 토큰은 카카오스토리 API 등을 사용할 때 필요하다. 예를 들어 카카오스토리의 프로필 가져오기 API를 사용하려면 이 발급받은 토큰이 필요하다. 이 과정이 OAuth 2.0의 흐름의 5,6번 과정에 속한다. 네이버 # 네이버도 OAuth를 이용하며, 네이버 로그인 API 명세에서 확인할 수 있다. 카카오와 마찬가지로 인가 코드 받기, 토큰 받기 두 과정을 거친다. 이렇게 발급받은 토큰을 사용하여 회원 프로필 조회 API, 카페 API 등을 사용할 수 있다. 마무리 # 이 포스팅은 OAuth 2.0의 클라이언트 구현에 도움이 되는 내용에 초점을 맞춰 생략된 부분이 많다. 만약 OAuth 2.0에 대해 더 자세히 알고 싶다면, RFC 6749을 참고하는 것이 좋다.","date":"2021-10-22T10:08:30+09:00","href":"https://disj11.github.io/an-introduction-to-oauth2/","objectID":"a177d88fa4b2236fde560a5c14b1fe69_2","order":2,"tags":["development"],"title":"Oauth2 에 대해서 알아보자"},{"content":"개요 # Java8 에서 추가된 DateTimeFormatter 클래스에 대해 알아보자. 미리 정의된 인스턴스 # DateTimeFormatter 에는 ISO 및 RFC 표준을 따라 정의되어 있는 날짜/시간 포맷을 제공한다. 예를들어 ISO_LOCAL_DATE 인스턴스를 사용하여 다음과 같이 \u0026lsquo;2021-09-29\u0026rsquo; 와 같은 문자열을 얻을 수 있다. LocalDate date = LocalDate.of(2021, 9, 29); DateTimeFormatter.ISO_LOCAL_DATE.format(date); // 2021-09-29 만약 \u0026lsquo;2021-09-29+09:00\u0026rsquo; 와 같이 오프셋을 포함한 문자열을 구하고 싶다면 ISO_OFFSET_DATE 를 사용한다. LocalDate date = LocalDate.of(2021, 9, 29); DateTimeFormatter.ISO_OFFSET_DATE.format(date.atStartOfDay(ZoneId.of(\u0026#34;UTC+9\u0026#34;))); // 2021-09-29+09:00 FormatStyle의 사용 # 사람이 이해하기 쉽게 날짜를 보여주고 싶을때가 있다. 이럴 때에는 java.time.format.FormatStyle 을 사용할 수 있다. FormatStyle 은 enum 값으로 FULL, LONG, MEDIUM, SHORT가 정의 되어있다. LocalDate day = LocalDate.of(2021, 9, 29); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL).format(day)); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.LONG).format(day)); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.MEDIUM).format(day)); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.SHORT).format(day)); 출력은 다음과 같다. Wednesday, September 29, 2021 September 29, 2021 Sep 29, 2021 9/29/21 ZonedDateTime 인스턴스를 사용하여 날짜와 시간을 함께 표현할 수도 있다. LocalDate day = LocalDate.of(2021, 9, 29); LocalTime time = LocalTime.of(13, 12, 45); ZonedDateTime zonedDateTime = ZonedDateTime.of(day, time, ZoneId.of(\u0026#34;Asia/Seoul\u0026#34;)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.FULL).format(zonedDateTime)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.LONG).format(zonedDateTime)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.MEDIUM).format(zonedDateTime)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.SHORT).format(zonedDateTime)); 출력은 다음과 같다. Wednesday, September 29, 2021 at 1:12:45 PM Korean Standard Time September 29, 2021 at 1:12:45 PM KST Sep 29, 2021, 1:12:45 PM 9/29/21, 1:12 PM 반대로 문자열을 ZonedDateTime 으로 변경하고 싶다면 format() 메서드 대신 parse() 메서드를 사용한다. ZonedDateTime dateTime = ZonedDateTime.from(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.FULL).parse(\u0026#34;Wednesday, September 29, 2021 at 1:12:45 PM Korean Standard Time\u0026#34;)); 사용자 정의 포맷 # 미리 정의된 포맷이 아닌 직접 포맷을 정의하여 사용하고 싶을 때가 있다. 이럴때에는 ofPattern() 메서드를 사용한다. String pattern = \u0026#34;yyyy-MM-dd\u0026#39;T\u0026#39;HH:mm:ss\u0026#34;; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(pattern); System.out.println(formatter.format(LocalDateTime.now())); // 2021-09-29T12:26:18 패턴 문자의 수는 중요하다. 예를들어 month에 MM 과 같은 패턴을 사용한다면 1월을 \u0026ldquo;01\u0026quot;로 표기하며, M 과 같이 표기할 경우 1월을 \u0026ldquo;1\u0026quot;로 표기한다. 자주 사용하는 패턴 문자는 다음과 같다. 문자 의미 표시 예시 u year year 2004; 04 y year-of-era year 2004; 04 M/L month-of-year number/text 7; 07; Jul; July; J d day-of-month number 10 H hour-of-day (0-23) number 0 m minute-of-hour number 30 s second-of-minute number 55 S fraction-of-second number 978 n nano-of-second number 987654321 추가적인 패턴 문자를 알고 싶다면 Java documentation의 Pattern Letters and Symbols 표를 확인한다. 마무리 # 이번 포스트에서는 DateTimeFormatter 에 대하여 알아보았다. DateTimeFormatter 은 SimpleDateFormat 과 달리 스레드에 안전하고 더 최적화 되어있으므로 만약 java8 이상 버전을 사용한다면 SimpleDateFormat 대신 DateTimeFormatter 을 사용하자. 참고 자료: Guide to DateTimeFormatter","date":"2021-09-29T19:33:31+09:00","href":"https://disj11.github.io/date-time-formatter-in-java/","objectID":"70521835029d78afeba9b97ffa274d1a_0","order":0,"tags":["java"],"title":"Date Time Formatter in Java"},{"content":"개요 # Isolation level은 트랜잭션에서 일관성이 없는 데이터를 어느 수준까지 허용할 것인지 정의하는 데이터베이스의 중요한 개념입니다. 격리 수준이 낮을수록 여러 사용자가 동일한 데이터에 동시에 접근할 수 있어 성능이 향상되지만, 이로 인해 잘못된 데이터를 읽거나 데이터 업데이트가 손실되는 문제가 발생할 수 있습니다. 반대로 격리 수준이 높아질수록 데이터의 일관성은 보장되지만, 동시에 접근 가능한 사용자의 수가 줄어들어 성능이 저하될 수 있습니다. 이러한 균형을 맞추기 위해 대부분의 데이터베이스 시스템은 네 가지 격리 수준을 제공하며, 애플리케이션의 요구 사항에 따라 적절한 격리 수준을 선택할 수 있도록 설계되었습니다. 용어 설명 # 격리 수준을 이해하기 위해 먼저 Dirty Read, Non-repeatable Read, Phantom Read라는 개념을 알아야 합니다. 이는 각각 트랜잭션 간의 충돌로 인해 발생할 수 있는 대표적인 문제들입니다. Dirty Read # 커밋되지 않은 데이터를 다른 트랜잭션에서 읽는 것을 허용할 때 발생합니다. 이는 롤백된 데이터를 읽음으로써 잘못된 정보를 기반으로 동작하게 되는 문제를 초래합니다. Transaction 1 Transaction 2 SELECT age FROM users WHERE id = 1; UPDATE users SET age = 21 WHERE id = 1; SELECT age FROM users WHERE id = 1; ROLLBACK; 위 예시에서 Transaction 1은 커밋되지 않은 데이터를 읽었기 때문에, 최종적으로 롤백된 값(21)을 잘못 참조하게 됩니다. Non-repeatable Read # 한 트랜잭션 내에서 동일한 쿼리를 두 번 수행했을 때, 그 사이에 다른 트랜잭션이 데이터를 수정하거나 삭제하여 첫 번째 조회와 두 번째 조회 결과가 달라지는 현상입니다. Transaction 1 Transaction 2 SELECT age FROM users WHERE id = 1; UPDATE users SET age = 21 WHERE id = 1; COMMIT; SELECT age FROM users WHERE id = 1; COMMIT; 위 예시에서 Transaction 1은 같은 데이터를 두 번 조회했지만, 중간에 Transaction 2가 데이터를 수정했기 때문에 결과가 일관되지 않습니다. Phantom Read # 한 트랜잭션 내에서 일정 범위의 레코드를 두 번 이상 읽었을 때, 첫 번째 쿼리에서는 없었던 새로운 레코드가 이후 쿼리에서 나타나는 현상을 말합니다. 이는 주로 레코드 삽입과 관련된 문제입니다. Transaction 1 Transaction 2 SELECT age FROM users WHERE age \u0026lt; 20 INSERT INTO users(name, age) VALUES ('홍길동', 10); COMMIT; SELECT age FROM users WHERE age \u0026lt; 20; COMMIT; 위 예시에서 Transaction 1은 처음에는 조건에 맞는 레코드가 없었지만, 중간에 Transaction 2가 새로운 레코드를 삽입하면서 결과가 달라집니다. Isolation Level # 데이터베이스는 위와 같은 문제를 해결하기 위해 네 가지 격리 수준을 제공합니다. 각 격리 수준은 허용되는 동시성 문제와 성능 간의 균형을 다르게 설정합니다. Read Uncommitted # 커밋되지 않은 데이터를 다른 트랜잭션이 읽는 것을 허용합니다. 가장 낮은 격리 수준으로, Dirty Read, Non-repeatable Read, Phantom Read 문제가 모두 발생할 수 있습니다. 성능은 가장 뛰어나지만 데이터 일관성이 낮습니다. Read Committed # 커밋된 데이터만 다른 트랜잭션이 읽는 것을 허용합니다. Dirty Read 문제는 방지하지만, 여전히 Non-repeatable Read와 Phantom Read 문제가 발생할 수 있습니다. 대부분의 DBMS가 기본 격리 수준으로 채택하고 있는 모드입니다. Repeatable Read # 한 트랜잭션이 읽은 데이터를 다른 트랜잭션이 수정하거나 삭제하지 못하도록 보장합니다. Non-repeatable Read 문제를 방지하며, 동일한 데이터를 여러 번 조회해도 항상 일관된 결과를 얻을 수 있습니다. 그러나 여전히 Phantom Read 문제가 발생할 가능성이 있습니다. Serializable # 가장 높은 격리 수준으로, 모든 트랜잭션을 직렬화하여 처리하는 것처럼 동작합니다. 선행 트랜잭션이 읽은 데이터에 대해 후행 트랜잭션이 수정, 삭제뿐만 아니라 새로운 레코드 삽입도 불가능하게 만듭니다. 완벽한 데이터 일관성을 보장하지만 성능 저하가 크며, 동시성 처리 능력이 크게 제한됩니다. 결론 # Isolation level은 트랜잭션 간의 동시성과 데이터 일관성 사이에서 균형을 맞추기 위한 중요한 설정입니다. 애플리케이션의 요구 사항과 시스템 성능 목표에 따라 적절한 격리 수준을 선택하는 것이 중요합니다. 예를 들어, 금융 시스템처럼 높은 데이터 일관성이 요구되는 경우에는 Serializable 수준을 고려해볼 수 있으며, 반대로 높은 성능과 동시성이 중요한 경우에는 Read Committed나 Read Uncommitted를 선택할 수 있습니다.","date":"2021-09-28T20:30:02+09:00","href":"https://disj11.github.io/understanding-isolation-level-in-database-management/","objectID":"b01a54df9b1a54a03c056e00f3bb0052_0","order":0,"tags":["database"],"title":"트랜잭션 격리 수준(Isolation Level)의 이해: 데이터 일관성과 성능의 균형"}]