[{"content":"TL;DR # JPA 에서 ID 에 val 을 사용해도 save 이후 ID 가 잘 설정된다. 코드 예제 # Member.kt @Entity class Member( @Id @GeneratedValue(strategy = GenerationType.IDENTITY) val id: Long = 0L, @Column( name = \u0026#34;name\u0026#34;, length = 30, nullable = false, ) var name: String, ) MemberRepository.kt @Repository interface MemberRepository : JpaRepository\u0026lt;Member, Long\u0026gt; 사용처 val member = Member(name = \u0026#34;홍길동\u0026#34;) // member.id = 0 val savedMember = memberRepository.save(member) // savedMember.id = 1 println(member.id) // member.id = 1 보는 바와 같이 val 로 id 를 설정하였어도 save 이후에 id 값이 잘 설정된다. 하지만 일반적으로 val 은 값이 변한다고 생각하지 않기 때문에 값을 저장한 이후에는 member 대신 savedMember 를 사용하는 것이 좋아 보인다.","date":"2023-09-15T05:10:46+09:00","href":"https://disj11.github.io/jpa-val-id-in-kotlin/","objectID":"55fc53d7c26247060b9396af409ee82e_0","order":0,"tags":["JPA","TIL"],"title":"코틀린에서 JPA 사용시 ID 에 val 사용하기"},{"content":"Configuration # connectionTimeout # 클라이언트가 커넥션을 요청한 이후에 커넥션을 얻기까지 기다릴 수 있는 최대 시간을 제어한다. 이 시간을 초과하면 SQLException 이 발생한다. 허용되는 최소값은 250ms 이며 기본값은 30,000ms (30초) 이다. idleTimeout # 커넥션이 유휴 상태(사용되지 않는 상태)로 유지될 수 있는 최대 시간을 제어한다. 이 설정은 minimumIdle 값이 maximumPoolSize 보다 작은 경우에만 적용된다. 설정된 시간 동안 커넥션이 사용되지 않으면 해당 커넥션은 커넥션풀에서 제거된다. 이 때 커넥션풀에 있는 유휴 상태의 커넥션이 miniumIdle 과 같다면 제거되지 않는다. 커넥션이 유휴 상태로 변경되는데에는 최대 +30초 에서 평균 +15초의 변동이 있을 수 있다. 이 값이 0이라면 유휴 커넥션을 제거하지 않는다. 이 값을 설정할 수 있는 최소값은 10,000ms (10초) 이며 기본값은 600,000ms (10분) 이다. NOTE: 커넥션 사용 이후 커넥션풀에 커넥션을 다시 반환하면 해당 커넥션의 idle time 은 다시 0으로 초기화된다. maxLifetime # 커넥션풀에 커넥션이 존재할 수 있는 최대 수명을 제어한다. 이 시간을 초과하면 커넥션풀에 있는 커넥션을 제거한다. 이때 현재 사용중인 커넥션이라면 커넥션을 제거하지 않는다. 커넥션풀에 있는 커넥션의 대량 제거를 방지하기 위해서 커넥션별로 시간 차이를 두며 작동한다. 이 값은 데이터베이스의 연결 시간 제한(MySQL인 경우 wait_timeout) 보다 짧아야 하며 네트워크 지연을 고려하여 wait_timeout 설정보다 2~3초 정도 짧게 줄 것을 권고한다. 이 값이 0이라면 최대 수명이 없음 (무한 수명) 을 의미한다. 허용되는 최소 값은 30,000ms (30초) 이며 기본값은 1,800,000ms (30분) 이다. NOTE: 커넥션 사용 여부와 관련 없이, 말 그대로 커넥션이 존재할 수 있는 최대 수명이다. minimumIdle # 최소 유휴 연결 수를 유지하기 위한 설정이다. 유휴 연결이 이 값보다 적어지고 총 커넥션이 maximumPoolSize 보다 작은 경우 HikariCP 는 빠르고 효율적으로 커넥션을 추가하기 위한 작업을 수행한다. 기본값은 maximumPoolSize 와 동일하다. maximumPoolSize # 유휴 커넥션과 사용 중인 커넥션을 모두 포함한 커넥션의 최대 수를 제어한다. 커넥션 요청시 유휴 커넥션이 없다면 connectionTimeout 만큼 차단되며, 이 시간동안 커넥션을 얻지 못할 시 SQLException 이 발생한다. 기본값은 10 이다. 참고 # HikariCP README.md 참고","date":"2023-09-02T15:16:53+09:00","href":"https://disj11.github.io/hikari-cp-configuration/","objectID":"b89d3496ac3560f046075f9c228fb2b6_0","order":0,"tags":["database"],"title":"HikariCP 자주 사용 하는 설정값 정리"},{"content":"JIT Compiler 란? # 자바 코드의 실행을 위해서는 바이트 코드로 컴파일이 필요하다. 바이트 코드는 다시 JVM 의 인터프리터를 통해 기계어로 해석되는 과정을 거쳐 실행된다. 이런 이유로 인터프리터를 통해 해석되는 과정없이 실행되는 언어에 비해 많이 느리다. 이러한 성능 차이를 해결하기 위해 JVM 에서는 JIT (Just In Time) Compiler 를 도입하였다. JIT Compiler 에 대한 자세한 내용 # Oracle 에서는 JDK 1.3 부터 HotSpot 이라는 가상 머신을 포함한다. 여기에는 C1 이라고 하는 클라이언트 컴파일러와 C2 라고 하는 서버 컴파일러 두 개의 JIT 컴파일러가 포함되어 있다. C1은 더 빠르게 실행되고 조금 덜 최적화 된 코드를 생성하도록 설계되었고, C2 는 실행하는데 시간이 좀 더 소요되지만 더 최적화 된 코드를 생성하도록 설계되었다. Tiered Compilation # JVM은 호출되는 메서드를 추적하고 자주 호출되는 메서드를 C1을 사용하여 컴파일한다. C1으로 컴파일된 메서드의 호출수가 증가하면 C2를 사용하여 한번 더 컴파일한다. 이해를 위해 간단하게 적었지만 세부적인 Compilation Levels 은 다음과 같다: Level 0 – Interpreted Code Level 1 – Simple C1 Compiled Code Level 2 – Limited C1 Compiled Code Level 3 – Full C1 Compiled Code Level 4 – C2 Compiled Code 각 레벨에 대해 더 자세한 내용을 확인하고 싶다면 Compilation Levels을 참고한다. 언제 C1, C2 를 사용하여 컴파일이 일어나는지 궁금하다면 다음 명령어를 통해 임계값을 확인할 수 있다: java -XX:+PrintFlagsFinal -version | grep Threshold | grep Tier openjdk version \u0026#34;17.0.7\u0026#34; 2023-04-18 OpenJDK Runtime Environment Temurin-17.0.7+7 (build 17.0.7+7) OpenJDK 64-Bit Server VM Temurin-17.0.7+7 (build 17.0.7+7, mixed mode, sharing) uintx IncreaseFirstTierCompileThresholdAt = 50 {product} {default} intx Tier2BackEdgeThreshold = 0 {product} {default} intx Tier2CompileThreshold = 0 {product} {default} intx Tier3BackEdgeThreshold = 60000 {product} {default} intx Tier3CompileThreshold = 2000 {product} {default} intx Tier3InvocationThreshold = 200 {product} {default} intx Tier3MinInvocationThreshold = 100 {product} {default} intx Tier4BackEdgeThreshold = 40000 {product} {default} intx Tier4CompileThreshold = 15000 {product} {default} intx Tier4InvocationThreshold = 5000 {product} {default} intx Tier4MinInvocationThreshold = 600 {product} {default} Tier3InvocationThreshold 와 Tier3BackEdgeThreshold, Tier3CompileThreshold 를 살펴보자. 맨 앞의 Tier3는 Level 3 로 컴파일 되기 위한 임계값임을 나타내며 각각의 의미는 다음과 같다: Tier3InvocationThreshold: 메서드 호출 횟수의 임계값을 나타낸다. Tier3BackEdgeThreshold: 백 엣지의 임계값을 나타낸다. Tier3CompileThreshold: 메서드 호출 횟수 임계값과 백 엣지 임계값의 합 백 엣지란, 반복문 등에서 이전 실행한 블록으로 돌아가는 분기 구문을 말한다. 예를들어 for 반복문의 경우 조건을 검사하고 조건문이 참이라면 다시 for 반복문의 블록으로 돌아가게 되는데, 이를 백 엣지라고 한다. 이 페이지에 메서드를 컴파일해야하는지 여부를 판단하기 위한 로직이 설명되어 있으며, 이를 코드로 표현하면 다음과 같다: function shouldCompileMethod(invocationCount, backEdgeCount) { if (invocationCount \u0026gt; Tier3InvocationThreshold) { return true; } if (invocationCount \u0026gt; Tier3MinInvocationThreshold \u0026amp;\u0026amp; invocationCount + backEdgeCount \u0026gt; Tier3CompileThreshold ) { return true; } return false; } 이 로직과 위의 임계값 정보를 바탕으로 메서드를 몇번 호출해야 컴파일이 일어날지 예측해보자. 먼저 위에서 찾은 Tier3 임계값이 다음과 같았다: intx Tier3CompileThreshold = 2000 intx Tier3InvocationThreshold = 200 intx Tier3MinInvocationThreshold = 100 만약 어떤 메서드가 있고, 메서드를 한번 호출할 때마다 20개의 loop back-edge count 를 생성한다고 해보자. 이 메서드는 100번 호출될 때 컴파일 될 것을 예측할 수 있다. (정확한 횟수는 아니므로 테스트는 해봐야 함.) 100 + (20 * 100) \u0026gt; 2000 --- ---------- ---- 1 2 3 1: 메서드 호출 횟수 2: back-edge 3: Tier3CompileThreshold 실제로 최적화가 일어나는지 확인해보고 싶다면 아래의 VM Options 를 추가하여 확인할 수 있다: -XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation 옵션을 추가하고 프로그램을 실행하면 hotspot_pid\u0026lt;pid\u0026gt;.log 형식의 파일이 생성된다. 샘플 코드를 통해 실제로 최적화가 일어나는지 확인해보자: fun main() { val arr = intArrayOf(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) (1..3000).forEach { i -\u0026gt; findMax(arr) if (i % 100 == 0) { // 너무 빨리 종료되면 c2 컴파일이 안될 수도 있어서 Thread.sleep(100) } } } fun findMax(arr: IntArray): Int { var max = arr[0] for (i in 1 until arr.size) { if (max \u0026lt; arr[i]) { max = arr[i] } } return max } 위 프로그램을 실행하면 hotspot_pid\u0026lt;pid\u0026gt;.log 파일이 생긴다. 파일을 열어보면 다음과 같이 level 3 컴파일을 위해 c1 queue 에 메서드가 적재된 것을 확인할 수 있다. \u0026lt;task_queued compile_id=\u0026#39;205\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;228\u0026#39; backedge_count=\u0026#39;2048\u0026#39; iicount=\u0026#39;228\u0026#39; level=\u0026#39;3\u0026#39; stamp=\u0026#39;0.438\u0026#39; comment=\u0026#39;tiered\u0026#39; hot_count=\u0026#39;228\u0026#39;/\u0026gt; count 와 backedge_count 를 통해 메서드가 몇 번 호출되었는지와 백엣지 수를 확인할 수 있다. 조금 더 아래 로그를 살펴보면 다음과 같이 level 3 로 코드 최적화가 된 것을 확인할 수 있다. \u0026lt;nmethod compile_id=\u0026#39;205\u0026#39; compiler=\u0026#39;c1\u0026#39; level=\u0026#39;3\u0026#39; entry=\u0026#39;0x00000208cb1883a0\u0026#39; size=\u0026#39;2560\u0026#39; address=\u0026#39;0x00000208cb188190\u0026#39; relocation_offset=\u0026#39;344\u0026#39; insts_offset=\u0026#39;528\u0026#39; stub_offset=\u0026#39;1872\u0026#39; scopes_data_offset=\u0026#39;2040\u0026#39; scopes_pcs_offset=\u0026#39;2216\u0026#39; dependencies_offset=\u0026#39;2520\u0026#39; nul_chk_table_offset=\u0026#39;2528\u0026#39; oops_offset=\u0026#39;1992\u0026#39; metadata_offset=\u0026#39;2008\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;228\u0026#39; backedge_count=\u0026#39;2048\u0026#39; iicount=\u0026#39;228\u0026#39; stamp=\u0026#39;0.438\u0026#39;/\u0026gt; 마찬가지로 level 4 로 코드가 최적화 된 것도 로그를 통해 확인할 수 있다. \u0026lt;task_queued compile_id=\u0026#39;207\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;2048\u0026#39; backedge_count=\u0026#39;18432\u0026#39; iicount=\u0026#39;2048\u0026#39; stamp=\u0026#39;2.914\u0026#39; comment=\u0026#39;tiered\u0026#39; hot_count=\u0026#39;2048\u0026#39;/\u0026gt; \u0026lt;nmethod compile_id=\u0026#39;207\u0026#39; compiler=\u0026#39;c2\u0026#39; level=\u0026#39;4\u0026#39; entry=\u0026#39;0x00000208d2c30820\u0026#39; size=\u0026#39;1232\u0026#39; address=\u0026#39;0x00000208d2c30690\u0026#39; relocation_offset=\u0026#39;344\u0026#39; insts_offset=\u0026#39;400\u0026#39; stub_offset=\u0026#39;880\u0026#39; scopes_data_offset=\u0026#39;936\u0026#39; scopes_pcs_offset=\u0026#39;1056\u0026#39; dependencies_offset=\u0026#39;1184\u0026#39; handler_table_offset=\u0026#39;1192\u0026#39; nul_chk_table_offset=\u0026#39;1216\u0026#39; oops_offset=\u0026#39;920\u0026#39; metadata_offset=\u0026#39;928\u0026#39; method=\u0026#39;com.kotlin.JitTestKt findMax ([I)I\u0026#39; bytes=\u0026#39;39\u0026#39; count=\u0026#39;2100\u0026#39; backedge_count=\u0026#39;18900\u0026#39; iicount=\u0026#39;2100\u0026#39; stamp=\u0026#39;2.917\u0026#39;/\u0026gt; JIT Compiler 가 정말 성능을 향상시켜주는지 알고 싶다면 -Xint 옵션으로 Jit Compiler 사용을 중지하고 테스트 해 볼 수 있다. 앞에서 살펴본 코드를 조금 변경하여 총 3번 실행해보았다. fun main() { val arr = intArrayOf(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) val startTimeMills = System.currentTimeMillis() (1..1_0000_0000).forEach { i -\u0026gt; findMax(arr) } println(\u0026#34;실행시간: ${System.currentTimeMillis() - startTimeMills}ms\u0026#34;) } fun findMax(arr: IntArray): Int { var max = arr[0] for (i in 1 until arr.size) { if (max \u0026lt; arr[i]) { max = arr[i] } } return max } JIT Compiler 를 활성화한 경우: 실행시간: 1595ms 실행시간: 875ms 실행시간: 1252ms JIT Compiler 를 비활성화 한 경우: 실행시간: 28558ms 실행시간: 32401ms 실행시간: 24760ms NOTE: spring boot 애플리케이션을 IntelliJ 에서 실행할 때 -XX:TieredStopAtLevel=1 를 자동으로 추가한다. 이로 인해 level 1 으로만 컴파일 되는 문제가 있다. (Jetbrains Issue) 정확한 확인을 위해서는 bootJar 를 만들어 java -jar 를 통해 직접 실행시켜야한다. java -XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation -Dspring.profiles.active=local -jar excutable.jar \u0026gt; spring-boot.log 참고 자료 # https://www.baeldung.com/jvm-tiered-compilation https://www.baeldung.com/graal-java-jit-compiler https://www.lmax.com/blog/staff-blogs/2016/03/05/observing-jvm-warm-effects/ https://www.oreilly.com/library/view/java-performance-the/9781449363512/ch04.html https://hg.openjdk.org/jdk8/jdk8/hotspot/file/104743074675/src/share/vm/runtime/advancedThresholdPolicy.hpp https://www.youtube.com/watch?v=CQi3SS2YspY\u0026amp;list=PLyGtIjZ_uWKNT5-ob1TL26hH0KVfoJQzw","date":"2023-05-10T23:56:05+09:00","href":"https://disj11.github.io/java-jit-compiler/","objectID":"4658aac5581ac910f876ff199ba0868c_0","order":0,"tags":["development"],"title":"Java JIT Compiler"},{"content":"Glue workflow 사용중 3시간 정도 걸리는 Glue Job 이 발견되었다. Worker 의 수를 10 -\u0026gt; 30 으로 올리니 17분 정도로 드라마틱하게 단축되어 왜 이런 현상이 발생하였는지 찾아보았다. Spark 에는 Shuffle Partition 이란 게 존재한다. join, groupBy 등의 연산을 수행할 때 이 Shuffle Partition 이 사용된다. 이 Shuffle Partition 은 Spark의 성능에 가장 큰 영향을 미치는 Partition 이다. 연산에 쓰이는 메모리가 부족할 때 Shuffle Spill (데이터를 직렬화 하고 스토리지에 저장, 데이터 처리 이후에 역직렬화 후 연산 재개) 이 발생한다. Shuffle Spill 이 일어나면, Task 가 지연되고 에러가 발생할 수 있다. 이 문제를 해결하기 위해서는 Core 당 메모리를 늘려야한다. 참고 사이트: https://aws.amazon.com/ko/blogs/big-data/introducing-amazon-s3-shuffle-in-aws-glue/ https://tech.kakao.com/2021/10/08/spark-shuffle-partition/","date":"2023-05-10T18:58:24+09:00","href":"https://disj11.github.io/shuffle-operation-in-glue/","objectID":"d76ce26aee8040146e22a71588af6dcc_0","order":0,"tags":["TIL","AWS","Glue"],"title":"Shuffle Operation in Glue"},{"content":"SQS 의 Queue type 에는 Standard 와 FIFO 가 있다. Standard queues 는 At-least-once delivery, Best-Effort Ordering 으로 작동한다. At-least-once delivery 는 적어도 한번 메시지가 전달된다는 의미로 같은 메시지가 경우에 따라 두 번 이상 전달될 수 있다. Best-Effort Ordering 은 경우에 따라 메시지의 순서가 보장되지 않는 것을 의미한다. 이러한 특성으로 Standard queues 를 사용하는 어플리케이션은 멱등성(idempotent) 을 보장해야 한다. 높은 처리량이 필요한 어플리케이션에 주로 사용한다. FIFO 는 Exactly-Once Processing, First-In-First-Out Delivery 로 작동한다. 메시지는 정확히 한 번 처리되며 메시지를 보내고 받는 순서가 보장된다. 이벤트 순서가 중요한 어플리케이션에 주로 사용한다. 참고 사이트: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-types.html","date":"2023-05-06T12:55:31+09:00","href":"https://disj11.github.io/sqs-queue-types/","objectID":"109cba42c1c691bccb86eaa42fac11ff_0","order":0,"tags":["TIL","AWS","SQS"],"title":"SQS Queue Types"},{"content":"메인 시퀀스로부터의 거리(distance from the main sequence)는 아키텍처 구조를 평가하는 몇 가지 메트릭중의 하나이다. 메인 시퀀스로부터의 거리는 불안정도와 추상도를 이용하여 계산하므로 먼저 불안정도와 추상도에 대해 알아보자. 추상도 (abstractness) # 추상도는 (추상 클래스, 인터페이스 등의) 추상 아티팩트(abstract artifact)와 구상 아티팩트(concrete artifact, 구현체)의 비율, 즉 구현 대비 추상화 정도를 나타낸다. 다음은 추상도를 구하는 공식이다. (Ma 는 모듈에 있는 추상 요소 (인터페이스 또는 추상 클래스), Mc는 구상 요소 (비 추상 클래스)) 예를 들어 5,000 라인의 코드를 모두 main() 메서드에 구현한 애플리케이션의 분자는 1, 분모는 5,000 이므로 추상도는 0에 가깝다. 불안정도 (instability) # 불안정도는 원심 커플링과 (구심 커플링 + 원심 커플링) 의 비율이다. 공식은 다음과 같다. (Ce는 원심 커플링, Ca는 구심 커플링) 여기에서 구심(afferent) 커플링은 (컴포넌트, 클래스, 함수 등의) 코드 아티팩트로 유입되는(incoming) 접속 수를, 원심(efferent) 커플링은 다른 코드 아티팩트로 유출되는(outgoing) 접속 수를 나타낸다. 불안정도는 코드베이스의 변동성(volatility)을 의미하므로 불안정도가 높은 코드베이스는 변경 시 커플링이 높아 더 깨지기 쉽다. 예를 들어, 여러 다른 클래스를 호출하는 클래스는 호출되는 메서드 중 하나라도 변경되면 호출하는 이 클래스 역시 잘못될 확률이 높다. 메인 시퀀스로부터의 거리 # 메인 시퀀스로부터의 거리는 불안정도와 추상도를 이용하여 계산한다. 공식은 다음과 같다. (A는 추상도를, I는 불안정도) 추상도와 불안정도는 비율이므로 항상 0과 1 사이의 값이다. 따라서 다음과 같은 그래프로 표현할 수 있다. 메인 시퀀스로부터의 거리가 메인 시퀀스에 가까울수록 추상도와 불안정도 사이에 균형을 잘 이룬다고 볼 수 있다. 오른쪽 위로 치우친 부분을 쓸모없는 구역(zone of uselessness), 반대로 왼쪽 아래로 치우친 부분을 고통스러운 구역(zone of pain) 이라고 부른다. 쓸모없는 구역에 속한 클래스는 추상화를 너무 많이해서 사용하기 어려운 코드이고, 고통스런 구역에 속한 클래스는 추상화를 거의 하지 않아 취약하고 관리하기 힘든 코드이다.","date":"2023-03-12T14:09:09+09:00","href":"https://disj11.github.io/distance-from-the-main-sequence/","objectID":"0b2a90ca1841f6eeb373c950ccca4592_0","order":0,"tags":["software engineering"],"title":"메인 시퀀스로부터의 거리를 사용한 아키텍처 구조 평가"},{"content":"응집 (cohesion) # 응집은 소프트웨어 개발에서 중요한 개념 중 하나로, 모듈 내의 구성 요소들이 서로 얼마나 연관되어 있는지를 나타낸다. 컴퓨터 과학자들은 응집도의 측정 범위를 정의했는데, 가장 좋은 것부터 나쁜 것 순으로 나열하면 다음과 같다. 기능적 응집 (functional cohesion) # 모듈의 각 파트는 다른 파트와 연관되어 있고 기능상 꼭 필요한 모든 것이 모듈에 들어있다. 순차적 응집 (sequential cohesion) # 한 모듈이 데이터를 출력하면 다른 한 모듈이 그것을 입력받는 형태로 상호작용한다. 소통적 응집 (communication cohesion) # 두 모듈이, 각자의 정보에 따라 작동하고(거나) 어떤 출력을 내는 형태로 통신 체인 (communication chain) 을 형성한다. 예를 들어, 데이터베이스에 레코드를 추가하면 그 정보에 따라 이메일이 만들어지는 형식이다. 절차적 응집 (procedural cohesion) # 두 모듈은 정해진 순서대로 실행되어야 한다. 일시적 응집 (temporal cohesion) # 모듈은 시점 의존성 (timing dependency) 에 따라 연관된다. 예를 들어, 시스템들이 시동할 때 그대지 관련이 없어 보이는 것들을 초기화 하는 경우가 많은데, 이런 작업들이 일시적으로 응집되었다고 할 수 있다. 논리적 응집 (logical cohesion) # 모듈의 내부 데이터는 기능적이 아니라, 논리적으로 연관되어 있다. 예를 들어 자바의 StringUtils 패키지는 각기 다른 작업을 수행하는 정적 메서드가 많이 있지만 서로 연관성은 없다. 동시적 응집 (coincidental cohesion) # 같은 소스 파일에 모듈 구성 요소가 들어 있지만 그 외에는 아무 연관성도 없다. 이는 가장 좋지 않은 형태의 응집이다. LCOM (Lack of Cohesion in Methods) # 코드의 응집도를 평가하기 위해서는 LCOM(응집 결여도, Lack of Cohesion in Methods) 메트릭을 사용할 수 있다. LCOM의 공식이 있지만 하나씩 말로 풀이하는 게 더 쉽게 때문에 공식을 따로 적지는 않겠다. LCOM의 공식을 말로 풀면, 공유 필드를 통해 공유되지 않는 메서드의 총 개수를 뜻한다. 예를 들어, private field a, b 가 있는 클래스가 있다고 하자. 이 클래스 안에는 a 만 엑세스 하는 메서드가 있고, b 만 엑세스하는 메서드도 있다. 공유 필드 (a와 b) 를 통해 공유되지 않는 메서드도 많이 존재한다. 그렇다면 이 클래스의 LCOM 점수는 높다고 할 수 있다. 즉 메서드의 응집 결여도가 높은 것이다. 좀 더 확실히 이해하기 위해 다음 그림을 보자. (필드는 육각형, 메서드는 사각형으로 표시) 클래스 X는 LCOM 점수가 낮고 구조적 응집이 우수하다. 반면, 클래스 Y는 응집이 결여되어 있고, 필드/메서드 세 쌍을 각자 자기의 클래스에 두어도 별로 상관이 없을 듯 하다. 클래스 Z는 응집이 조함된 모양새로, 세 번째 필드/메서드 쌍은 자체 클래스로 빼내어도 될 것 같다. 이처럼 LCOM 메트릭은 코드베이스를 분석하는데 매우 유용하다. 하지만 소프트웨어 메트릭은 거의 대부분 한두가지 중요한 결함이 있는데, LCOM도 예외가 아니다. LCOM 메트릭이 찾아내는 것은 \u0026lsquo;구조적\u0026rsquo; 응집 결여도 일 뿐, 이 메트릭만으로는 어떤 조각들이 서로 잘 맞는지 논리적으로 판단할 수는 없다. 이후에 보면 좋은 포스트: 메인 시퀀스로부터의 거리","date":"2023-03-12T11:41:11+09:00","href":"https://disj11.github.io/cohesion-in-software-engineering/","objectID":"a35cbd56dc52fb38d6b50c76480a89b6_0","order":0,"tags":["software engineering"],"title":"응집도를 측정할 수 있는 방법"},{"content":"확장성 # 확장성 은 증가한 부하에 대처하는 시스템의 능력을 설명하는데 사용되는 용어이다. 확장성을 논할 때 \u0026ldquo;X는 확장 가능하다\u0026rdquo; 또는 \u0026ldquo;Y는 확장성이 없다\u0026rdquo; 와 같은 말은 의미가 없다. 확장성을 논한다는 것은 \u0026ldquo;시스템이 커진다면 이에 대처하기 위한 선택은 무엇인가?\u0026rdquo; 와 \u0026ldquo;추가 부하를 다루기 위해 자원을 어떻게 투입할까?\u0026rdquo; 와 같은 질문을 고려한다는 의미이다. 부하 기술하기 # 이러한 질문에 답변을 위해서는 현재 시스템의 부하를 간결하게 기술해야한다. 그래야 부하 성장 질문(부하가 두 배로 된다면 어떻게 될까?)을 논의할 수 있다. 부하는 부하 매개변수(load parameter) 라 부르는 몇 개의 숫자로 나타낼 수 있다. 시스템에 따라 적합한 부하 매개변수는 달라질 수 있지만, 일반적으로 다음과 같은 부하 매개변수들이 있다: 웹 서버의 초당 요청 수 데이터베이스의 읽기 대 쓰기 비율 동시 활성 사용자 (active user) 캐시 적중률 부하 매개변수는 평균적인 경우가 중요할 수도 있고, 소수의 극단적인 경우가 병목 현상의 원인일 수도 있다. 성능 기술하기 # 부하를 기술하면 부하가 증가할 때 어떤 일이 일어나는지 조사할 수 있다: 부하 매개변수를 증가시키고 시스템 자원(CPU, 메모리, 네트워크 대역폭)은 변경하지 않는다면 시스템 성능에 어떤 영향을 미칠까? 부하 매개변수를 증가시켰을 때 성능을 유지시키길 원한다면 자원을 얼마나 많이 늘려야 할까? 두 질문에 답변을 하기 위해서는 성능 수치가 필요하다. 하둡과 같은 일괄 처리 시스템은 보통 처리량(throughput) (초당 처리할 수 있는 레코드 수 또는 일정 크기의 데이터 집합으로 작업을 수행할 때 걸리는 시간) 에 관심을 가진다. 온라인 시스템이라면 서비스 응답 시간(response time) (클라이언트가 요청을 보내고 응답을 받기까지의 시간) 에 관심을 둔다. 동일한 요청을 하더라도 매번 응답 시간이 다르기때문에, 응답 시간은 단일 숫자가 아니라 측정 가능한 분포로 생각해야한다. 응답 시간을 살필 때는 평균 응답 시간은 좋은 지표가 아니다. 평균은 얼마나 많은 사용자가 실제로 지연을 경험했는지 알려주지 않기 때문이다. 대신 백분위(percentile) 를 사용하는 것이 좋다. 응답 시간 목록을 가장 빠른 시간부터 제일 느린 시간 순으로 정렬했을 때 중간 지점을 중앙값(median) 이라고 한다. 예를 들어 중간 응답 시간이 200밀리초 라면 사용자중 절반은 응답 시간 미만으로, 나머지 절반은 응답 시간보다 오래 걸렸다는 의미가 된다. 이렇게 특이 값(outlier) (대부분의 요청은 빠르지만 가끔 꽤 오래 걸리는 특이 값) 을 측정하기 위해서 상위 백분위를 살펴보는 것도 좋다. 주로 95분위(p95), 99분위(p99), 99.9분위(p999) 가 일반적이다. 이는 각각, 요청의 95%, 99%, 99.9%가 특정 기준치보다 더 빠르다면, 해당 기준치가 각 백분위의 응답 시간 기준치가 된다는 의미이다. 예를 들어, 95분위 응답 시간이 1.5초라면 100개의 요청 중 95개는 1.5초 미만이고, 5개는 1.5초보다 더 걸린다는 의미이다. 꼬리 지연 시간(tail latency) 로 알려진 상위 백분위 응답 시간은 서비스의 사용자 경험에 직접적인 영양을 주기 때문에 중요한 수치가 될 수 있다.","date":"2023-02-05T12:15:15+09:00","href":"https://disj11.github.io/what-you-need-to-know-first-for-scalability/","objectID":"4a0cc8ecd24023d79932941231a36c42_0","order":0,"tags":["development"],"title":"확장성을 위해 먼저 알아야할 사항"},{"content":"Windows 초기 설정 # Windows 최초 설치 후 설정 정리 날개셋 한글 입력기 설치 # 세벌식 유저이므로 날개셋 한글 입력기를 다운받는다. vim 유저이므로 ESC 누를 시 영문으로 전환하는 기능을 설정한다. 설정 방법은 아래 이미지를 참고한다. PowerToys # Microsoft Store 에서 Microsoft PowerToys 를 찾아 설치한다. Scoop # scoop 을 다운 받는다. Set-ExecutionPolicy RemoteSigned -Scope CurrentUser # Optional: Needed to run a remote script the first time irm get.scoop.sh | iex Git # Git 을 다운 받는다. scoop install git VIM # gvim 을 다운받는다. 설치 시 Create .bat files 를 체크한다. 이 옵션을 체크하면 명령 프롬프트에서 vim 명령 사용이 가능해진다. vim-plug 를 설치한다. powershell 을 실행하여 다음 명령어를 입력한다. iwr -useb https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim |` ni $HOME/vimfiles/autoload/plug.vim -Force _vimrc 파일을 작성한다. C:\\Users\\사용자계정 위치에 _vimrc 파일을 생성한 뒤 다음 내용을 입력한다. let mapleader=\u0026#34; \u0026#34; set encoding=UTF-8 set number set showcmd set incsearch set ignorecase set scrolloff=5 set clipboard=unnamed set smartindent set expandtab set tabstop=4 set shiftwidth=4 set softtabstop=4 map \u0026lt;Home\u0026gt; ^ map \u0026lt;End\u0026gt; $ nnoremap \u0026lt;leader\u0026gt;ca ggVG \u0026#34; vim-plug call plug#begin() Plug \u0026#39;ryanoasis/vim-devicons\u0026#39; Plug \u0026#39;joshdick/onedark.vim\u0026#39; Plug \u0026#39;vim-airline/vim-airline\u0026#39; Plug \u0026#39;vim-airline/vim-airline-themes\u0026#39; Plug \u0026#39;terryma/vim-multiple-cursors\u0026#39; Plug \u0026#39;preservim/nerdtree\u0026#39; Plug \u0026#39;easymotion/vim-easymotion\u0026#39; Plug \u0026#39;tpope/vim-commentary\u0026#39; Plug \u0026#39;tpope/vim-surround\u0026#39; call plug#end() syntax on colorscheme onedark let g:airline_theme=\u0026#39;onedark\u0026#39; let NERDTreeMapOpenVSplit=\u0026#39;v\u0026#39; let NERDTreeMapPreviewVSplit=\u0026#39;gv\u0026#39; let NERDTreeMapOpenSplit=\u0026#39;s\u0026#39; let NERDTreeMapPreviewSplit=\u0026#39;gs\u0026#39; nnoremap \u0026lt;leader\u0026gt;nt :NERDTreeToggle\u0026lt;CR\u0026gt; nnoremap \u0026lt;leader\u0026gt;nc :NERDTreeFind\u0026lt;CR\u0026gt; nnoremap \u0026lt;leader\u0026gt;nf :NERDTreeFocus\u0026lt;CR\u0026gt; nmap \u0026lt;leader\u0026gt;/ \u0026lt;Plug\u0026gt;(easymotion-bd-fn) nmap \u0026lt;leader\u0026gt;; \u0026lt;Plug\u0026gt;(easymotion-next) nmap \u0026lt;leader\u0026gt;, \u0026lt;Plug\u0026gt;(easymotion-prev) if has(\u0026#39;gui_running\u0026#39;) set guifont=JetBrainsMono\\ Nerd\\ Font\\ Mono:h13 endif \u0026#34; intellij if has(\u0026#39;ide\u0026#39;) set ideajoin set quickscope nmap \u0026lt;leader\u0026gt;* \u0026lt;Action\u0026gt;(FindUsages) nmap \u0026lt;leader\u0026gt;o \u0026lt;Action\u0026gt;(GotoFile) nmap \u0026lt;leader\u0026gt;f \u0026lt;Action\u0026gt;(FindInPath) nmap \u0026lt;leader\u0026gt;t \u0026lt;Action\u0026gt;(HideAllWindows) nmap \u0026lt;leader\u0026gt;gp \u0026lt;Action\u0026gt;(Vcs.UpdateProject) nmap \u0026lt;leader\u0026gt;gb \u0026lt;Action\u0026gt;(Git.Branches) nmap gd \u0026lt;Action\u0026gt;(GotoDeclaration) nmap gD \u0026lt;Action\u0026gt;(GotoImplementation) nmap ]m \u0026lt;Action\u0026gt;(MethodDown) nmap [m \u0026lt;Action\u0026gt;(MethodUp) \u0026#34; navigation nmap \u0026lt;leader\u0026gt;nr \u0026lt;Action\u0026gt;(RecentFiles) nmap \u0026lt;leader\u0026gt;nl \u0026lt;Action\u0026gt;(RecentLocations) \u0026#34; code nmap \u0026lt;leader\u0026gt;cd \u0026lt;Action\u0026gt;(Debug) nmap \u0026lt;leader\u0026gt;cr \u0026lt;Action\u0026gt;(Run) nmap == \u0026lt;Action\u0026gt;(ReformatCode) nmap \u0026lt;leader\u0026gt;co \u0026lt;Action\u0026gt;(OptimizeImports) nmap \u0026lt;leader\u0026gt;gg \u0026lt;Action\u0026gt;(Generate) nmap \u0026lt;leader\u0026gt;gc \u0026lt;Action\u0026gt;(GenerateConstructor) nmap \u0026lt;leader\u0026gt;go \u0026lt;Action\u0026gt;(OverrideMethods) nmap \u0026lt;leader\u0026gt;gi \u0026lt;Action\u0026gt;(ImplementMethods) nmap \u0026lt;leader\u0026gt;cn \u0026lt;Action\u0026gt;(NewElementSamePlace) \u0026#34; show nmap \u0026lt;leader\u0026gt;sd \u0026lt;Action\u0026gt;(QuickJavaDoc) nmap \u0026lt;leader\u0026gt;sp \u0026lt;Action\u0026gt;(ParameterInfo) nmap \u0026lt;leader\u0026gt;ss \u0026lt;Action\u0026gt;(FileStructurePopup) \u0026#34; refactor vmap \u0026lt;leader\u0026gt;rm \u0026lt;Action\u0026gt;(ExtractMethod) nmap \u0026lt;leader\u0026gt;rn \u0026lt;Action\u0026gt;(RenameElement) \u0026#34; vim-multiple-cursors nmap \u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextWholeOccurrence xmap \u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextWholeOccurrence nmap g\u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextOccurrence xmap g\u0026lt;C-n\u0026gt; \u0026lt;Plug\u0026gt;NextOccurrence nmap \u0026lt;C-x\u0026gt; \u0026lt;Plug\u0026gt;SkipOccurrence xmap \u0026lt;C-x\u0026gt; \u0026lt;Plug\u0026gt;SkipOccurrence nmap \u0026lt;C-p\u0026gt; \u0026lt;Plug\u0026gt;RemoveOccurrence xmap \u0026lt;C-p\u0026gt; \u0026lt;Plug\u0026gt;RemoveOccurrence nmap \u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllWholeOccurrences xmap \u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllWholeOccurrences nmap g\u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllOccurrences xmap g\u0026lt;S-C-n\u0026gt; \u0026lt;Plug\u0026gt;AllOccurrences endif vim 플러그인을 설치한다. powershell 을 관리자 권한으로 실행한다. vim 명령을 입력 후 vim 으로 진입한다. :PlugInstall 명령어를 통해 플러그인을 설치한다. Nerd Fonts 에서 JetBrainsMono Nerd Font 를 설치한다. 압축 해제하면 여러 개의 파일이 나오는데, JetBrains Mono Regular Nerd Font Complete Mono Windows Compatible 만 설치해도 된다. SDKMAN # 자바 버전 관리를 편하게 하기 위해 sdkman 을 설치한다. scoop bucket add palindrom615 https://github.com/palindrom615/scoop-bucket scoop install sdkman JDK # sdkman 을 사용하여 설치하고 싶은 자바를 선택하여 설치한다. sdk list java 명령어로 자바 버전을 확인할 수 있다. IntelliJ # JetBrains Toolbox App 을 설치한다. 이후 ToolBox App 에서 Intellij IDEA Ultimate 를 설치한다. IntelliJ 설치가 완료되면 아래의 플러그인을 설치한다. IdeaVim IdeaVim-EasyMotion IdeaVim-Quickscope 이외에 필요한 플러그인이 있다면, 추가적으로 설치한다. (Kotest 플러그인 등) 이후 vim 과 동일한 키 설정을 사용하기 하기 위해 .ideavimrc 에 다음 내용을 추가한다. source ~/_vimrc 개발 시 JDK 가 필요하다면 SDK 에 JDK 설치 경로를 추가한다. SDKMAN 으로 설치한 JDK 는 ~/.sdkman 위치에서 찾을 수 있다. Etc. # Hugo # 개인 블로그 개발 환경을 위해 hugo 설치 scoop install hugo-extended","date":"2023-01-30T09:10:13+09:00","href":"https://disj11.github.io/notes/windows-initial-setup/","objectID":"b73afb709007eb214f049c0b08270fc4_0","order":0,"tags":["settings"],"title":"Windows Initial Setup"},{"content":"Kotlin provides extension functions for the Iterable interface, such as the filter function. Here is an example of using the filter function: fun averageNonBlankLength(strings: List\u0026lt;String\u0026gt;): Double = strings .filter { it.isNotBlank() } .map(String::length) .sum() / strings.size.toDouble() It\u0026rsquo;s worth noting that the filter and map functions in Kotlin return new Lists, unlike their counterparts Stream.filter and Stream.map in Java, which return a Stream. In this example, two new intermediate lists are created in memory as the result of calling filter and map on the original list. However, this overhead may not be significant depending on the size of the original list and the complexity of the operations. If the size of the original list or complexity of the operation chain is high and memory usage is a concern, you might consider using sequence type instread of List . you can convert a list to a sequence via asSequence() function which will create a lazy sequence and perform operations on it. Another option is to use the sequenceOf(list) function which will create a sequence from the list. Here\u0026rsquo;s an example of using the sequence type to perform the same operation as the previous example: fun averageNonBlankLength(strings: List\u0026lt;String\u0026gt;): Double = strings.asSequence() .filter { it.isNotBlank() } .map(String::length) .sum() / strings.size.toDouble() In this example, the asSequence() function is used to convert the original List of strings to a Sequence of strings. Then, the filter and map functions are used to perform the same operations as before, but instead of creating intermediate Lists, a Sequence is returned from each function call. It\u0026rsquo;s worth noting that using a sequence allows for lazy evaluation, meaning that the elements of the sequence are only evaluated as they are needed, this can help to reduce the memory usage. Using a sequence can be beneficial when memory efficiency is a concern, particularly in situations where the size of the result set of data is not known ahead of time or when the operations are complex and intermediate results are unnecessary to be stored in memory. This is how the list processing goes: The sequence processing goes like this: If you would like to learn more about the sequence type in Kotlin, you can refer to the official documentation","date":"2023-01-10T23:59:43+09:00","href":"https://disj11.github.io/en/memory-efficient-iterable-data-processing-with-sequences/","objectID":"9196b793888e6c55f42104278dbfd7ea_0","order":0,"tags":["kotlin"],"title":"Kotlin: Memory Efficient Iterable Data Processing with Sequences"},{"content":"Kotlin은 filter 함수와 같은 Iterable 인터페이스를 위한 확장 함수를 제공한다. filter 함수를 사용하는 예제는 다음과 같다: fun averageNonBlankLength(strings: List\u0026lt;String\u0026gt;): Double = strings .filter { it.isNotBlank() } .map(String::length) .sum() / strings.size.toDouble() 한 가지 주목할 점은 Kotlin의 filter 및 map 함수는 Stream을 반환하는 Java의 Stream.filter 및 Stream.map과 달리 새로운 List를 반환한다는 점이다. 이 예제에서는 원본 리스트에서 filter 및 map을 호출한 결과로 메모리에 두 개의 새로운 리스트가 생성된다. 그러나 원본 리스트의 크기와 작업의 복잡성에 따라 이 오버헤드는 중요하지 않을 수 있다. 원본 리스트의 크기가 크거나 작업 체인의 복잡성이 커서 메모리 사용량이 우려되는 경우, List 대신 Sequence 타입을 사용할 수 있다. asSequence() 함수를 사용하여 리스트를 시퀀스로 변환하거나 sequenceOf(list) 함수를 사용하여 리스트에서 시퀀스를 생성할 수 있다. 아래 예제는 이전 예제와 동일한 작업을 수행하는 데 sequence 유형을 사용하는 방법을 보여준다: fun averageNonBlankLength(strings: List\u0026lt;String\u0026gt;): Double = strings.asSequence() .filter { it.isNotBlank() } .map(String::length) .sum() / strings.size.toDouble() 이 예제에서는 asSequence() 함수를 사용하여 List를 Sequence로 변환한다. 그런 다음 filter 및 map 함수를 사용하여 이전과 동일한 작업을 수행하지만 중간 List를 생성하는 대신 각 함수 호출에서 Sequence가 반환된다. 시퀀스를 사용하면 lazy evaluation로 동작하므로 필요없는 계산을 하지 않는다. 이는 메모리 사용량을 줄이는 데 도움이 될 수 있다. 시퀀스는 결과 데이터 집합의 크기를 미리 알 수 없는 상황이나, 작업이 복잡하고 중간 결과를 메모리에 저장할 필요가 없는 상황 등 메모리 효율성이 중요한 경우에 유용하다. List 처리는 다음과 같이 진행된다: Sequence 의 처리는 다음과 같이 진행된다: Sequence 유형에 대해 더 알고 싶다면 공식 문서 를 참고하자.","date":"2023-01-10T23:59:43+09:00","href":"https://disj11.github.io/memory-efficient-iterable-data-processing-with-sequences/","objectID":"b0b2647497d39a8d7b5016846e7ddd3b_0","order":0,"tags":["kotlin"],"title":"Kotlin: 시퀀스를 활용한 메모리 효율적인 데이터 처리 방법"},{"content":"확장 함수(extension functions)의 수신 객체는 매개변수이기 때문에 null 값이 허용된다. anObject.method() 와 anObject.extensionFunction() 는 비슷해 보일 수 있지만 사실은 그렇지 않다. anObject가 null인 경우, method() 는 호출될 수 없지만 anObject.extensionFunction()은 호출될 수 있다. 다음 예제를 살펴보자: fun String?.extensionFunction() = this?.length fun main() { val str: String? = null println(str.extensionFunction()) // prints \u0026#39;null\u0026#39; } 이 예제에서 확장 함수 내에서 this 를 사용할 때 타입 안전 연산자(safe call operator)를 사용하고 있다. 이 코드에는 단점이 하나 있는데, 바로 null을 반환할 수 있다는 것이다. 이런 경우 이 함수를 사용할 때 다음과 같은 예외 처리가 필요할 것이다: val str: String = \u0026#34;Some text\u0026#34; val length = str.extensionFunction() ?: error(\u0026#34;Should never happen\u0026#34;) 하지만 코드를 사용하는 곳에서 extensionFunction() 이 확장 함수라는 것을 인지하지 못한다면 예외 처리를 하지 못할 수도 있다. 이런 경우 버그 발생의 여지가 있다. 따라서 null이 가능한 수신 객체를 사용할 경우에는 null을 반환하지 않는 것이 좋다. null을 반환하는 확장 함수가 필요한 경우, 해당 확장 함수를 non-nullable 유형의 확장으로 정의하고, 호출할 때 타입 안전 연산자를 사용하는 것이 좋다. 다음 코드를 참고하자: fun String.extensionFunction(): Int? { return // ... } val length = str?.extensionFunction() 확장 함수에 대해 궁금한 점이 있다면 공식 문서 더 많은 정보를 확인할 수 있다.","date":"2023-01-08T21:22:27+09:00","href":"https://disj11.github.io/nullable-receiver-in-extension-functions-of-kotlin/","objectID":"13b0cf36b526654795d8d3c931abfea3_0","order":0,"tags":["kotlin"],"title":"Kotlin: 확장 함수의 수신 객체"},{"content":"The receiver object in extension functions allows null values because it is actually a parameter. At first glance, anObject.method() and anObject.extensionFunction() may look similar, but this is not the case. If anObject is null, the method() will never be called, but the extensionFunction() can still be called. Here is an example: fun String?.extensionFunction() = this?.length fun main() { val str: String? = null println(str.extensionFunction()) // prints \u0026#39;null\u0026#39; } In this example, when using this inside an extension function, note that the safe call operator should be used. This code has a disadvantage: it may return null. In these cases, we should write code like the following: val str: String = \u0026#34;Some text\u0026#34; val length = str.extensionFunction() ?: error(\u0026#34;Should never happen\u0026#34;) If the surrounding code changes, it could cause a bug to occur. To avoid these problems, if you use a nullable receiver inside an extension function, it is best not to return null. If you need an extension function that returns null, you can define it as an extension of a non-nullable type and use the safe call operator when calling the extension, as shown in the following code: fun String.extensionFunction(): Int? { return // ... } val length = str?.extensionFunction() If you have any questions about the extensions, you can find more information here.","date":"2023-01-08T21:22:27+09:00","href":"https://disj11.github.io/en/nullable-receiver-in-extension-functions-of-kotlin/","objectID":"2dbe44e0911d44532b267a5323b18451_0","order":0,"tags":["kotlin"],"title":"Nullable Receiver in Extension Functions of Kotlin"},{"content":"Kotlin에서 데이터 클래스를 주의해야 할 사항이 있다. 데이터 클래스는 자동으로 copy() 함수를 생성하는데, 이 함수를 통해 속성값을 수정한 새로운 인스턴스를 생성할 수 있게 된다. 클래스의 속성 중에 불변성을 유지해야 하는 속성이 있다면, 데이터 클래스의 사용은 위험할 수 있다. 예를 들어, 다음과 같은 Point 클래스가 있다: data class Point private constructor( val value: Int, ) { companion object { fun of(value: Int) = if (value \u0026lt; 0) { throw IllegalArgumentException(\u0026#34;The value argument should always be set to a positive value, but the current value is $value\u0026#34;) } else { Point(value) } } } 코드에서 보는 바와 같이 Point 클래스의 value 속성은 양수여야 한다. 그러나 copy() 함수를 사용하면 음수값을 설정할 수 있다: val point = Point.of(10) // The copy() function allows us to set an invalid value. val invalidPoint = point.copy(value = -10) 이를 방지하기 위해 데이터 클래스 대신 다음과 같은 Point 클래스를 정의할 수 있다: class Point private constructor( val value: Int, ) { override fun equals(other: Any?): Boolean { if (this === other) return true if (javaClass != other?.javaClass) return false other as Point if (value != other.value) return false return true } override fun hashCode(): Int { return value } override fun toString(): String { return \u0026#34;Point(value=$value)\u0026#34; } } 이 포스트에서 알아본 것 처럼, Kotlin에서 데이터 클래스를 사용할 때 copy() 함수가 자동으로 생성된다는 점을 조심해야한다. 데이터 클래스에 대해 더 많은 정보를 원한다면 공식 문서를 참조하다.","date":"2023-01-08T14:39:00+09:00","href":"https://disj11.github.io/notes-on-using-data-classes-in-kotlin/","objectID":"33d5ed4a10544fb713669873294bc369_0","order":0,"tags":["kotlin"],"title":"Kotlin에서 데이터 클래스를 사용할 때 주의할 점"},{"content":"When using data classes in Kotlin, it is important to keep a few things in mind. Data classes automatically create a copy() function, which can be used to create a new instance of the class with modified property values. However, if a property of the class must maintain an invariant, this function may not behave as expected. For example, consider the following Point class: data class Point private constructor( val value: Int, ) { companion object { fun of(value: Int) = if (value \u0026lt; 0) { throw IllegalArgumentException(\u0026#34;The value argument should always be set to a positive value, but the current value is $value\u0026#34;) } else { Point(value) } } } The value property of the Point class is intended to be positive. However, the copy() function allows us to set an invalid value: val point = Point.of(10) // The copy() function allows us to set an invalid value. val invalidPoint = point.copy(value = -10) To prevent this from happening, we can define the Point class as follows: class Point private constructor( val value: Int, ) { override fun equals(other: Any?): Boolean { if (this === other) return true if (javaClass != other?.javaClass) return false other as Point if (value != other.value) return false return true } override fun hashCode(): Int { return value } override fun toString(): String { return \u0026#34;Point(value=$value)\u0026#34; } } As we have learned in this post, it is important to always consider the copy() function when using data classes in Kotlin. If you have any questions about the data classes, you can find more information here.","date":"2023-01-08T14:39:00+09:00","href":"https://disj11.github.io/en/notes-on-using-data-classes-in-kotlin/","objectID":"2b7b0aa434c491d238b82df1cb31e25e_0","order":0,"tags":["kotlin"],"title":"Notes on Using Data Classes in Kotlin"},{"content":"개요 # SOLID 란 Robert C.Martin 이 명명한 객체 지향 프로그래밍의 다섯 가지 설계 원칙이다. SOLID 는 다음을 의미한다. S - Single-responsibility Principle (SRP: 단일 책임 원칙) O - Open-closed Principle (OCP: 개방-폐쇄 원칙) L - Liskov Substitution Principle (LSP: 리스코프 치환 원칙) I - Interface Segregation Principle (ISP: 인터페이스 분리 원칙) D - Dependency Inversion Principle (DIP: 의존 관계 역전 원칙) 이번 포스팅에서는 이 다섯 가지 원칙에 대해서 알아본다. 단일 책임 원칙 # 하나의 클래스는 한 가지 책임만 가져야 하며, 클래스를 변경해야 하는 이유는 단 하나여야 한다는 원칙이다. 이 원칙을 지키면 어떤 점이 좋을까? 테스팅 - 하나의 책임만을 가졌으므로 훨씬 더 적은 테스트 케이스로 테스트를 만들 수 있다. 낮은 결합도 - 하나의 클래스가 갖는 기능이 적을수록 종속성이 줄어 든다. 이는 클래스가 변경되었을 때 외부의 영향을 신경쓸 필요가 줄어든다는 것을 의미한다. 예제를 통해 단일 책임 원칙을 지키는 코드를 알아보자. public class Book { private String name; private String author; private String text; //constructor, getters and setters } 이름과 저자, 텍스트를 갖는 간단한 Book 클래스이다. 여기에 텍스트 속성과 관련된 몇 가지 메서드를 추가해 보자. public class Book { private String name; private String author; private String text; //constructor, getters and setters // Book 클래스의 속성과 직접적인 연관을 갖는 메서드 public String replaceWordInText(String word) { return text.replaceAll(word, text) } public boolean isWordInText(String word) { return text.contains(word); } } 이제 책을 읽기 위해 printTextToConsole() 메서드를 추가하려고 한다. 다음과 같이 Book 클래스에 메서드를 추가하면 될까? Bad: public class Book { //... void printTextToConsole() { // 텍스트 서식 지정 및 출력 } } 이는 앞에서 설명한 단일 책임 원칙을 위반한다. 단일 책임 원칙을 지키기 위해서는 텍스트 출력에 대한 별도 클래스를 생성해야 한다. Good: public class BookPrinter { void printTextToConsole(String text) { // 텍스트 서식 지정 및 출력 } void printTextToAnotherMedium(String text) { // 다른 미디어로 텍스트를 보내기 위한 코드... } } 콘솔로 텍스트를 출력하는 기능을 만들었다. 콘솔이 아닌 다른 미디어로 텍스트를 출력하는 기능을 추가할 수도 있을 것이다. 미디어가 이메일이 됐든, 로그가 됐든, 어느 것이든 상관없이 이제 텍스트 출력이라는 문제에만 전념할 수 있는 클래스가 만들어졌다. 개방-폐쇄 원칙 # 클래스는 확장에는 열려있지만, 수정에는 닫혀있어야 한다는 원칙이다. 조금 더 쉽게 풀면, 기존의 코드를 수정하지 않고도 새로운 기능을 추가할 수 있어야 한다는 것이다. 이 원칙을 지키면 잠재적인 새로운 버그를 방지하는 데 도움이 된다. Bad: public class Vehicle { private Type type; public void move() { if (Type.AIR_PLANE.equals(type)) { System.out.println(\u0026#34;하늘을 날다\u0026#34;); } else if (Type.CAR.equals(type)) { System.out.println(\u0026#34;도로를 달린다\u0026#34;); } else if (Type.SUBWAY) { System.out.println(\u0026#34;철도를 달린다\u0026#34;); } } } 이 코드는 탈 것의 종류가 추가될 때마다 기존의 코드를 수정해야 한다. 개방-폐쇄 원칙을 지킨 코드는 다음과 같다. public interface Vehicle { void move(); } public class AirPlane implements Vehicle { @Override public void move() { System.out.println(\u0026#34;하늘을 날다\u0026#34;); } } public class Car implements Vehicle { @Override public void move() { System.out.println(\u0026#34;도로를 달린다\u0026#34;); } } public class Subway implements Vehicle { @Override public void move() { System.out.println(\u0026#34;철도를 달린다\u0026#34;); } } 이 코드는 새로운 탈 것이 추가되더라도 기존의 코드 변경 없이 새로운 클래스를 생성하면 된다. 리스코프 치환 원칙 # S가 T의 하위형 타입이라면 T 타입의 객체는 어떠한 속성의 수정 없이 타입 S로 교체할 수 있어야 한다는 원칙이다. 리스코프 치환 원칙 위반의 예로 가장 많이 사용하는 것은 직사각형 클래스로부터 정사각형 클래스를 파생하는 것이다. Bad: public class Rectangle { protected int width; protected int height; public void setWidth(int width) { this.width = width; } public void setHeight(int height) { this.height = height; } public int getArea() { return width * heght; } } public class Square extends Rectangle { @Override public void setWidth(int width) { this.width = width; this.hegiht = height; } @Override public void setHeight(int height) { this.height = height; this.width = height; } } 정사각형은 가로와 세로가 항상 같아야 하기 때문에 가로와 세로를 독립적으로 변경할 수 없다. 그렇다고 해서 이 코드의 Square 와 같이 메서드를 오버라이딩 하게 되면, 가로와 세로를 독립적으로 변경할 수 있는 직사각형 할당자의 조건을 위반하게 된다. 이 코드를 클라이언트에서 다음과 같이 사용했다고 해보자. public void printArea(List\u0026lt;Rectangle\u0026gt; rectangles) { for (Rectangle rectangle : rectangles) { rectangle.setWidth(4); rectangle.setHeight(5); System.out.println(rectangle.getArea()); } } 이 메서드는 20 이 출력 될까? 만약 매개 변수로 받은 클래스의 타입이 Square 라면 25 가 출력될 것이다. 리스코프 치환 원칙을 지키는 코드는 다음과 같다. Good: public interface Shape { int getArea(); } public class Rectangle implements Shape { private int width; private int height; // setter @Override public int getArea() { return width * height; } } public class Square implements Shape { private int length; // setter public getArea() { return length * length; } } 인터페이스 분리 원칙 # 많은 기능을 가진 인터페이스를 더 작게 분할해야 한다는 원칙이다. 다음의 예시를 보자. Bad: public interface Printer { void print(); void fax(); void scan(); } public class AllInOnePrinter implements Printer { public void print() { // ... } public void fax() { // ... } public void scan() { // ... } } public class EconomicPrinter implements Printer { public void print() { // ... } public void fax() { throw new UnsupportedOperationException(\u0026#34;Fax not supported.\u0026#34;); } public void scan() { throw new UnsupportedOperationException(\u0026#34;Scan not supported.\u0026#34;); } } 인터페이스 분리 원칙을 따른 코드는 다음과 같다. Good: public interface Printer { void print(); } public interface Fax { void fax(); } public interface Scanner { void scan(); } public class AllInOnePrinter implements Printer, Fax, Scanner { print() { // ... } fax() { // ... } scan() { // ... } } public class EconomicPrinter implements Printer { print() { // ... } } 의존 관계 역전 원칙 # 이 원칙은 소프트웨어 모듈을 분리 시 지켜야 하는 두 가지 사항을 명시한다. 상위 모듈은 하위 모듈에 의존해서는 안된다. 상위 모듈과 하위 모듈 모두 추상화에 의존해야 한다. 추상화는 세부 사항에 의존해서는 안된다. 세부 사항은 추상화에 의존해야 한다. 설명 만으로는 이해하기가 힘들 수 있지만, 우리가 자주 사용하는 의존성 주입도 이 원칙을 따르는 방법 중 하나이다. 다음 예시를 보자. Bad: public class MailService { private final RealMailSender mailSender; public MailService() { this.mailSender = new RealMailSender(); } public void send() { mailSender.send(); } } 이 코드는 new 키워드로 생성된 RealMailSender 로 인해 MailService 와 RealMailSender 간의 강한 결합을 발생시킨다. 이는 테스트를 어렵게 만들 뿐 아니라 RealMailSender 클래스를 다른 메일 발송 클래스로 전환하는 것도 어렵게 만든다. 의존 관계 역전","date":"2021-11-03T21:21:49+09:00","href":"https://disj11.github.io/introduction-to-solid-design-principles/","objectID":"feceb77edc638013d77845fd13cc5611_0","order":0,"tags":["development"],"title":"SOLID Design Principles"},{"content":"원칙을 지키는 코드를 살펴보자. Good: public interface MailSender { void send(); } public class RealMailSender implements MailSender { @Override public void send() { // 실제 메일을 발송한다. } } public class ConsoleMailSender implements MailSender { @Override public void send() { // 메일 내용을 콘솔에만 출력한다. } } public class MailService { private final MailSender mailSender; public MailService(MailSender mailSender) { this.mailSender = mailSender; } } 의존 관계 역전 원칙을 잘 지키는 코드이다. 의존성 주입을 통해 실제 구현체와의 의존성을 분리하였다. 만약 테스트 환경이라면 실제로 메일이 발송되어서는 안되기 때문에 ConsoleMailSender 를 사용하면 될 것이다. 운영 환경이라면 RealMailSender 를 사용하면 된다. 마무리 # 객체 지향 설계의 SOLID 원칙에 대해 살펴보았다. 객체 지향 설계의 \u0026lsquo;원칙\u0026rsquo; 이라는 말이 붙었을 정도이다. 간단한 프로그램을 만들더라도 항상 SOLID 원칙을 준수할 수 있도록 습관을 들이는 것이 좋을 것이다.","date":"2021-11-03T21:21:49+09:00","href":"https://disj11.github.io/introduction-to-solid-design-principles/","objectID":"feceb77edc638013d77845fd13cc5611_1","order":1,"tags":["development"],"title":"SOLID Design Principles"},{"content":"개요 # 이전까지 자바에서 사용하던 HttpURLConnection 는 지원 수준이 너무 낮아 서드 파티 라이브러리인 Apache HttpClient, Jetty, 스프링의 RestTemplate 을 많이 사용하였다. 하지만 Java 11 에서 HTTP/2와 Web Socket 을 구현하는 HTTP Client API 의 표준화가 정식으로 도입되었다. 이번 포스팅에서는 Java 11 에서 채택된 HTTP Client API 표준화에 대해 알아본다. 변경점 (JEP 321) # Java 9 에서 도입되었던 HTTP API가 이제 공식적으로 Java SE API에 통합 되었다. 새로운 HTTP APIs 는 java.net.HTTP.* 패키지에서 확인할 수 있다. 최신 버전의 HTTP 프로토콜은 stream multiplexing, header compression 와 push promises 등을 통해 전반벅인 성능이 향상되었다. Java 11 부터 API는 비동기로 동작합니다. 비동기는 CompletableFuture 를 사용하여 구현되었다. 새로운 HTTP 클라이언트 API는 외부 종속성 없이 HTTP/2와 같은 최신 웹 기능을 지원한다. 새로운 API는 HTTP 1.1/2 WebSocket에 대한 기본 지원을 제공한다. 핵심 기능을 제공하는 클래스와 인터페이스는 다음과 같다. HttpClient class, java.net.http.HttpClient HttpRequest class, java.net.http.HttpRequest HttpResponse interface, java.net.http.HttpResponse WebSocket interface, java.net.http.WebSocket 이전 버전의 문제점 # 기존에 사용하던 HttpURLConnection API 는 다음과 같은 문제가 존재했다: 더 이상 작동하지 않는 프로토콜을 사용하도록 디자인 되었다. (FTP, gopher, etc.) HTTP/1.1 이전 버전이며 너무 추상적이다. blocking mode 로만 동작한다. (하나의 스레드당 하나의 request/response) HTTP Client API 개요 # HttpURLConnection 과 달리 HTTP Client 는 동기화 비동기 모두를 제공한다. API는 다음의 3가지 핵심 클래스로 이루어 진다. HttpRequest - HttpClient 를 통해 보낼 요청 HttpClient - 여러 요청에 대한 공통 구성 정보를 담는 컨테이너 역할 HttpResponse - HttpRequest 호출의 결과 다음 섹션에서 각각에 대해 더 자세히 알아보자. HttpRequest # 이름에서 알 수 있듯 보내려는 요청을 나타내는 객체이다. HttpRequest.Builder 를 사용하여 새 인스턴스를 만들 수 있다. Builder 클래스는 HttpRequest.newBuilder() 를 통해 얻을 수 있다. URI 설정 # 요청을 생성할 때 가장 먼저 해야 할 일은 URL을 제공하는 것이다. 다음과 같이 두 가지 방법을 통해 URL 을 제공 할 수 있다. HttpRequest.newBuilder(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) HTTP Method 지정 # Builder 에서 다음 메서드 중 하나를 호출하여 사용할 HTTP Method 를 정의 할 수 있다. GET() POST(BodyPublisher body) PUT(BodyPublisher body) DELETE() BodyPublisher 에 대해서는 이후에 다루기로 하고, 먼저 간단한 GET 요청 예제를 살펴보자. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .GET() .build(); 이 요청에는 요청에 필요한 모든 정보가 있다. 하지만 때때로 요청에 추가적인 파라미터가 필요할 수도 있다. 몇 가지 중요한 파라미터에는 다음과 같은 것들이 있다. HTTP protocol 의 버전 headers timeout HTTP protocol 버전 # API 는 기본적으로 HTTP/2 프로토콜을 사용하지만 사용하려는 프로토콜의 버전을 명시할 수 있다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .version(HttpClient.Version.HTTP_2) .GET() .build(); 중요한 점은 HTTP/2 가 지원되지 않는 경우 클라이언트는 HTTP/1.1 로 대체한다는 점이다. Header 설정 # header 에 추가적인 정보가 필요한 경우 builder 메서드를 사용할 수 있다. 여기에는 두 가지 방법이 있다. headers() 메서드를 통해 모든 헤더를 키와 값의 쌍으로 제공 header() 메서드를 통해 하나의 키와 값을 제공 HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .headers(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;) .GET() .build(); HttpRequest request2 = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .header(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;) .header(\u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;) .GET() .build(); Timeout 설정 # Builder 인스턴스의 timeout() 메서드를 사용하여 응답 시간을 설정할 수 있다. 만약 응답 시간을 초과한다면 HttpTimeoutException 이 발생한다. 기본 값은 infinity 이다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .timeout(Duration.of(10, SECONDS)) .GET() .build(); Request Body 설정 # Request Method 가 POST, PUT, DELETE 인 경우 요청 본문을 설정할 수 있다. 새로운 API 는 요청 본문을 작성할 수 있도록 여러가지의 BodyPublisher 구현체를 제공한다. StringProcessor ( HttpRequest.BodyPublishers.ofString 를 사용하여 생성함) InputStreamProcessor (HttpRequest.BodyPublishers.ofInputStream 를 사용하여 생성함) ByteArrayProcessor (HttpRequest.BodyPublishers.ofByteArray 를 사용하여 생성함) FileProcessor (HttpRequest.BodyPublishers.ofFile 를 사용하여 생성함) request body 가 필요 없는 경우는 HttpRequest.BodyPublishers.noBody() 를 사용한다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .POST(HttpRequest.BodyPublishers.noBody()) .build(); StringBodyPublisher # HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.ofString(\u0026#34;Sample request body\u0026#34;)) .build(); InputStreamBodyPublisher # byte[] sampleData = \u0026#34;Sample request body\u0026#34;.getBytes(); HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.ofInputStream(() -\u0026gt; new ByteArrayInputStream(sampleData))) .build(); ByteArrayProcessor # byte[] sampleData = \u0026#34;Sample request body\u0026#34;.getBytes(); HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.ofByteArray(sampleData)) .build(); FileProcessor # HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/post\u0026#34;)) .headers(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain;charset=UTF-8\u0026#34;) .POST(HttpRequest.BodyPublishers.fromFile( Paths.get(\u0026#34;src/test/resources/sample.txt\u0026#34;))) .build(); HttpClient # 모든 요청은 HttpClient 를 통해 전송한다. HttpClient 는 HttpClient.newBuilder() 메서드 또는 HttpClient.newHttpClient() 를 통해 얻을 수 있다. Response Body 핸들링 # Publisher 와 비슷하게 Response Body handler 생성을 위한 메서드가 있다. BodyHandlers.ofByteArray BodyHandlers.ofString BodyHandlers.ofFile BodyHandlers.discarding BodyHandlers.replacing BodyHandlers.ofLines BodyHandlers.fromLineSubscriber BodyHandlers 팩토리 클래스의 사용에 주의한다. java 11 이전 버전에서는 다음과 같이 사용했다. HttpResponse\u0026lt;String\u0026gt; response = client.send(request, HttpResponse.BodyHandler.asString()); 이제는 다음과 같이 사용할 수 있다. HttpResponse\u0026lt;String\u0026gt; response = client.send(request, BodyHandlers.ofString()); Proxy 설정 # Builder 인스턴스에서 proxy() 메서드를 사용하여 간단하게 프록시를 추가할 수 있다. 다음은 시스템 기본 프록시를 사용하게 하는 예제이다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient .newBuilder() .proxy(ProxySelector.getDefault()) .build() .send(request, BodyHandlers.ofString()); Redirect Polcy 설정 # 접근하려는 페이지가 다른 주소로 이동하는 경우가 있다. 이 경우 일반적으로 변경된 URI 와 함께 HTTP 상태코드 3xx 를 받게 된다. 적절한 리다이렉션 정책을 설정하면 HttpClient 가 자동으로 요청을 새 URI 로 리다이렉션 한다. 리다이렉션 정책 설정은 Builder 인스턴스의 followRedirects() 메서드를 사용한다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newBuilder() .followRedirects(HttpClient.Redirect.ALWAYS) .build() .send(request, BodyHandlers.ofString()); 리다이렉션 정책은 HttpClient.Redirect 에 정의 되어 있다. Authenticator 설정 # Authenticator 는 연결을 위한 자격증명을 나타낸다. 예를 들어 연결 하려는 서버가 username, password 를 요구한다면 PasswordAuthentication 클래스를 사용할 수 있다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newBuilder() .authenticator(new Authenticator() { @Override protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication( \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;.toCharArray()); } }).build() .send(request, BodyHandlers.ofString()); Send Requests - Sync vs. Async # HttpClient 는 동기와 비동기 요청 모두 제공한다. send() - 동기 sendAsync() - 비동기 send 메서드는 응답이 올 때까지 기다리고, HttpResponse 객체를 리턴한다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newBuilder() .build() .send(request, BodyHandlers.ofString()); 응답이 올 때까지 기다리기 때문에 많은 양의 데이터를 처리해야 할 때 단점이 있다. 반면에 sendAsync 메서드는 비동기로 작동하며 CompletableFeature\u0026lt;HttpResponse\u0026gt; 를 리턴한다. CompletableFuture\u0026lt;HttpResponse\u0026lt;String\u0026gt;\u0026gt; response = HttpClient.newBuilder() .build() .sendAsync(request, HttpResponse.BodyHandlers.ofString()); 다음과 같은 사용도 가능하다. List\u0026lt;URI\u0026gt; targets = Arrays.asList( new URI(\u0026#34;https://postman-echo.com/get?foo1=bar1\u0026#34;), new URI(\u0026#34;https://postman-echo.com/get?foo2=bar2\u0026#34;)); HttpClient client = HttpClient.newHttpClient(); List\u0026lt;CompletableFuture\u0026lt;String\u0026gt;\u0026gt; futures = targets.stream() .map(target -\u0026gt; client .sendAsync( HttpRequest.newBuilder(target).GET().build(), HttpResponse.BodyHandlers.ofString()) .thenApply(response -\u0026gt; response.body())) .collect(Collectors.toList()); 비동기를 위한 Executor 설정 # 비동기 호출 시 사용할 스레드를 제공하는 Executor 을 정의할 수도 있다. 이를 사용하여 요청 처리에 사용되는 스레드 수를 제한할 수 있다. ExecutorService executorService = Executors.newFixedThreadPool(2); CompletableFuture\u0026lt;HttpResponse\u0026lt;String\u0026gt;\u0026gt; response1 = HttpClient.newBuilder() .executor(executorService) .build() .sendAsync(request, HttpResponse.BodyHandlers.ofString()); CompletableFuture\u0026lt;HttpResponse\u0026lt;String\u0026gt;\u0026gt; response2 = HttpClient.newBuilder() .executor(executorService) .build() .sendAsync(request, HttpResponse.BodyHandlers.ofString()); HttpClient 는 기본적으로 java.util.concurrent.Executors.newCachedThreadPool() 를 사용한다. CookieHandler 설정 # Builder 의 cookieHandler 메서드를 사용하여 클라이언트별 CookieHandler 를 손쉽게 설정할 수 있다. 예를 들어 모든 쿠키를 허용하지 않으려면 다음과 같이 사용할 수 있다.","date":"2021-11-02T18:11:57+09:00","href":"https://disj11.github.io/http-client-in-java/","objectID":"c92630f9f1d66213ba2997c1abb859dc_0","order":0,"tags":["java"],"title":"Http Client in Java"},{"content":"HttpClient.newBuilder() .cookieHandler(new CookieManager(null, CookiePolicy.ACCEPT_NONE)) .build(); 만약 CookieManager 가 쿠키 저장을 허용했다면 HttpClient 에서 CookieHandler 를 통해 쿠키에 액세스 할 수 있다. ((CookieManager) httpClient.cookieHanlder().get()).getCookieStore() HttpResponse # HttpResponse 클래스는 서버의 응답을 나타낸다. 여러가지 유용한 메서드가 있지만 가장 중요한 것은 두 가지 이다. statusCode() - HTTP 상태 코드를 반환한다. body() - 응답에 대한 본문을 반환하며 반환 유형은 send() 메서드에 전달된 BodyHandler 에 따라 다르다. 이 외에도 uri(), headers(), trailers(), version() 등과 같은 유용한 메서드가 있다. Response 객체의 URI # Response 객체의 uri() 메서드는 응답 된 URI 를 반환한다. 리다이렉션이 일어났을 수도 있기 때문에 request 객체의 URI 와 다른 경우도 있다. assertThat(request.uri().toString(), equalTo(\u0026#34;http://stackoverflow.com\u0026#34;)); assertThat(response.uri().toString(), equalTo(\u0026#34;https://stackoverflow.com/\u0026#34;)); Response Headers # Response 객체의 headers() 메서드를 통해 응답 헤더를 확인할 수 있다. 응답 헤더는 HttpHeaders 이며 read-only 이다. HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newHttpClient() .send(request, HttpResponse.BodyHandlers.ofString()); HttpHeaders responseHeaders = response.headers(); Response Version # version() 메서드를 통해 서버와 통신하는 데 사용된 HTTP 프로토콜의 버전을 알 수 있다. 요청 시 HTTP/2 버전을 사용했더라도 HTTP/1.1 을 통해 응답이 올 수도 있음에 주의한다. HttpRequest request = HttpRequest.newBuilder() .uri(new URI(\u0026#34;https://postman-echo.com/get\u0026#34;)) .version(HttpClient.Version.HTTP_2) .GET() .build(); HttpResponse\u0026lt;String\u0026gt; response = HttpClient.newHttpClient() .send(request, HttpResponse.BodyHandlers.ofString()); assertThat(response.version(), equalTo(HttpClient.Version.HTTP_1_1)); 참조 # Exploring the New HTTP Client in Java","date":"2021-11-02T18:11:57+09:00","href":"https://disj11.github.io/http-client-in-java/","objectID":"c92630f9f1d66213ba2997c1abb859dc_1","order":1,"tags":["java"],"title":"Http Client in Java"},{"content":"개요 # DecimalFormat은 미리 정의된 포맷을 사용하여 10진수 문자열 표현을 형식화 할 수 있는 NumberFormat 의 하위 클래스이다. 역으로 문자열을 숫자로 구문 분석하는 데 사용할 수도 있다. 이번 포스팅에서는 DecimalFormat 의 사용법을 알아본다. 패턴 문자 # 숫자를 어떤 형식으로 나타낼 지 지정하기 위해서는 먼저 패턴 문자를 알아야한다. 총 11가지 문자가 있지만, 네 가지만 알고 있으면 대부분의 상황에서 문제 없이 사용할 수 있다. 0 : 값이 제공되면 숫자를, 그렇지 않다면 0을 출력 # : 값이 제공되면 숫자를, 그렇지 않다면 아무것도 출력하지 않음 . : 소수점 구분 기호를 넣을 위치를 지정 , : 그룹화 구분 기호를 넣을 위치를 지정 DecimalFormat 사용 시 패턴이 지정될 경우 지정된 규칙이 실행되고, 그렇지 않은 경우는 JVM Locale 의 DecimalFormatSymbol 에 따라 규칙이 실행된다. 기본 포맷팅 # 실제 코드를 통해 포맷을 적용해보자. Simple Decimal # 정수 부분은 패턴 문자가 입력되는 문자보다 개수가 더 적더라도 잘리지 않는다. 다음의 테스트 코드를 통해 확인할 수 있다. double d = 123.45; Assertions.assertEquals(new DecimalFormat(\u0026#34;#.##\u0026#34;).format(d), \u0026#34;123.45\u0026#34;); Assertions.assertEquals(new DecimalFormat(\u0026#34;0.00\u0026#34;).format(d), \u0026#34;123.45\u0026#34;); 정수와 소수 부분의 패턴 문자가 입력되는 문자보다 길 경우는 # 인 경우 삭제되고, 0 인 경우는 0 이 채워지는 것을 볼 수 있다. double d = 123.45; assertEquals(new DecimalFormat(\u0026#34;####.###\u0026#34;).format(d), \u0026#34;123.45\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;0000.000\u0026#34;).format(d), \u0026#34;0123.450\u0026#34;); Rounding (반올림) # 앞에서 정수 부분은 패턴 문자가 입력되는 문자보다 개수가 더 적더라도 잘리지 않는다고 하였다. 하지만 소수 부분은 패턴 문자가 더 적은 경우, 패턴 문자의 길이에 맞게 반올림 된다. double d = 123.45; assertEquals(new DecimalFormat(\u0026#34;#.#\u0026#34;).format(d), \u0026#34;123.5\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;#\u0026#34;).format(d), \u0026#34;123\u0026#34;); Grouping (그룹핑) # , 패턴 문자는 다음과 같이 사용한다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;#,###.#\u0026#34;).format(d), \u0026#34;1,234,567.9\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;#,###\u0026#34;).format(d), \u0026#34;1,234,568\u0026#34;); Mixing String Literals (문자열 리터럴 혼용) # 문자열 리터럴과 패턴을 혼용하여 사용할 수 있다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;The # number\u0026#34;).format(d), \u0026#34;The 1234568 number\u0026#34;); 다음과 같은 방법을 통해 문자열 리터럴에 특수 문자를 사용 수도 있다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;The \u0026#39;#\u0026#39; # number\u0026#34;).format(d), \u0026#34;The # 1234568 number\u0026#34;); Localized Formatting # 이탈리아 같은 몇몇의 나라에서는 그룹핑 문자로 . 를 사용하고 소수 구분 기호로 , 를 사용한다. 이런 나라에서는 #,###.## 패턴을 이용할 시 1.234.567,89 로 포맷팅 된다. 경우에 따라 이는 유용한 i18n 기능이 될 수도 있지만, 그렇지 않은 경우도 있을 것이다. 이럴 때에는 DecimalFormatSymbols 을 사용한다. double d = 1234567.89; assertEquals(new DecimalFormat(\u0026#34;#,###.##\u0026#34;, new DecimalFormatSymbols(Locale.ENGLISH)).format(d), \u0026#34;1,234,567.89\u0026#34;); assertEquals(new DecimalFormat(\u0026#34;#,###.##\u0026#34;, new DecimalFormatSymbols(Locale.ITALIAN)).format(d), \u0026#34;1.234.567,89\u0026#34;); Parsing # 다음과 같이 문자열을 숫자로 파싱이 가능하다. assertEquals(new DecimalFormat(\u0026#34;\u0026#34;, new DecimalFormatSymbols(Locale.ENGLISH)).parse(\u0026#34;1234567.89\u0026#34;), 1234567.89); Thread-Safety # DecimalFormat 은 스레드에 안전하지 않기 때문에 스레드 간 동일 인스턴스를 공유할 때 주의하여야 한다. 참조 # A Practical Guide to DecimalFormat","date":"2021-11-01T20:00:12+09:00","href":"https://disj11.github.io/number-formatter-in-java/","objectID":"2c1f8384688be7e39ddc4bee18838b0b_0","order":0,"tags":["java"],"title":"Number Formatter in Java"},{"content":"소개 # OAuth는 오픈 API의 인증(authentication)과 권한 부여(authorization)를 제공하기 위해 만들어진 프로토콜이다. OAuth 1.0과 OAuth 2.0이 있는데, 현재는 RFC 5849에서 설명하는 OAuth 1.0을 폐기하고, RFC 6749에 설명된 OAuth 2.0 방식을 사용한다. 이번 포스팅에서는 OAuth 2.0에 관하여 알아본다. 역할 (Rules) # OAuth 2.0을 이해하기 위해서는 먼저 OAuth 2.0에서 정의하는 4가지 역할에 관하여 알아야한다. Resource Owner (리소스 소유자) Resource Service (리소스 서버) Client (클라이언트) Authorization Server (인증 서버) 리소스 소유자는 보호된 리소스의 소유자를 말한다. 예를 들어 은행관련 서비스에서 계좌 잔액이라는 리소스가 있다면, 이 계좌의 소유주(예금주)가 리소스의 소유자가 된다. 리소스 서버는 보호된 리소스를 제공하는 서버를 말한다. 예를 들어 오픈뱅킹 서비스는 각 은행들의 API를 연동하여 다양한 리소스(거래내역, 계좌실명 등)를 제공한다. 이런 경우 오픈뱅킹의 서버가 리소스 서버라고 할 수 있다. 클라이언트는 오픈 API를 호출하는 응용 프로그램을 말한다. 예를 들어 오픈뱅킹 API를 이용하여 모든 은행들의 잔액을 볼 수 있는 어플리케이션을 만들었다면, 이 어플리케이션이 클라이언트가 된다. 인증 서버는 리소스 소유자로부터 리소스에 접근 권한을 획득한 이후에 리소스에 접근하기 위한 엑세스 토큰(Access Token)을 발급해주는 서버를 말한다. OAuth 2.0의 흐름 # 다음 그림은 OAuth 2.0의 대략적인 흐름을 나타낸다. +--------+ +---------------+ | |--(1)- Authorization Request -\u0026gt;| Resource | | | | Owner | | |\u0026lt;-(2)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(3)-- Authorization Grant --\u0026gt;| Authorization | | Client | | Server | | |\u0026lt;-(4)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(5)----- Access Token ------\u0026gt;| Resource | | | | Server | | |\u0026lt;-(6)--- Protected Resource ---| | +--------+ +---------------+ 그림을 보고 하나씩 짚어보자. 리소스 서버에게 리소스를 요청하기 전에 먼저 인증을 요청한다. 인증 요청은 리소스 소유자에게 직접 할 수도 있지만, 중간에 인증 서버를 통해 간접적으로 하는 것이 좋다. 클라이언트는 리소스 소유자의 인가를 나타내는 자격정보인 인가 승인을 받는다. 클라이언트는 2번에서 받은 인가 승인을 사용하여 엑세스 토큰을 요청한다. 인증 서버는 클라이언트를 인증하고, 제시된 인가 승인이 유효한지 확인한다. 유효한 경우 엑세스 토큰을 발급한다. 클라이언트는 엑세스 토큰을 제시하여 리소스 서버에 보호된 리소스를 요청한다. 리소스 서버는 엑세스 토큰이 유효한지 확인하고, 유효한 경우 요청을 받아들인다. 인가 승인 (Authorization Grant) # \u0026ldquo;인가 승인\u0026quot;은 리소스 소유자가 보호된 리소스에 대한 접근을 허용한다는 것을 나타내는 자격 정보(Credentials)이다. 이는 클라이언트가 엑세스 토큰을 얻기 위해 사용된다. 인가 승인에는 네 가지 유형이 있다. 이번 포스팅에서는 네 가지 유형 중 인가 코드(authorization code) 방식에 대해서만 설명하며, 추가적인 유형은 RFC 6749 - Authorization Grant를 참고한다. 인가 코드 (Authorization Code) # 클라이언트는 사용자 에이전트(User-Agent)를 통해 리소스 소유자를 인증 서버로 안내한다. 인증 서버는 리소스 소유자를 인증하고, 인증이 완료되면 클라이언트는 인증 코드를 획득한다. 네이버 로그인이나 카카오 로그인 API가 사용하는 인가 승인 유형이 바로 이 유형이다. 엑세스 토큰 (Access Token) # 엑세스 토큰은 보호된 리소스에 접근할 수 있도록 하는 권한 증명이다. 엑세스 토큰으로 접근할 수 있는 리소스의 범위와 사용할 수 있는 기간이 정해져 있다. 리프레시 토큰 (Refresh Token) # 리프레시 토큰은 엑세스 토큰을 얻는 데 사용할 수 있는 권한 증명이다. 엑세스 토큰이 유효하지 않거나, 만료된 경우 새로운 엑세스 토큰을 발급 받기 위해 사용된다. 더 좁은 범위로 추가적인 엑세스 토큰을 받기 위해 사용되기도 한다. 아래의 그림은 리프레시 토큰을 사용하여 엑세스 토큰을 갱신하는 흐름을 보여준다. +--------+ +---------------+ | |--(1)------- Authorization Grant ---------\u0026gt;| | | | | | | |\u0026lt;-(2)----------- Access Token -------------| | | | \u0026amp; Refresh Token | | | | | | | | +----------+ | | | |--(3)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(4)- Protected Resource --| Resource | | Authorization | | Client | | Server | | Server | | |--(5)---- Access Token ----\u0026gt;| | | | | | | | | | | |\u0026lt;-(6)- Invalid Token Error -| | | | | | +----------+ | | | | | | | |--(7)----------- Refresh Token -----------\u0026gt;| | | | | | | |\u0026lt;-(8)----------- Access Token -------------| | 인가 획득 (Obtaining Authorization) # 클라이언트가 리소스 소유자로부터 인가를 획득하는 과정에 대해 알아보자. 인가 승인에서 알아본 것처럼 인가 획득을 위한 유형에는 네 가지가 있지만, 이 포스팅에서는 인가 코드를 사용하여 인가를 획득하는 과정에 대해서만 설명한다. 인가 코드 승인 유형은 리다이렉션이 기반이 된다. 때문에 클라이언트는 리소스 소유자의 유저 에이전트(일반적으로 웝 브라우저)와 상호작용 할 수 있어야하며, 리다이렉션을 통해 인증 서버로 오는 요청을 받을수 있어야 한다. 인가 코드 승인 유형 흐름 # 다음 그림은 인가 코드 방식의 흐름을 보여준다. +----------+ | Resource | | Owner | | | +----------+ ^ | (2) +----|-----+ Client Identifier +---------------+ | -+----(1)-- \u0026amp; Redirection URI ----\u0026gt;| | | User- | | Authorization | | Agent -+----(2)-- User authenticates ---\u0026gt;| Server | | | | | | -+----(3)-- Authorization Code ---\u0026lt;| | +-|----|---+ +---------------+ | | ^ v (1) (3) | | | | | | ^ v | | +---------+ | | | |\u0026gt;---(4)-- Authorization Code ---------\u0026#39; | | Client | \u0026amp; Redirection URI | | | | | |\u0026lt;---(5)----- Access Token -------------------\u0026#39; +---------+ (w/ Optional Refresh Token) 1,2,3번의 과정이 두 부분으로 나누어 지는데, 이는 유저 에이전트를 통해 전달되기 때문이다. 1번은 클라이언트가 리소스 소유자의 유저 에이전트를 인증 서버로 안내하며 흐름을 시작하는 과정이다. 클라이언트는 클라이언트의 식별자(client identifier), 요청 범위(requested scope), 로컬 상태(local state), 리다이렉션 URI를 포함해야한다. 네이버 아이디로 로그인 API를 연동한 어플리케이션에서 [네이버 아이디로 로그인] 버튼을 누르면 흐름이 시작되는데, 이 과정이라고 생각하면 된다. 2번은 인증 서버가 유저 에이전트를 통해 리소스 소유자를 인증하고, 리소스 소유자가 클라이언트의 접근 요청에 승인 혹은 거부할 지를 선택하는 단계이다. 3번 과정은 인증 서버가 유저 에이전트를 제공된 리다이렉션 URI로 이동시키는 과정이다. 이때 리다이렉션 URI에는 인증 코드와 로컬 상태가 포함된다. 4번은 클라이언트가 이전 과정에서 받은 인증 코드를 포함하여 인증 서버에 엑세스 토큰을 요청하는 단계이다. 요청을 보낼 때에는 3번 과정에서 사용했던 리다이렉션 URI도 포함하여 전달한다. 5번 과정에서 인증서버는 인증 코드가 유효한지 확인하고, 3번 과정과 4번 과정의 리다이렉션 URI가 동일한지 확인한다. 유효하다는 게 획인되면 엑세스 토큰과 (선택적으로) 리프레시 토큰을 응답한다. 인가 요청 (Authorization Request) # 클라이언트는 인증 코드 요청을 할 때 application/x-www-form-urlencoded 를 사용하여 다음 파라미터를 포함해야한다. response_type 필수. \u0026ldquo;code\u0026quot;로 고정 client_id 필수. 클라이언트의 식별자 redirect_uri 선택사항. 자세한 내용은 RFC 6749 - Redirection Endpoint 참고 scope 선택사항. 자세한 내용은 RFC 6749 - Access Token Scope 참고 state 권장사항. 인증 서버는 유저 에이전트를 클라이언트로 리다이렉트할 때 이 값을 포함한다. RFC 6749 - Cross-Site Request Forgery에 기술된대로 사이트 간 요청 위조를 방지하는 데 사용하는 것이 좋다. 인가 요청의 예: GET /authorize?response_type=code\u0026amp;client_id=s6BhdRkqt3\u0026amp;state=xyz\u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1 Host: server.example.com 인가 응답 (Authorization Response) #","date":"2021-10-22T10:08:30+09:00","href":"https://disj11.github.io/an-introduction-to-oauth2/","objectID":"a177d88fa4b2236fde560a5c14b1fe69_0","order":0,"tags":["development"],"title":"Oauth2 에 대해서 알아보자"},{"content":"리소스 소유자가 접근 요청을 승인하면, 인증 서버는 다음의 파라미터를 application/x-www-form-urlencoded 를 사용하여 클라이언트에게 전달한다. 성공 응답 (Successful Response) # code 필수. 인증 서버에서 생성된 인증 코드이다. 유출 위험을 줄이기 위해 만료 시간이 짧아야 하며 최대 10분이 권장된다. 클라이언트는 인증 코드를 두 번 이상 사용하면 안된다. 만약 두번 이상 사용될 경우 인증 서버는 요청을 거부해야 하며, 해당 인증 코드 이전에 발급된 모든 토큰을 취소하는 것이 좋다. state 클라이언트가 인증 요청 시 state 파라미터를 포함했다면 필수. 클라이언트로부터 전달 받은 값과 동일해야한다. 성공 응답의 예: HTTP/1.1 302 Found Location: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA\u0026amp;state=xyz 오류 응답 (Error Response) # 만약 요청이 누락되거나, 유효하지 않는 경우, 리다이렉션 URI가 일치하지 않는 경우, 클라이언트 식별자가 누락되거나 유효하지 않는 경우는 유저 에이전트를 유효하지 않은 URI로 리다이렉트 되게 해서는 안된다. 이 경우에 인증 서버는 다음 파라미터를 사용하여 리소스 소유자에게 오류를 알려주는 것이 좋다. error 필수. 다음의 에러 코드 사용 invalid_request 요청 시 필수 파라미터의 누락, 유효하지 않은 파라미터 포함, 파라미터를 두 번 이상 포함 등 unauthorized_client 클라이언트가 이 인가 승인 유형을 사용할 권한이 없음 access_denied 리소스 소유자 또는 인증 서버가 요청을 거부 unsupported_response_type 인증 서버가 Authorization Code Grant 유형을 지원하지 않음 invalid_scope 요청한 scope가 유효하지 않거나, 알 수 없거나, 손상된 경우 server_error 인증 서버에 예기치 못한 오류가 발생 temporarily_unavailable 인증 서버의 과부하 또는 유지보수로 인해 요청을 처리할 수 없음 error_description 선택사항. 클라이언트 개발자가 발생한 오류를 이해하는 데 도움을 주는 정보를 제공한다. error_uri 선택사항. 클라이언트 개발자를 위해 발생한 오류와 관련된 추가 정보를 제공한다. state 클라이언트가 인증 요청 시 state 파라미터를 포함했다면 필수. 클라이언트로부터 전달 받은 값과 동일해야한다. 오류 응답의 예: HTTP/1.1 302 Found Location: https://client.example.com/cb?error=access_denied\u0026amp;state=xyz 엑세스 토큰 요청 (Access Token Request) # 클라이언트는 토큰 요청시 UTF-8 인코딩을 사용하여 application/x-www-form-urlencoded 형식으로 된 다음과 같은 파라미터를 body에 담아야한다. grant_type 필수. 값은 \u0026ldquo;authorization_code\u0026quot;로 고정 code 필수. 인증 서버로부터 받은 인증 코드 redirect_uri 인증 요청 시 redirect_uri가 존재했다면 필수이며, 인증 요청 시 사용했던 값과 동일해야 한다. client_id 클라이언트가 인증 서버와 인증하지 않는 경우 필수. 클라이언트 인증에 관한 자세한 내용은 RFC 6749 - Client Authentication를 참고한다. 토큰 요청의 예: POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencodedgrant_type=authorization_code\u0026amp;code=SplxlOBeZQQYbYS6WxSbIA\u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb 엑세스 토큰 응답 (Access Token Response) # Access Token 요청이 유효하고 인증되었다면, 인증 서버는 Access Token과 선택적으로 갱신 토큰을 발급한다. 성공 응답 (Successful Response) # 인증 서버는 Access Token과 선택적으로 갱신 토큰을 발급하고, 다음 파라미터를 200 (OK) 상태 코드로 응답한다. 파라미터는 application/json 유형을 사용하여 HTTP Response Body에 포함한다. access_token 필수. 인증 서버가 발급한 엑세스 토큰 token_type 필수. 토큰의 타입으로 보통 baerer 타입을 많이 사용한다. 자세한 내용은 RFC 6749 - Access Token Types를 참고한다. expires_in 권장사항. 초 단위의 Access Token 수명. 예를 들어 값이 3600이라면 토큰이 생성된 시간으로부터 3600초(1 시간) 뒤에 만료된다는 의미이다. refresh_token 선택사항. 인증 서버가 발급한 리프레시 토큰 scope 클라이언트가 요청한 범위와 동일하다면 선택사항. 그렇지 않은 경우 필수. 자세한 내용은 RFC 6749 - Access Token Scope를 참고한다. 성공 응답의 예: HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;refresh_token\u0026#34;:\u0026#34;tGzv3JOkF0XG5Qx2TlKWIA\u0026#34;, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; } 오류 응답 (Error Response) # 인증 서버는 다음 파라미터를 400 (Bad Request) 상태 코드로 응답한다. 파라미터는 application/json 유형을 사용하여 HTTP Response Body에 포함한다. error 필수. 다음의 에러 코드 사용 invalid_request 요청 시 필수 파라미터의 누락, 유효하지 않은 파라미터 포함, 파라미터를 두 번 이상 포함 등 invalid_client 클라이언트가 인증에 실패한 경우 (e.g. 알 수 없는 클라이언트, 클라이언트 인증이 포함되지 않음, 지원되지 않는 인증 방법). invalid_grant 인가 승인 유형 또는 Refresh Token이 유효하지 않거나, 만료, 취소된 경우 또는 인증 요청에 사용된 리다이렉션 URI가 일치하지 않거나 다른 클라이언트에게 발급된 경우 unauthorized_client 클라이언트가 이 인가 승인 유형을 사용할 권한이 없음 access_denied 리소스 소유자 또는 인증 서버가 요청을 거부 unsupported_grant_type 서버가 지원하지 않는 인가 승인 유형인 경우 temporarily_unavailable 인증 서버의 과부하 또는 유지보수로 인해 요청을 처리할 수 없음 (503 Service Unavailable 상태 코드는 HTTP redirect를 통해 클라이언트에게 전달 될 수 없기 때문에 이 오류 코드가 필요) invalid_scope 요청한 scope가 유효하지 않거나, 알 수 없거나, 손상된 경우 error_description 선택사항. 클라이언트 개발자가 발생한 오류를 이해하는 데 도움을 주는 정보를 제공한다. error_uri 선택사항. 클라이언트 개발자를 위해 발생한 오류와 관련된 추가 정보를 제공한다. 오류 응답의 예: HTTP/1.1 400 Bad Request Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;error\u0026#34;:\u0026#34;invalid_request\u0026#34; } 사용 예 # 카카오와 네이버에서도 OAuth 2.0 방식의 로그인 API를 제공한다. 카카오 # 카카오 로그인 문서를 확인해보면, 카카오 로그인을 위해서 인가 코드 받기, 토큰 받기 두 과정을 거친다. 이 과정이 인가 획득과 동일하다. 이렇게 발급받은 토큰은 카카오스토리 API 등을 사용할 때 필요하다. 예를 들어 카카오스토리의 프로필 가져오기 API를 사용하려면 이 발급받은 토큰이 필요하다. 이 과정이 OAuth 2.0의 흐름의 5,6번 과정에 속한다. 네이버 # 네이버도 OAuth를 이용하며, 네이버 로그인 API 명세에서 확인할 수 있다. 카카오와 마찬가지로 인가 코드 받기, 토큰 받기 두 과정을 거친다. 이렇게 발급받은 토큰을 사용하여 회원 프로필 조회 API, 카페 API 등을 사용할 수 있다. 마무리 # 이 포스팅은 OAuth 2.0의 클라이언트 구현에 도움이 되는 내용에 초점을 맞춰 생략된 부분이 많다. 만약 OAuth 2.0에 대해 더 자세히 알고 싶다면, RFC 6749을 참고하는 것이 좋다.","date":"2021-10-22T10:08:30+09:00","href":"https://disj11.github.io/an-introduction-to-oauth2/","objectID":"a177d88fa4b2236fde560a5c14b1fe69_1","order":1,"tags":["development"],"title":"Oauth2 에 대해서 알아보자"},{"content":"개요 # Java8 에서 추가된 DateTimeFormatter 클래스에 대해 알아보자. 미리 정의된 인스턴스 # DateTimeFormatter 에는 ISO 및 RFC 표준을 따라 정의되어 있는 날짜/시간 포맷을 제공한다. 예를들어 ISO_LOCAL_DATE 인스턴스를 사용하여 다음과 같이 \u0026lsquo;2021-09-29\u0026rsquo; 와 같은 문자열을 얻을 수 있다. LocalDate date = LocalDate.of(2021, 9, 29); DateTimeFormatter.ISO_LOCAL_DATE.format(date); // 2021-09-29 만약 \u0026lsquo;2021-09-29+09:00\u0026rsquo; 와 같이 오프셋을 포함한 문자열을 구하고 싶다면 ISO_OFFSET_DATE 를 사용한다. LocalDate date = LocalDate.of(2021, 9, 29); DateTimeFormatter.ISO_OFFSET_DATE.format(date.atStartOfDay(ZoneId.of(\u0026#34;UTC+9\u0026#34;))); // 2021-09-29+09:00 FormatStyle의 사용 # 사람이 이해하기 쉽게 날짜를 보여주고 싶을때가 있다. 이럴 때에는 java.time.format.FormatStyle 을 사용할 수 있다. FormatStyle 은 enum 값으로 FULL, LONG, MEDIUM, SHORT가 정의 되어있다. LocalDate day = LocalDate.of(2021, 9, 29); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.FULL).format(day)); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.LONG).format(day)); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.MEDIUM).format(day)); System.out.println(DateTimeFormatter.ofLocalizedDate(FormatStyle.SHORT).format(day)); 출력은 다음과 같다. Wednesday, September 29, 2021 September 29, 2021 Sep 29, 2021 9/29/21 ZonedDateTime 인스턴스를 사용하여 날짜와 시간을 함께 표현할 수도 있다. LocalDate day = LocalDate.of(2021, 9, 29); LocalTime time = LocalTime.of(13, 12, 45); ZonedDateTime zonedDateTime = ZonedDateTime.of(day, time, ZoneId.of(\u0026#34;Asia/Seoul\u0026#34;)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.FULL).format(zonedDateTime)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.LONG).format(zonedDateTime)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.MEDIUM).format(zonedDateTime)); System.out.println(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.SHORT).format(zonedDateTime)); 출력은 다음과 같다. Wednesday, September 29, 2021 at 1:12:45 PM Korean Standard Time September 29, 2021 at 1:12:45 PM KST Sep 29, 2021, 1:12:45 PM 9/29/21, 1:12 PM 반대로 문자열을 ZonedDateTime 으로 변경하고 싶다면 format() 메서드 대신 parse() 메서드를 사용한다. ZonedDateTime dateTime = ZonedDateTime.from(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.FULL).parse(\u0026#34;Wednesday, September 29, 2021 at 1:12:45 PM Korean Standard Time\u0026#34;)); 사용자 정의 포맷 # 미리 정의된 포맷이 아닌 직접 포맷을 정의하여 사용하고 싶을 때가 있다. 이럴때에는 ofPattern() 메서드를 사용한다. String pattern = \u0026#34;yyyy-MM-dd\u0026#39;T\u0026#39;HH:mm:ss\u0026#34;; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(pattern); System.out.println(formatter.format(LocalDateTime.now())); // 2021-09-29T12:26:18 패턴 문자의 수는 중요하다. 예를들어 month에 MM 과 같은 패턴을 사용한다면 1월을 \u0026ldquo;01\u0026quot;로 표기하며, M 과 같이 표기할 경우 1월을 \u0026ldquo;1\u0026quot;로 표기한다. 자주 사용하는 패턴 문자는 다음과 같다. 문자 의미 표시 예시 u year year 2004; 04 y year-of-era year 2004; 04 M/L month-of-year number/text 7; 07; Jul; July; J d day-of-month number 10 H hour-of-day (0-23) number 0 m minute-of-hour number 30 s second-of-minute number 55 S fraction-of-second number 978 n nano-of-second number 987654321 추가적인 패턴 문자를 알고 싶다면 Java documentation의 Pattern Letters and Symbols 표를 확인한다. 마무리 # 이번 포스트에서는 DateTimeFormatter 에 대하여 알아보았다. DateTimeFormatter 은 SimpleDateFormat 과 달리 스레드에 안전하고 더 최적화 되어있으므로 만약 java8 이상 버전을 사용한다면 SimpleDateFormat 대신 DateTimeFormatter 을 사용하자. 참고 자료: Guide to DateTimeFormatter","date":"2021-09-29T19:33:31+09:00","href":"https://disj11.github.io/date-time-formatter-in-java/","objectID":"70521835029d78afeba9b97ffa274d1a_0","order":0,"tags":["java"],"title":"Date Time Formatter in Java"},{"content":"개요 # Isolation level 은 트랜잭션에서 일관성이 없는 데이터를 어느 수준까지 허용할 것인지를 정의한다. isolation level 이 낮을수록 많은 사용자가 동일한 데이터에 동시에 접근할 수 있는 성능이 향상되지만, 이는 잘 못된 데이터를 읽거나 데이터의 업데이트가 손실되는 등과 같은 증상을 유발할 수 있다. 반대로 isolation level 이 높을수록 문제가 발생할 확률은 줄어들지만, 동일한 데이터에 동시에 접근할 수 있는 성능은 떨어진다. 따라서 데이터베이스 시스템은 보통 네 종류의 isolation level을 정의하고, 알맞은 격리 수준을 선택할 수 있도록 하였다. 용어 설명 # 격리 수준에 대해 알아보기 전에 Dirty Read, Non-repeatable Read, Phantom Read 가 무엇인지 알아야한다. Dirty Read # 커밋되지 않은 데이터를 다른 트랜잭션에서 읽을 수 있도록 허용할 때 발생한다. Transaction 1 Transaction 2 SELECT age FROM users WHERE id = 1; UPDATE users SET age = 21 WHERE id = 1; SELECT age FROM users WHERE id = 1; ROLLBACK; Non-repeatable Read # 한 트랜잭션 내에서 같은 쿼리를 두 번 수행할 때, 그 사이에 다른 트랜잭션이 값을 수정 또는 삭제함으로써 첫 번째와 두 번째 조회의 결과가 다르게 나타나는 현상을 말한다. Transaction 1 Transaction 2 SELECT age FROM users WHERE id = 1; UPDATE users SET age = 21 WHERE id = 1; COMMIT; SELECT age FROM users WHERE id = 1; COMMIT; Phantom Read # 한 트랜잭션 내에서 일정 범위의 레코드를 두 번 이상 읽을 때, 첫 번째 쿼리에서는 없었던 레코드가 이후의 쿼리에서 나타나는 현상을 말한다. Transaction 1 Transaction 2 SELECT age FROM users WHERE age \u0026lt; 20 INSERT INTO users(name, age) VALUES ('홍길동', 10); COMMIT; SELECT age FROM users WHERE age \u0026lt; 20; COMMIT; Isolation level # 앞서 설명한대로 데이터베이스에서는 보통 네 종류의 isolation level을 제공한다. Read Uncommitted # 커밋되지 않은 데이터를 다른 트랜잭션이 읽는 것을 허용한다. Dirty Read, Non-repeatable Read, Phantom Read 현상이 발생한다. Read Committed # 커밋된 데이터만 다른 트랜잭션이 읽는 것을 허용한다. Non-repeatable Read 와 Phantom Read 현상이 발생한다. 대부분의 DBMS가 기본모드로 채택하고 있는 모드이다. Repeatable Read # 선행 트랜잭션이 읽은 데이터의 트랜잭션이 종료될 때까지 후행 트랜잭션은 이 데이터를 갱신하거나 삭제할 수 없게 한다. 같은 데이터를 여러 번 조회하여도 일관성 있는 결과를 보장한다. Phantom Read 현상이 발생한다. Serializable Read # 선행 트랜잭션이 읽은 데이터를 후행 트랜잭션이 갱신하거나 삭제하지 못하게 할 뿐만 아니라, 새로운 레코드를 삽입하는 것도 막는다. 완벽한 읽기 일관성 모드를 제공한다.","date":"2021-09-28T20:30:02+09:00","href":"https://disj11.github.io/understanding-isolation-level-in-database-management/","objectID":"b01a54df9b1a54a03c056e00f3bb0052_0","order":0,"tags":["database"],"title":"Isolation Level 에 대해 알아보자"}]